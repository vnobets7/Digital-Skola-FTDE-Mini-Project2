[0m16:26:21.049768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D633661280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D632E317F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D632E30DA0>]}


============================== 16:26:21.053771 | b4383e9f-8d1d-4789-ba08-eaec36988537 ==============================
[0m16:26:21.053771 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:26:21.054771 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m16:26:21.071770 [info ] [MainThread]: dbt version: 1.8.5
[0m16:26:21.072830 [info ] [MainThread]: python version: 3.12.4
[0m16:26:21.073338 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m16:26:21.074347 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m16:26:21.177346 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m16:26:21.178349 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m16:26:21.179347 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m16:26:21.180347 [info ] [MainThread]: adapter type: postgres
[0m16:26:21.180347 [info ] [MainThread]: adapter version: 1.8.2
[0m16:26:21.262349 [info ] [MainThread]: Configuration:
[0m16:26:21.262349 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:26:21.263347 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:26:21.264347 [info ] [MainThread]: Required dependencies:
[0m16:26:21.264347 [debug] [MainThread]: Executing "git --help"
[0m16:26:21.298912 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:26:21.299915 [debug] [MainThread]: STDERR: "b''"
[0m16:26:21.300916 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:26:21.301914 [info ] [MainThread]: Connection:
[0m16:26:21.301914 [info ] [MainThread]:   host: localhost
[0m16:26:21.302913 [info ] [MainThread]:   port: 5433
[0m16:26:21.302913 [info ] [MainThread]:   user: postgres
[0m16:26:21.303912 [info ] [MainThread]:   database: data_warehouse
[0m16:26:21.304913 [info ] [MainThread]:   schema: dbt_dev
[0m16:26:21.304913 [info ] [MainThread]:   connect_timeout: 10
[0m16:26:21.305915 [info ] [MainThread]:   role: None
[0m16:26:21.305915 [info ] [MainThread]:   search_path: None
[0m16:26:21.306913 [info ] [MainThread]:   keepalives_idle: 0
[0m16:26:21.307914 [info ] [MainThread]:   sslmode: None
[0m16:26:21.307914 [info ] [MainThread]:   sslcert: None
[0m16:26:21.308913 [info ] [MainThread]:   sslkey: None
[0m16:26:21.308913 [info ] [MainThread]:   sslrootcert: None
[0m16:26:21.309913 [info ] [MainThread]:   application_name: dbt
[0m16:26:21.309913 [info ] [MainThread]:   retries: 1
[0m16:26:21.310912 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:26:21.311914 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m16:26:21.373916 [debug] [MainThread]: Using postgres connection "debug"
[0m16:26:21.373916 [debug] [MainThread]: On debug: select 1 as id
[0m16:26:21.374916 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:26:21.382912 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m16:26:21.384914 [debug] [MainThread]: On debug: Close
[0m16:26:21.384914 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:26:21.385915 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:26:21.388170 [debug] [MainThread]: Command `dbt debug` succeeded at 16:26:21.387913 after 0.45 seconds
[0m16:26:21.388701 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m16:26:21.389233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D633661280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D632BD8830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D633D1D7F0>]}
[0m16:26:21.389759 [debug] [MainThread]: Flushing usage events
[0m16:54:50.037695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47A51280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B4507BA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47113380>]}


============================== 16:54:50.042699 | 80267b90-f5af-4f7b-b891-0418626e189b ==============================
[0m16:54:50.042699 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:54:50.043697 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s payment', 'send_anonymous_usage_stats': 'True'}
[0m16:54:50.262285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80267b90-f5af-4f7b-b891-0418626e189b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47BAE990>]}
[0m16:54:50.313285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80267b90-f5af-4f7b-b891-0418626e189b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47ADD730>]}
[0m16:54:50.315287 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:54:50.337284 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:54:50.338284 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:54:50.339285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '80267b90-f5af-4f7b-b891-0418626e189b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47822570>]}
[0m16:54:51.923006 [error] [MainThread]: Encountered an error:
Compilation Error in model payment (models\raw\payment.sql)
  unexpected '/'
    line 2
      [materialized](/reference/resource-configs/materialized)="<materialization_name>",
[0m16:54:51.924975 [debug] [MainThread]: Command `dbt run` failed at 16:54:51.924975 after 2.02 seconds
[0m16:54:51.924975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47A51280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47F59CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B47F5B3B0>]}
[0m16:54:51.925976 [debug] [MainThread]: Flushing usage events
[0m16:55:49.676556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB7F52B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB7F50A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AABF84D0>]}


============================== 16:55:49.680559 | e3806cf2-2030-4acd-aa32-ed3a29bdc98b ==============================
[0m16:55:49.680559 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:55:49.681559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run -s payment', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:55:49.873108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e3806cf2-2030-4acd-aa32-ed3a29bdc98b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB879550>]}
[0m16:55:49.924736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e3806cf2-2030-4acd-aa32-ed3a29bdc98b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB996750>]}
[0m16:55:49.925737 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:55:49.933736 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:55:49.934737 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:55:49.935735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e3806cf2-2030-4acd-aa32-ed3a29bdc98b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB4686B0>]}
[0m16:55:50.804069 [error] [MainThread]: Encountered an error:
Compilation Error in model payment (models\raw\payment.sql)
  expected token 'end of print statement', got '{'
    line 8
      FROM {{ source{'public', 'payment'} }}
[0m16:55:50.806072 [debug] [MainThread]: Command `dbt run` failed at 16:55:50.806072 after 1.22 seconds
[0m16:55:50.806072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB87B2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ABD8F1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ABC4BBC0>]}
[0m16:55:50.807072 [debug] [MainThread]: Flushing usage events
[0m16:57:25.134864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9DF028CB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9DE3BCBF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E1B0B2F0>]}


============================== 16:57:25.138864 | 233a6383-8fe5-4977-b7fb-45d1cd6fc044 ==============================
[0m16:57:25.138864 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:57:25.139864 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run -s payment', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:57:25.335511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E1E05B50>]}
[0m16:57:25.387511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E0DE9280>]}
[0m16:57:25.389511 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:57:25.397512 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:57:25.398513 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:57:25.399511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E1DBDCD0>]}
[0m16:57:26.568659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E21FFBC0>]}
[0m16:57:26.681659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E349B0E0>]}
[0m16:57:26.682660 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m16:57:26.683661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E34B2390>]}
[0m16:57:26.685658 [info ] [MainThread]: 
[0m16:57:26.686659 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:57:26.687659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m16:57:26.755864 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:57:26.756871 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:57:26.756871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:26.766869 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.009 seconds
[0m16:57:26.768869 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:57:26.769870 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_raw)
[0m16:57:26.770874 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_raw"
"
[0m16:57:26.776552 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m16:57:26.777069 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: BEGIN
[0m16:57:26.777585 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:57:26.783935 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:57:26.783935 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m16:57:26.784911 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_raw"} */
create schema if not exists "dbt_dev_raw"
[0m16:57:26.785917 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:57:26.786917 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m16:57:26.786917 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m16:57:26.787917 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m16:57:26.790917 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m16:57:26.790917 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: Close
[0m16:57:26.795767 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m16:57:26.801522 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:57:26.802045 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m16:57:26.802569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:26.807731 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:57:26.808732 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:57:26.808732 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m16:57:26.811731 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m16:57:26.813731 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m16:57:26.814732 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m16:57:26.815734 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m16:57:26.817531 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:57:26.818064 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m16:57:26.818593 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:57:26.824396 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:57:26.824919 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:57:26.825438 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m16:57:26.828060 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m16:57:26.829570 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m16:57:26.830570 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m16:57:26.835468 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:26.836012 [debug] [MainThread]: On master: BEGIN
[0m16:57:26.836538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:57:26.842331 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:57:26.842859 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:26.842859 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:57:26.864426 [debug] [MainThread]: SQL status: SELECT 37 in 0.021 seconds
[0m16:57:26.867426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9DF859370>]}
[0m16:57:26.867426 [debug] [MainThread]: On master: ROLLBACK
[0m16:57:26.868426 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:26.869426 [debug] [MainThread]: On master: BEGIN
[0m16:57:26.870427 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:57:26.870427 [debug] [MainThread]: On master: COMMIT
[0m16:57:26.871426 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:26.871426 [debug] [MainThread]: On master: COMMIT
[0m16:57:26.872426 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:57:26.872426 [debug] [MainThread]: On master: Close
[0m16:57:26.873426 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:57:26.874427 [info ] [MainThread]: 
[0m16:57:26.878715 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m16:57:26.879241 [info ] [Thread-1 (]: 1 of 1 START sql table model dbt_dev_raw.payment ............................... [RUN]
[0m16:57:26.879766 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.payment'
[0m16:57:26.880810 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m16:57:26.888141 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m16:57:26.890141 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m16:57:26.983707 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m16:57:26.986708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:57:26.986708 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m16:57:26.986708 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:57:26.993709 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:57:26.994707 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:57:26.994707 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m16:57:27.002707 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m16:57:27.009707 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:57:27.009707 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m16:57:27.010707 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:57:27.028708 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:57:27.028708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:57:27.029707 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:57:27.035708 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m16:57:27.041707 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m16:57:27.046708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:57:27.047707 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m16:57:27.048707 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:57:27.050707 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m16:57:27.052707 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a6383-8fe5-4977-b7fb-45d1cd6fc044', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9DF7E0EF0>]}
[0m16:57:27.053707 [info ] [Thread-1 (]: 1 of 1 OK created sql table model dbt_dev_raw.payment .......................... [[32mSELECT 14596[0m in 0.17s]
[0m16:57:27.055210 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m16:57:27.056249 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:27.056773 [debug] [MainThread]: On master: BEGIN
[0m16:57:27.057295 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:57:27.063585 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:57:27.064107 [debug] [MainThread]: On master: COMMIT
[0m16:57:27.064630 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:27.065154 [debug] [MainThread]: On master: COMMIT
[0m16:57:27.066180 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m16:57:27.066180 [debug] [MainThread]: On master: Close
[0m16:57:27.067189 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:57:27.067189 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_raw' was properly closed.
[0m16:57:27.067189 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m16:57:27.068186 [debug] [MainThread]: Connection 'model.data_warehouse.payment' was properly closed.
[0m16:57:27.068186 [info ] [MainThread]: 
[0m16:57:27.069016 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m16:57:27.070098 [debug] [MainThread]: Command end result
[0m16:57:27.097545 [info ] [MainThread]: 
[0m16:57:27.098546 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:57:27.099548 [info ] [MainThread]: 
[0m16:57:27.100547 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:57:27.101546 [debug] [MainThread]: Command `dbt run` succeeded at 16:57:27.101546 after 2.08 seconds
[0m16:57:27.102546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E1CD4BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E1CECFE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9E349B2C0>]}
[0m16:57:27.102546 [debug] [MainThread]: Flushing usage events
[0m17:03:55.039015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C14AEB9B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C16CD59D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C16CD5970>]}


============================== 17:03:55.043562 | bd0b560a-a0e0-45d3-9ff6-2e96092d61d2 ==============================
[0m17:03:55.043562 [info ] [MainThread]: Running with dbt=1.8.5
[0m17:03:55.044559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:03:55.244302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1754D6A0>]}
[0m17:03:55.296374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C17641070>]}
[0m17:03:55.297373 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:03:55.305374 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m17:03:55.498585 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 8 files added, 0 files changed.
[0m17:03:55.498585 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\film_actor.sql
[0m17:03:55.499586 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\film.sql
[0m17:03:55.499586 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\inventory.sql
[0m17:03:55.500586 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\rental.sql
[0m17:03:55.500586 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\actor.sql
[0m17:03:55.501585 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\address.sql
[0m17:03:55.501585 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\customer.sql
[0m17:03:55.502585 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\staff.sql
[0m17:03:55.740842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18AF89B0>]}
[0m17:03:55.837843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18BD03E0>]}
[0m17:03:55.838842 [info ] [MainThread]: Found 11 models, 4 data tests, 9 sources, 417 macros
[0m17:03:55.839844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C17865010>]}
[0m17:03:55.841843 [info ] [MainThread]: 
[0m17:03:55.842843 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:03:55.846843 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m17:03:55.918979 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:03:55.920037 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:03:55.920557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:55.930011 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.010 seconds
[0m17:03:55.932074 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:03:55.934697 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:03:55.935226 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:03:55.935747 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:03:55.942640 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m17:03:55.943718 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:03:55.944786 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev)
[0m17:03:55.945844 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev"
"
[0m17:03:55.951112 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m17:03:55.951640 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: BEGIN
[0m17:03:55.952173 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:03:55.957967 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:03:55.957967 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m17:03:55.958978 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev"} */
create schema if not exists "dbt_dev"
[0m17:03:55.960094 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m17:03:55.961252 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m17:03:55.961775 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m17:03:55.962303 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m17:03:55.968659 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m17:03:55.969184 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: Close
[0m17:03:55.971828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m17:03:55.977713 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:03:55.978778 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m17:03:55.978778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:03:55.984529 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:03:55.985531 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:03:55.985531 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m17:03:55.988528 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.002 seconds
[0m17:03:55.990531 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m17:03:55.991529 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m17:03:55.992530 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m17:03:55.995346 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:03:55.996404 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m17:03:55.996937 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:03:56.003304 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m17:03:56.003836 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:03:56.004876 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m17:03:56.006985 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m17:03:56.008989 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m17:03:56.009989 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m17:03:56.016174 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.017237 [debug] [MainThread]: On master: BEGIN
[0m17:03:56.017767 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:03:56.023628 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.024661 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.024661 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:03:56.046233 [debug] [MainThread]: SQL status: SELECT 37 in 0.021 seconds
[0m17:03:56.048231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1790C230>]}
[0m17:03:56.049237 [debug] [MainThread]: On master: ROLLBACK
[0m17:03:56.049237 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.050231 [debug] [MainThread]: On master: BEGIN
[0m17:03:56.051233 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m17:03:56.052232 [debug] [MainThread]: On master: COMMIT
[0m17:03:56.052232 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.053232 [debug] [MainThread]: On master: COMMIT
[0m17:03:56.053232 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:03:56.054232 [debug] [MainThread]: On master: Close
[0m17:03:56.054232 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:03:56.055233 [info ] [MainThread]: 
[0m17:03:56.058821 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m17:03:56.059347 [info ] [Thread-1 (]: 1 of 11 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m17:03:56.060404 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m17:03:56.060934 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m17:03:56.068347 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m17:03:56.069358 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m17:03:56.113354 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m17:03:56.115361 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:03:56.116360 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m17:03:56.116360 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:03:56.123358 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.123358 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:03:56.124359 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m17:03:56.126355 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.001 seconds
[0m17:03:56.132355 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:03:56.132355 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m17:03:56.134354 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.151354 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m17:03:56.151354 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:03:56.152355 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m17:03:56.155357 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:03:56.160354 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m17:03:56.165355 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:03:56.166354 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m17:03:56.167356 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.169356 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m17:03:56.171357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C15040F80>]}
[0m17:03:56.171357 [info ] [Thread-1 (]: 1 of 11 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.11s]
[0m17:03:56.173302 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m17:03:56.173836 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m17:03:56.174361 [info ] [Thread-1 (]: 2 of 11 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m17:03:56.174888 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m17:03:56.175410 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m17:03:56.178593 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m17:03:56.179635 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m17:03:56.182760 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m17:03:56.183288 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:03:56.183817 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m17:03:56.184323 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.190328 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.190328 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:03:56.191328 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m17:03:56.193330 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m17:03:56.197329 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:03:56.197329 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m17:03:56.199330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.200333 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m17:03:56.201333 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:03:56.201333 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m17:03:56.205333 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:03:56.207330 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m17:03:56.208333 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:03:56.208333 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m17:03:56.209331 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.211334 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m17:03:56.211334 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C19034FB0>]}
[0m17:03:56.213331 [info ] [Thread-1 (]: 2 of 11 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.04s]
[0m17:03:56.214391 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m17:03:56.214929 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m17:03:56.215467 [info ] [Thread-1 (]: 3 of 11 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m17:03:56.216531 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m17:03:56.217050 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m17:03:56.219691 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m17:03:56.220749 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m17:03:56.224481 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m17:03:56.225516 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:03:56.226526 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m17:03:56.226526 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.233525 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.233525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:03:56.234524 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m17:03:56.236524 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m17:03:56.239525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:03:56.240524 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m17:03:56.241525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.244527 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m17:03:56.244527 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:03:56.245528 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m17:03:56.248525 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:03:56.250529 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m17:03:56.251528 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:03:56.252528 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m17:03:56.253524 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.254528 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m17:03:56.255529 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C19063E30>]}
[0m17:03:56.256525 [info ] [Thread-1 (]: 3 of 11 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.04s]
[0m17:03:56.257528 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m17:03:56.258296 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m17:03:56.258826 [info ] [Thread-1 (]: 4 of 11 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m17:03:56.259350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m17:03:56.260406 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m17:03:56.264122 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m17:03:56.265178 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m17:03:56.268408 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m17:03:56.269448 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:03:56.269448 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m17:03:56.270460 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.276455 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.276455 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:03:56.277456 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m17:03:56.286456 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m17:03:56.289456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:03:56.289456 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m17:03:56.290458 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.292457 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m17:03:56.292457 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:03:56.293457 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m17:03:56.298458 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m17:03:56.301459 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m17:03:56.302460 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:03:56.302460 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m17:03:56.303460 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.305458 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m17:03:56.305458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18F60590>]}
[0m17:03:56.306457 [info ] [Thread-1 (]: 4 of 11 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m17:03:56.307457 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m17:03:56.308347 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m17:03:56.308873 [info ] [Thread-1 (]: 5 of 11 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m17:03:56.309400 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m17:03:56.309922 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m17:03:56.314212 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m17:03:56.316314 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m17:03:56.319464 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m17:03:56.320472 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:03:56.321473 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m17:03:56.321473 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.327472 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.328473 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:03:56.329475 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m17:03:56.333475 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m17:03:56.336474 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:03:56.336474 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m17:03:56.338472 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.339472 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m17:03:56.339472 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:03:56.340475 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m17:03:56.343472 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:03:56.346472 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m17:03:56.347471 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:03:56.347471 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m17:03:56.349472 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.350471 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m17:03:56.350471 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C19070140>]}
[0m17:03:56.351474 [info ] [Thread-1 (]: 5 of 11 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.04s]
[0m17:03:56.352473 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m17:03:56.353512 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m17:03:56.354043 [info ] [Thread-1 (]: 6 of 11 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m17:03:56.354571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m17:03:56.355096 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m17:03:56.358271 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m17:03:56.359305 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m17:03:56.363048 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m17:03:56.364089 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:03:56.365101 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m17:03:56.365101 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.371096 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.372097 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:03:56.373097 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m17:03:56.376097 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m17:03:56.381097 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:03:56.381097 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m17:03:56.382099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.384099 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m17:03:56.385101 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:03:56.385101 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m17:03:56.390097 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m17:03:56.393096 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m17:03:56.393096 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:03:56.394097 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m17:03:56.396099 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.397098 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m17:03:56.398096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1908E8A0>]}
[0m17:03:56.399097 [info ] [Thread-1 (]: 6 of 11 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.04s]
[0m17:03:56.400098 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m17:03:56.400798 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m17:03:56.401329 [info ] [Thread-1 (]: 7 of 11 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m17:03:56.401859 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m17:03:56.402385 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m17:03:56.405019 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.406066 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m17:03:56.409279 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.410327 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.410853 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m17:03:56.411386 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.439903 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m17:03:56.440903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.441904 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:03:56.443906 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m17:03:56.446906 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.447907 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:03:56.448904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.450904 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m17:03:56.450904 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.451903 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m17:03:56.453904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:03:56.456903 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m17:03:56.457903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:03:56.457903 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m17:03:56.458905 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.460907 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m17:03:56.460907 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18F601D0>]}
[0m17:03:56.461905 [info ] [Thread-1 (]: 7 of 11 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m17:03:56.463761 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m17:03:56.464296 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m17:03:56.464823 [info ] [Thread-1 (]: 8 of 11 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m17:03:56.465350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m17:03:56.465872 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m17:03:56.469043 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m17:03:56.469569 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m17:03:56.472691 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m17:03:56.473741 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.474270 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m17:03:56.474796 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.480311 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.481311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.482313 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m17:03:56.489311 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m17:03:56.492313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.492313 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m17:03:56.494312 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.497312 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.498315 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m17:03:56.499311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.503314 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m17:03:56.503314 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.504314 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m17:03:56.512312 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m17:03:56.515311 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m17:03:56.515311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:03:56.516310 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m17:03:56.520315 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:03:56.521315 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m17:03:56.522312 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18BD21B0>]}
[0m17:03:56.523313 [info ] [Thread-1 (]: 8 of 11 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m17:03:56.524311 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m17:03:56.524854 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m17:03:56.525383 [info ] [Thread-1 (]: 9 of 11 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m17:03:56.526445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m17:03:56.526977 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m17:03:56.532287 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m17:03:56.533332 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m17:03:56.535934 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m17:03:56.536939 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:03:56.537939 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m17:03:56.537939 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.543941 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.544941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:03:56.545940 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m17:03:56.553939 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m17:03:56.556939 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:03:56.557939 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m17:03:56.558941 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.559943 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m17:03:56.560942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:03:56.561943 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m17:03:56.569940 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m17:03:56.571939 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m17:03:56.572942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:03:56.572942 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m17:03:56.573939 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.575939 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m17:03:56.575939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C190465A0>]}
[0m17:03:56.576940 [info ] [Thread-1 (]: 9 of 11 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.05s]
[0m17:03:56.578941 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m17:03:56.579574 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m17:03:56.580107 [info ] [Thread-1 (]: 10 of 11 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m17:03:56.581155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m17:03:56.581683 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m17:03:56.584332 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m17:03:56.585390 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m17:03:56.588565 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m17:03:56.589630 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:03:56.590163 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m17:03:56.590672 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.596681 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:03:56.597680 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:03:56.597680 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m17:03:56.603679 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m17:03:56.606680 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:03:56.607680 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m17:03:56.608680 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.610679 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m17:03:56.610679 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:03:56.611683 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m17:03:56.615684 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:03:56.617683 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m17:03:56.618683 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:03:56.618683 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m17:03:56.619683 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:03:56.621679 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m17:03:56.621679 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C18EBDCD0>]}
[0m17:03:56.622681 [info ] [Thread-1 (]: 10 of 11 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.04s]
[0m17:03:56.624590 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m17:03:56.625117 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m17:03:56.625638 [info ] [Thread-1 (]: 11 of 11 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m17:03:56.626684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.my_second_dbt_model)
[0m17:03:56.627217 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m17:03:56.630402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.631463 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m17:03:56.650047 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.651099 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.651622 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m17:03:56.652139 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:03:56.658033 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.658541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.659554 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m17:03:56.661553 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m17:03:56.664550 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.665549 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:03:56.666552 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:03:56.668553 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m17:03:56.668553 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.669591 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m17:03:56.672109 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:03:56.676109 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m17:03:56.679110 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:03:56.679110 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m17:03:56.681109 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m17:03:56.682110 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m17:03:56.683110 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd0b560a-a0e0-45d3-9ff6-2e96092d61d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1941BEF0>]}
[0m17:03:56.684111 [info ] [Thread-1 (]: 11 of 11 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m17:03:56.685110 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m17:03:56.686488 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.687026 [debug] [MainThread]: On master: BEGIN
[0m17:03:56.687557 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:03:56.693997 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m17:03:56.694529 [debug] [MainThread]: On master: COMMIT
[0m17:03:56.695602 [debug] [MainThread]: Using postgres connection "master"
[0m17:03:56.696132 [debug] [MainThread]: On master: COMMIT
[0m17:03:56.697173 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m17:03:56.698185 [debug] [MainThread]: On master: Close
[0m17:03:56.698185 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:03:56.699186 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev' was properly closed.
[0m17:03:56.699186 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m17:03:56.700183 [debug] [MainThread]: Connection 'model.data_warehouse.my_second_dbt_model' was properly closed.
[0m17:03:56.700183 [info ] [MainThread]: 
[0m17:03:56.701400 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 0.86 seconds (0.86s).
[0m17:03:56.703532 [debug] [MainThread]: Command end result
[0m17:03:56.732488 [info ] [MainThread]: 
[0m17:03:56.733488 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:03:56.734486 [info ] [MainThread]: 
[0m17:03:56.735484 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m17:03:56.737487 [debug] [MainThread]: Command `dbt run` succeeded at 17:03:56.737487 after 1.80 seconds
[0m17:03:56.737487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C17694950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1761D130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025C1761DFD0>]}
[0m17:03:56.738488 [debug] [MainThread]: Flushing usage events
[0m21:17:36.202416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBD9B018E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBD9F25AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBD9A0AF90>]}


============================== 21:17:36.209413 | 726c628e-9633-4d00-9a6e-377b32353035 ==============================
[0m21:17:36.209413 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:17:36.210414 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m21:17:36.241967 [info ] [MainThread]: dbt version: 1.8.5
[0m21:17:36.242966 [info ] [MainThread]: python version: 3.12.4
[0m21:17:36.243965 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m21:17:36.243965 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m21:17:36.388051 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m21:17:36.388569 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m21:17:36.389569 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m21:17:36.390567 [info ] [MainThread]: adapter type: postgres
[0m21:17:36.391566 [info ] [MainThread]: adapter version: 1.8.2
[0m21:17:36.477114 [info ] [MainThread]: Configuration:
[0m21:17:36.478114 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:17:36.479113 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:17:36.479113 [info ] [MainThread]: Required dependencies:
[0m21:17:36.480113 [debug] [MainThread]: Executing "git --help"
[0m21:17:36.521661 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:17:36.521661 [debug] [MainThread]: STDERR: "b''"
[0m21:17:36.522661 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:17:36.523662 [info ] [MainThread]: Connection:
[0m21:17:36.523662 [info ] [MainThread]:   host: localhost
[0m21:17:36.524661 [info ] [MainThread]:   port: 5433
[0m21:17:36.524661 [info ] [MainThread]:   user: postgres
[0m21:17:36.525661 [info ] [MainThread]:   database: data_warehouse
[0m21:17:36.526660 [info ] [MainThread]:   schema: dbt_dev
[0m21:17:36.526660 [info ] [MainThread]:   connect_timeout: 10
[0m21:17:36.527660 [info ] [MainThread]:   role: None
[0m21:17:36.527660 [info ] [MainThread]:   search_path: None
[0m21:17:36.528661 [info ] [MainThread]:   keepalives_idle: 0
[0m21:17:36.528661 [info ] [MainThread]:   sslmode: None
[0m21:17:36.529660 [info ] [MainThread]:   sslcert: None
[0m21:17:36.529660 [info ] [MainThread]:   sslkey: None
[0m21:17:36.530660 [info ] [MainThread]:   sslrootcert: None
[0m21:17:36.530660 [info ] [MainThread]:   application_name: dbt
[0m21:17:36.531660 [info ] [MainThread]:   retries: 1
[0m21:17:36.532660 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:17:36.533662 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m21:17:38.837796 [debug] [MainThread]: Using postgres connection "debug"
[0m21:17:38.838796 [debug] [MainThread]: On debug: select 1 as id
[0m21:17:38.838796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:17:38.861794 [debug] [MainThread]: SQL status: SELECT 1 in 0.022 seconds
[0m21:17:38.862794 [debug] [MainThread]: On debug: Close
[0m21:17:38.862794 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:17:38.863794 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:17:38.865795 [debug] [MainThread]: Command `dbt debug` succeeded at 21:17:38.865795 after 2.80 seconds
[0m21:17:38.865795 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:17:38.867160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBDA13DA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBDA2C1D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBD9FD8D10>]}
[0m21:17:38.867694 [debug] [MainThread]: Flushing usage events
[0m21:17:59.914816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDBF6C620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020ED95BBA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDBD61700>]}


============================== 21:17:59.918816 | 1be4452a-2adf-45d2-9cec-deb0b8b0e526 ==============================
[0m21:17:59.918816 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:17:59.919816 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:18:00.134736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC1DF140>]}
[0m21:18:00.189736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC110F80>]}
[0m21:18:00.191735 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:18:00.215737 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:18:01.201983 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 9 files added, 0 files changed.
[0m21:18:01.202983 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_customer.sql
[0m21:18:01.203984 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_inventory.sql
[0m21:18:01.203984 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\fact_payment.sql
[0m21:18:01.204984 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_address.sql
[0m21:18:01.204984 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_actor.sql
[0m21:18:01.206048 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_rental.sql
[0m21:18:01.206568 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_film_actor.sql
[0m21:18:01.206568 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_film.sql
[0m21:18:01.207562 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediete\dim_staff.sql
[0m21:18:01.475079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDD65BE60>]}
[0m21:18:01.597079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDD71BE60>]}
[0m21:18:01.597079 [info ] [MainThread]: Found 20 models, 4 data tests, 9 sources, 417 macros
[0m21:18:01.598077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC6158E0>]}
[0m21:18:01.601079 [info ] [MainThread]: 
[0m21:18:01.602079 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:18:01.609077 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m21:18:01.681660 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:18:01.682661 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:18:01.682661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:01.691661 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.009 seconds
[0m21:18:01.693660 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:18:01.696660 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:18:01.697048 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:18:01.697574 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:01.704994 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.007 seconds
[0m21:18:01.706575 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:18:01.709143 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:18:01.709143 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:18:01.710468 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:01.716803 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m21:18:01.718382 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:18:01.719460 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_intermediete)
[0m21:18:01.720035 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_intermediete"
"
[0m21:18:01.726305 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediete"
[0m21:18:01.726830 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediete: BEGIN
[0m21:18:01.727398 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:01.733136 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.733136 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediete"
[0m21:18:01.734135 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_intermediete"} */
create schema if not exists "dbt_dev_intermediete"
[0m21:18:01.738136 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.004 seconds
[0m21:18:01.740136 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediete: COMMIT
[0m21:18:01.740136 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediete"
[0m21:18:01.741140 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediete: COMMIT
[0m21:18:01.744138 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m21:18:01.744138 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediete: Close
[0m21:18:01.747503 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_intermediete'
[0m21:18:01.752741 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:18:01.753268 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m21:18:01.753796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:01.759592 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.760592 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:18:01.760592 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:18:01.767594 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m21:18:01.769593 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m21:18:01.770592 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m21:18:01.771593 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_raw)
[0m21:18:01.773608 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:18:01.774138 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m21:18:01.774673 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:01.780995 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.781519 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:18:01.782045 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:18:01.785189 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m21:18:01.787181 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m21:18:01.788179 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m21:18:01.789181 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m21:18:01.792870 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:18:01.793394 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m21:18:01.793917 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:18:01.799685 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.800207 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:18:01.800731 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:18:01.803365 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m21:18:01.804362 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m21:18:01.805362 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m21:18:01.811444 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.811978 [debug] [MainThread]: On master: BEGIN
[0m21:18:01.812502 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:18:01.818855 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.819382 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.819947 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:18:01.856719 [debug] [MainThread]: SQL status: SELECT 38 in 0.036 seconds
[0m21:18:01.858719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDD998800>]}
[0m21:18:01.859720 [debug] [MainThread]: On master: ROLLBACK
[0m21:18:01.860721 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.861720 [debug] [MainThread]: On master: BEGIN
[0m21:18:01.862719 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:18:01.862719 [debug] [MainThread]: On master: COMMIT
[0m21:18:01.863721 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.863721 [debug] [MainThread]: On master: COMMIT
[0m21:18:01.864719 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:18:01.864719 [debug] [MainThread]: On master: Close
[0m21:18:01.865719 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:18:01.866721 [info ] [MainThread]: 
[0m21:18:01.871077 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m21:18:01.872127 [info ] [Thread-1 (]: 1 of 20 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:18:01.872657 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m21:18:01.873182 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m21:18:01.880509 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m21:18:01.881509 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m21:18:01.919025 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m21:18:01.920025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.921023 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m21:18:01.921023 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:18:01.927023 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:01.928023 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.929023 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m21:18:01.945024 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.016 seconds
[0m21:18:01.951025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.952024 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:18:01.953025 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:01.956024 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.956024 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:18:01.957025 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:01.976024 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:18:01.977024 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.977024 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:18:01.980023 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:01.987023 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:18:01.992025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:18:01.992025 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:18:01.998023 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m21:18:02.001023 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m21:18:02.003025 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDB7FE0F0>]}
[0m21:18:02.005024 [info ] [Thread-1 (]: 1 of 20 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m21:18:02.006613 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m21:18:02.007142 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m21:18:02.007665 [info ] [Thread-1 (]: 2 of 20 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:18:02.008237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m21:18:02.008766 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m21:18:02.012477 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m21:18:02.013529 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m21:18:02.017211 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m21:18:02.018319 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.018876 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m21:18:02.019402 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.026898 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.027956 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.028482 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m21:18:02.033723 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.005 seconds
[0m21:18:02.037288 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.038289 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:18:02.039290 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.042290 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.043289 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:18:02.044289 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.046288 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:18:02.046288 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.047288 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:18:02.050288 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.053289 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:18:02.054288 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:18:02.054288 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:18:02.058289 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.060288 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m21:18:02.061288 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDBA7C50>]}
[0m21:18:02.062288 [info ] [Thread-1 (]: 2 of 20 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:18:02.063584 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m21:18:02.064105 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m21:18:02.064632 [info ] [Thread-1 (]: 3 of 20 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:18:02.065679 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m21:18:02.066202 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m21:18:02.069414 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m21:18:02.070465 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m21:18:02.074178 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m21:18:02.074695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.075689 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m21:18:02.075689 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.081687 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:02.082688 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.083687 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m21:18:02.092689 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.009 seconds
[0m21:18:02.097689 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.097689 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:18:02.100689 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:18:02.105688 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.106690 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:18:02.108688 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.112218 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:18:02.113205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.114204 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:18:02.118203 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:18:02.123205 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:18:02.124205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:18:02.124205 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:18:02.129204 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.131203 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m21:18:02.132204 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDBEFFB0>]}
[0m21:18:02.133204 [info ] [Thread-1 (]: 3 of 20 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.07s]
[0m21:18:02.135204 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m21:18:02.136027 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m21:18:02.137102 [info ] [Thread-1 (]: 4 of 20 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:18:02.138158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m21:18:02.139215 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m21:18:02.143481 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m21:18:02.145067 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m21:18:02.152254 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m21:18:02.154255 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.155255 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m21:18:02.156254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.165256 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m21:18:02.165256 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.166252 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m21:18:02.181252 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.015 seconds
[0m21:18:02.186252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.187253 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:18:02.189254 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.192253 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.193253 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:18:02.195253 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.197252 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:18:02.197252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.198253 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:18:02.204252 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:18:02.206253 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:18:02.207255 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:18:02.208256 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:18:02.213252 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.214253 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m21:18:02.215253 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF633E0>]}
[0m21:18:02.216255 [info ] [Thread-1 (]: 4 of 20 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m21:18:02.217256 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m21:18:02.219009 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m21:18:02.219546 [info ] [Thread-1 (]: 5 of 20 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:18:02.220598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m21:18:02.221131 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m21:18:02.224339 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m21:18:02.225401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m21:18:02.230175 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m21:18:02.231233 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.231764 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m21:18:02.232297 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.240345 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m21:18:02.241337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.242338 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m21:18:02.251336 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.009 seconds
[0m21:18:02.256337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.256337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:18:02.258338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.261337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.262337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:18:02.263338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.265337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:18:02.266337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.266337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:18:02.270338 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:18:02.274338 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:18:02.275338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:18:02.276337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:18:02.280336 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.281337 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m21:18:02.282336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDB559D0>]}
[0m21:18:02.283339 [info ] [Thread-1 (]: 5 of 20 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.06s]
[0m21:18:02.285339 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m21:18:02.286338 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m21:18:02.287337 [info ] [Thread-1 (]: 6 of 20 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:18:02.288339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m21:18:02.288339 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m21:18:02.292337 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m21:18:02.293337 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m21:18:02.297336 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m21:18:02.298336 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.298336 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m21:18:02.299336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.306337 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.307340 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.308338 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m21:18:02.314336 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.006 seconds
[0m21:18:02.319337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.320337 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:18:02.321337 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.324338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.325337 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:18:02.326338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.328337 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:18:02.328337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.329336 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:18:02.332336 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.335339 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:18:02.336338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:18:02.336338 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:18:02.340336 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:18:02.342336 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m21:18:02.342336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDBA75F0>]}
[0m21:18:02.343337 [info ] [Thread-1 (]: 6 of 20 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m21:18:02.345338 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m21:18:02.345946 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m21:18:02.346475 [info ] [Thread-1 (]: 7 of 20 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:18:02.347532 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m21:18:02.348060 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m21:18:02.350688 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.351211 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m21:18:02.354905 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.355972 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.356501 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m21:18:02.357017 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.363015 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:02.364015 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.365016 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:18:02.367016 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m21:18:02.371016 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.372016 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:18:02.374015 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.377015 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.378015 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:18:02.379015 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.382018 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:18:02.382018 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.383018 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:18:02.386016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.389015 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:18:02.390021 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:18:02.391014 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:18:02.396016 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.398015 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m21:18:02.399015 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDA48A40>]}
[0m21:18:02.400018 [info ] [Thread-1 (]: 7 of 20 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m21:18:02.401016 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m21:18:02.402016 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m21:18:02.403016 [info ] [Thread-1 (]: 8 of 20 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:18:02.404016 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m21:18:02.405017 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m21:18:02.408015 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m21:18:02.409016 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m21:18:02.413016 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m21:18:02.414015 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.414015 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m21:18:02.415015 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.422015 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.423014 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.424016 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m21:18:02.436015 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.011 seconds
[0m21:18:02.440015 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.441016 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:18:02.442016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.445585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.446589 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:18:02.448586 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.450586 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:18:02.450586 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.451586 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:18:02.458588 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:18:02.462586 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:18:02.463585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:18:02.463585 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:18:02.467585 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:18:02.468585 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m21:18:02.469585 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF54AA0>]}
[0m21:18:02.470587 [info ] [Thread-1 (]: 8 of 20 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m21:18:02.471589 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m21:18:02.472796 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m21:18:02.473371 [info ] [Thread-1 (]: 9 of 20 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:18:02.474438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m21:18:02.474971 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m21:18:02.478142 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m21:18:02.479230 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m21:18:02.482926 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m21:18:02.483449 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.484443 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m21:18:02.485444 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.492442 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.493442 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.494442 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m21:18:02.508443 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.014 seconds
[0m21:18:02.512443 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.512443 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:18:02.514442 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.516443 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.517442 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:18:02.518443 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.521443 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:18:02.521443 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.522442 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:18:02.532443 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m21:18:02.535443 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:18:02.536444 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:18:02.537443 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:18:02.543445 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m21:18:02.545443 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m21:18:02.546443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDAA2360>]}
[0m21:18:02.547443 [info ] [Thread-1 (]: 9 of 20 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m21:18:02.548444 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m21:18:02.549224 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m21:18:02.550313 [info ] [Thread-1 (]: 10 of 20 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:18:02.551373 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m21:18:02.551903 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m21:18:02.556155 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m21:18:02.557737 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m21:18:02.561342 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m21:18:02.562344 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.563343 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m21:18:02.563343 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.570342 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.571343 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.572342 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m21:18:02.582343 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.009 seconds
[0m21:18:02.585343 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.586344 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:18:02.587343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.590342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.591343 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:18:02.592343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.594342 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:18:02.594342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.595343 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:18:02.597342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:18:02.600342 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:18:02.600342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:18:02.601342 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:18:02.605343 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:18:02.607343 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m21:18:02.608343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF47200>]}
[0m21:18:02.609342 [info ] [Thread-1 (]: 10 of 20 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m21:18:02.610344 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m21:18:02.611342 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m21:18:02.612342 [info ] [Thread-1 (]: 11 of 20 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:18:02.613344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m21:18:02.613344 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m21:18:02.616342 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m21:18:02.617342 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m21:18:02.622342 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m21:18:02.624342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:18:02.624342 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m21:18:02.625342 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.632343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.632343 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:18:02.633342 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:18:02.635344 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m21:18:02.695903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:18:02.696905 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:18:02.697904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.699905 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:18:02.699905 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:18:02.700905 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:18:02.704903 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.706903 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:18:02.707904 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:18:02.708905 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:18:02.709904 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.711903 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m21:18:02.712904 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDBB65D0>]}
[0m21:18:02.712904 [info ] [Thread-1 (]: 11 of 20 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m21:18:02.715080 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m21:18:02.715606 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m21:18:02.716661 [info ] [Thread-1 (]: 12 of 20 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:18:02.717188 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m21:18:02.717712 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m21:18:02.720451 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m21:18:02.721535 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m21:18:02.726289 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m21:18:02.727287 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:18:02.728288 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m21:18:02.728288 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.735287 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:02.735287 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:18:02.736287 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m21:18:02.739286 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m21:18:02.742288 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:18:02.743286 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:18:02.744286 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.746286 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:18:02.747287 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:18:02.747287 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:18:02.750286 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:18:02.752286 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:18:02.753287 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:18:02.754288 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:18:02.756286 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.757288 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m21:18:02.758289 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF71E50>]}
[0m21:18:02.759287 [info ] [Thread-1 (]: 12 of 20 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.04s]
[0m21:18:02.760287 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m21:18:02.761286 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m21:18:02.762318 [info ] [Thread-1 (]: 13 of 20 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:18:02.763393 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m21:18:02.763914 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m21:18:02.766529 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m21:18:02.768096 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m21:18:02.771827 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m21:18:02.773341 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:18:02.774340 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m21:18:02.774340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.781338 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:02.782339 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:18:02.782339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:18:02.785339 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m21:18:02.788338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:18:02.789339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:18:02.790338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.792339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:18:02.792339 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:18:02.793339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:18:02.796342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.799338 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:18:02.799338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:18:02.800339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:18:02.801338 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.803339 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m21:18:02.804339 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC45D520>]}
[0m21:18:02.805341 [info ] [Thread-1 (]: 13 of 20 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.04s]
[0m21:18:02.806861 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m21:18:02.807400 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m21:18:02.808454 [info ] [Thread-1 (]: 14 of 20 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:18:02.808982 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m21:18:02.809519 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m21:18:02.812133 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m21:18:02.813704 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m21:18:02.818924 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m21:18:02.820923 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:18:02.821924 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m21:18:02.821924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.848923 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m21:18:02.849924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:18:02.849924 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m21:18:02.857925 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m21:18:02.861973 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:18:02.862507 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:18:02.863487 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.864486 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:18:02.865486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:18:02.865486 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:18:02.871488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m21:18:02.874486 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:18:02.874486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:18:02.875488 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:18:02.876487 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.878487 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m21:18:02.879486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDB529F0>]}
[0m21:18:02.880488 [info ] [Thread-1 (]: 14 of 20 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m21:18:02.881487 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m21:18:02.882621 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m21:18:02.883151 [info ] [Thread-1 (]: 15 of 20 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:18:02.883678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m21:18:02.884203 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m21:18:02.888400 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m21:18:02.889979 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m21:18:02.893193 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m21:18:02.895187 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:18:02.895187 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m21:18:02.895187 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.901186 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:02.902187 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:18:02.903187 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:18:02.907187 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:18:02.910187 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:18:02.911188 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:18:02.912188 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.914188 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:18:02.915187 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:18:02.915187 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:18:02.919187 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:18:02.922187 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:18:02.922187 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:18:02.923188 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:18:02.924188 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.926187 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m21:18:02.927187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDBF911C0>]}
[0m21:18:02.928188 [info ] [Thread-1 (]: 15 of 20 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.04s]
[0m21:18:02.929448 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m21:18:02.929970 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m21:18:02.931036 [info ] [Thread-1 (]: 16 of 20 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:18:02.931567 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m21:18:02.932102 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m21:18:02.935277 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m21:18:02.936891 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m21:18:02.940544 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m21:18:02.941545 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:18:02.942545 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m21:18:02.942545 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:02.949544 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:02.949544 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:18:02.950545 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:18:02.954546 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m21:18:02.958544 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:18:02.958544 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:18:02.959543 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:02.961544 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:18:02.961544 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:18:02.962543 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:18:02.967543 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:18:02.970543 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:18:02.971543 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:18:02.971543 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:18:02.973543 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:02.974544 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m21:18:02.975544 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF72960>]}
[0m21:18:02.975544 [info ] [Thread-1 (]: 16 of 20 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.04s]
[0m21:18:02.977851 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m21:18:02.978380 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m21:18:02.978901 [info ] [Thread-1 (]: 17 of 20 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:18:02.979949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m21:18:02.980474 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m21:18:02.985165 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m21:18:02.986467 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m21:18:03.004070 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.005071 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.006071 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m21:18:03.006071 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:03.012070 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:03.013070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.013070 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:18:03.016069 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:18:03.019070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.020070 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:18:03.021070 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:03.023071 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:18:03.023071 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.024070 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:18:03.026812 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:18:03.029445 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:18:03.032616 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:18:03.033140 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:18:03.034185 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m21:18:03.036279 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m21:18:03.037278 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDF73AA0>]}
[0m21:18:03.038278 [info ] [Thread-1 (]: 17 of 20 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m21:18:03.039410 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m21:18:03.040463 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m21:18:03.041519 [info ] [Thread-1 (]: 18 of 20 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:18:03.042584 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m21:18:03.043101 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m21:18:03.045734 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m21:18:03.046784 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m21:18:03.050507 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m21:18:03.051498 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:18:03.052499 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m21:18:03.052499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:03.081057 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m21:18:03.082059 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:18:03.082059 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:18:03.091059 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m21:18:03.095058 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:18:03.095058 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:18:03.097059 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:03.099058 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:18:03.099058 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:18:03.100058 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:18:03.107059 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:18:03.110057 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:18:03.111058 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:18:03.111058 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:18:03.113057 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:03.114058 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m21:18:03.115058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC591AF0>]}
[0m21:18:03.116059 [info ] [Thread-1 (]: 18 of 20 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m21:18:03.117057 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m21:18:03.118634 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m21:18:03.119166 [info ] [Thread-1 (]: 19 of 20 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:18:03.120213 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m21:18:03.120735 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m21:18:03.123895 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m21:18:03.124945 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m21:18:03.128680 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m21:18:03.129196 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:18:03.130191 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m21:18:03.130191 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:03.137192 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:18:03.137192 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:18:03.138192 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:18:03.147197 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m21:18:03.150191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:18:03.151192 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:18:03.152191 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:03.154191 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:18:03.155192 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:18:03.155192 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:18:03.161191 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m21:18:03.165191 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:18:03.166192 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:18:03.166192 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:18:03.168190 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:03.169192 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m21:18:03.170192 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDDB57CE0>]}
[0m21:18:03.171191 [info ] [Thread-1 (]: 19 of 20 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.05s]
[0m21:18:03.172192 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m21:18:03.173336 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m21:18:03.174410 [info ] [Thread-1 (]: 20 of 20 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:18:03.175459 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m21:18:03.175989 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m21:18:03.178611 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m21:18:03.179648 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m21:18:03.183371 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m21:18:03.183891 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:18:03.184886 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m21:18:03.185886 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:03.191886 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:18:03.192887 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:18:03.193886 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:18:03.200886 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m21:18:03.204886 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:18:03.204886 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:18:03.206887 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:03.207887 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:18:03.208887 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:18:03.208887 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:18:03.211888 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:18:03.214886 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:18:03.215886 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:18:03.215886 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:18:03.217886 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:03.219887 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m21:18:03.220887 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be4452a-2adf-45d2-9cec-deb0b8b0e526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC22D550>]}
[0m21:18:03.220887 [info ] [Thread-1 (]: 20 of 20 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.04s]
[0m21:18:03.222873 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m21:18:03.223936 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:03.224475 [debug] [MainThread]: On master: BEGIN
[0m21:18:03.225006 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:18:03.231346 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:18:03.231868 [debug] [MainThread]: On master: COMMIT
[0m21:18:03.232397 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:03.232926 [debug] [MainThread]: On master: COMMIT
[0m21:18:03.233462 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:18:03.233980 [debug] [MainThread]: On master: Close
[0m21:18:03.234977 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:18:03.234977 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_intermediete' was properly closed.
[0m21:18:03.235977 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m21:18:03.235977 [debug] [MainThread]: Connection 'model.data_warehouse.dim_staff' was properly closed.
[0m21:18:03.237601 [info ] [MainThread]: 
[0m21:18:03.238140 [info ] [MainThread]: Finished running 19 table models, 1 view model in 0 hours 0 minutes and 1.63 seconds (1.63s).
[0m21:18:03.242334 [debug] [MainThread]: Command end result
[0m21:18:03.276655 [info ] [MainThread]: 
[0m21:18:03.277655 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:18:03.277655 [info ] [MainThread]: 
[0m21:18:03.278658 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m21:18:03.279655 [debug] [MainThread]: Command `dbt run` succeeded at 21:18:03.279655 after 3.46 seconds
[0m21:18:03.280654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDBFC1C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDC438E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EDBED7E60>]}
[0m21:18:03.280654 [debug] [MainThread]: Flushing usage events
[0m21:25:10.228699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE30C5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCDBE7440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCD95CFE0>]}


============================== 21:25:10.233701 | 1a34875b-12f4-4874-8b2b-cedc1e936b07 ==============================
[0m21:25:10.233701 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:25:10.235698 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:25:10.439283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE4B0FE0>]}
[0m21:25:10.496849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCDC1C800>]}
[0m21:25:10.498848 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:25:10.506848 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:25:10.690417 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m21:25:10.691417 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\total_revenue.sql
[0m21:25:10.946137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFA3AF30>]}
[0m21:25:11.066138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFA52690>]}
[0m21:25:11.067137 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:25:11.067137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFA36990>]}
[0m21:25:11.070137 [info ] [MainThread]: 
[0m21:25:11.072137 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:25:11.077136 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m21:25:11.156718 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:25:11.157718 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:25:11.157718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:11.167719 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.009 seconds
[0m21:25:11.169720 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:25:11.172840 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:25:11.173363 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:25:11.173900 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.180243 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m21:25:11.181852 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:25:11.183970 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:25:11.184692 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:25:11.185242 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.191689 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m21:25:11.193282 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:25:11.195943 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:25:11.196351 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:25:11.196876 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.203856 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.007 seconds
[0m21:25:11.205470 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:25:11.206530 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_mart)
[0m21:25:11.207058 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_mart"
"
[0m21:25:11.212497 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m21:25:11.213037 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: BEGIN
[0m21:25:11.213543 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.219955 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.219955 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m21:25:11.220946 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_mart"} */
create schema if not exists "dbt_dev_mart"
[0m21:25:11.221949 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:25:11.223944 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m21:25:11.223944 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m21:25:11.224944 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m21:25:11.235945 [debug] [ThreadPool]: SQL status: COMMIT in 0.011 seconds
[0m21:25:11.236949 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: Close
[0m21:25:11.238947 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m21:25:11.247004 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:25:11.247004 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m21:25:11.248154 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:11.254779 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.254779 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:25:11.255778 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:25:11.258778 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m21:25:11.259778 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m21:25:11.260778 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m21:25:11.261779 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m21:25:11.264825 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:25:11.265358 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m21:25:11.265888 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.272263 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.272790 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:25:11.273314 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:25:11.276404 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m21:25:11.277404 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m21:25:11.278404 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m21:25:11.279406 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_mart)
[0m21:25:11.283633 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:25:11.284154 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m21:25:11.284154 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.291015 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.291541 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:25:11.292069 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:25:11.295227 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:25:11.296227 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m21:25:11.297222 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m21:25:11.298223 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m21:25:11.300487 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:25:11.301135 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m21:25:11.301658 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:11.307978 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.308504 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:25:11.309025 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:25:11.311652 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m21:25:11.313651 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m21:25:11.314651 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m21:25:11.321369 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:11.321892 [debug] [MainThread]: On master: BEGIN
[0m21:25:11.322443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:25:11.328822 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.329823 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:11.329823 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:25:11.337820 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m21:25:11.340822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFA9EF00>]}
[0m21:25:11.340822 [debug] [MainThread]: On master: ROLLBACK
[0m21:25:11.341823 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:11.342823 [debug] [MainThread]: On master: BEGIN
[0m21:25:11.343821 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:25:11.343821 [debug] [MainThread]: On master: COMMIT
[0m21:25:11.344824 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:11.344824 [debug] [MainThread]: On master: COMMIT
[0m21:25:11.345823 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:25:11.345823 [debug] [MainThread]: On master: Close
[0m21:25:11.346820 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:25:11.347821 [info ] [MainThread]: 
[0m21:25:11.351352 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m21:25:11.352405 [info ] [Thread-1 (]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:25:11.353453 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m21:25:11.353453 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m21:25:11.361272 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m21:25:11.362272 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m21:25:11.402276 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m21:25:11.403276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.403276 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m21:25:11.404376 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:25:11.410272 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.411273 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.412272 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m21:25:11.414273 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m21:25:11.421273 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.422273 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:25:11.423272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.426272 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.427272 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:25:11.428272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.449273 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:25:11.450328 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.451285 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:25:11.460282 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m21:25:11.469284 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:25:11.474282 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:25:11.475283 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:25:11.483284 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m21:25:11.486283 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m21:25:11.487284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCDB9DE80>]}
[0m21:25:11.488285 [info ] [Thread-1 (]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m21:25:11.490350 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m21:25:11.490875 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m21:25:11.491923 [info ] [Thread-1 (]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:25:11.492458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m21:25:11.492985 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m21:25:11.496120 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m21:25:11.497230 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m21:25:11.503383 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m21:25:11.504383 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.505384 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m21:25:11.505384 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.512383 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.513386 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.513386 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m21:25:11.516384 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m21:25:11.519384 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.520383 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:25:11.521384 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.524383 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.525383 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:25:11.526383 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.528383 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:25:11.528383 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.529384 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:25:11.537428 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:25:11.539386 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:25:11.540386 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:25:11.540386 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:25:11.549384 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m21:25:11.551395 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m21:25:11.552395 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFEF12E0>]}
[0m21:25:11.553396 [info ] [Thread-1 (]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m21:25:11.555142 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m21:25:11.555679 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m21:25:11.556730 [info ] [Thread-1 (]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:25:11.557253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m21:25:11.557777 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m21:25:11.560952 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m21:25:11.561997 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m21:25:11.566220 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m21:25:11.567215 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.568215 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m21:25:11.569214 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.575214 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:25:11.576216 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.577217 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m21:25:11.579214 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m21:25:11.582217 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.583213 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:25:11.584215 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.587216 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.587216 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:25:11.588216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.590297 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:25:11.591219 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.591219 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:25:11.600214 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m21:25:11.603215 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:25:11.604215 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:25:11.604215 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:25:11.613213 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m21:25:11.615214 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m21:25:11.616214 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFEA32F0>]}
[0m21:25:11.617217 [info ] [Thread-1 (]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m21:25:11.618473 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m21:25:11.618999 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m21:25:11.620053 [info ] [Thread-1 (]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:25:11.620581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m21:25:11.621119 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m21:25:11.624343 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m21:25:11.625413 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m21:25:11.630619 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m21:25:11.631619 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.631619 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m21:25:11.632619 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.638617 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.639616 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.639616 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m21:25:11.666616 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.026 seconds
[0m21:25:11.670616 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.671617 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:25:11.673617 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.675617 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.676619 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:25:11.677617 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.679615 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:25:11.679615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.680615 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:25:11.697615 [debug] [Thread-1 (]: SQL status: COMMIT in 0.017 seconds
[0m21:25:11.700616 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:25:11.701620 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:25:11.702617 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:25:11.712617 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.009 seconds
[0m21:25:11.714618 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m21:25:11.716618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADD02AA930>]}
[0m21:25:11.717617 [info ] [Thread-1 (]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.10s]
[0m21:25:11.720618 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m21:25:11.721616 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m21:25:11.722531 [info ] [Thread-1 (]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:25:11.724192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m21:25:11.724814 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m21:25:11.728836 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m21:25:11.730531 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m21:25:11.736169 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m21:25:11.738168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.738168 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m21:25:11.740169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.748169 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m21:25:11.749169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.750167 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m21:25:11.755169 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:25:11.759168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.760169 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:25:11.763168 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:25:11.768168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.768168 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:25:11.770168 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.772169 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:25:11.772169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.773167 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:25:11.777167 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:25:11.781169 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:25:11.782168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:25:11.783168 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:25:11.787168 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:25:11.788168 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m21:25:11.789170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFD82720>]}
[0m21:25:11.791170 [info ] [Thread-1 (]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m21:25:11.792169 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m21:25:11.793168 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m21:25:11.794167 [info ] [Thread-1 (]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:25:11.795169 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m21:25:11.795169 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m21:25:11.798168 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m21:25:11.799168 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m21:25:11.803169 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m21:25:11.804171 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.804171 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m21:25:11.805172 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.812169 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.812169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.813169 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m21:25:11.817168 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m21:25:11.821168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.822170 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:25:11.824167 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.827167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.827167 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:25:11.828167 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.831169 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:25:11.831169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.832168 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:25:11.835169 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:11.838167 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:25:11.839167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:25:11.840168 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:25:11.843170 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:11.845170 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m21:25:11.845170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFDECF20>]}
[0m21:25:11.846168 [info ] [Thread-1 (]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m21:25:11.848168 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m21:25:11.848871 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m21:25:11.849927 [info ] [Thread-1 (]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:25:11.850458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m21:25:11.850982 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m21:25:11.853630 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.854166 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m21:25:11.857905 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.858971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.859494 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m21:25:11.860026 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.866013 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.867017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.868017 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:25:11.870016 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m21:25:11.872591 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.873592 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:25:11.874589 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.877591 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.877591 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:25:11.878593 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.880592 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:25:11.881592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.881592 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:25:11.884588 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:11.888589 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:25:11.889590 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:25:11.890590 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:25:11.894588 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:25:11.896588 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m21:25:11.897588 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE583C20>]}
[0m21:25:11.898591 [info ] [Thread-1 (]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m21:25:11.900172 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m21:25:11.900708 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m21:25:11.901236 [info ] [Thread-1 (]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:25:11.902339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m21:25:11.902866 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m21:25:11.907071 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m21:25:11.908139 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m21:25:11.911296 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m21:25:11.912294 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.913293 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m21:25:11.913293 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.920295 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.921295 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.921295 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m21:25:11.929293 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m21:25:11.932296 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.933295 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:25:11.935295 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.939296 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.940294 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:25:11.941294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:11.943297 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:25:11.943297 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.944298 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:25:11.950295 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m21:25:11.954296 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:25:11.955296 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:25:11.955296 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:25:11.959294 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:11.960297 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m21:25:11.961294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADD0286600>]}
[0m21:25:11.962299 [info ] [Thread-1 (]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m21:25:11.963298 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m21:25:11.964720 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m21:25:11.965244 [info ] [Thread-1 (]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:25:11.966292 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m21:25:11.966822 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m21:25:11.970488 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m21:25:11.971013 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m21:25:11.975225 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m21:25:11.976271 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:11.976271 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m21:25:11.977267 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:11.984268 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:11.984268 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:11.985267 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m21:25:11.994266 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m21:25:11.998269 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:11.999269 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:25:12.000746 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.004728 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:12.005729 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:25:12.007728 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.009728 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:25:12.010729 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:12.011431 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:25:12.018478 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:25:12.021479 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:25:12.022479 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:25:12.023481 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:25:12.027479 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:25:12.028478 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m21:25:12.029478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCF92E9C0>]}
[0m21:25:12.030481 [info ] [Thread-1 (]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m21:25:12.031481 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m21:25:12.032774 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m21:25:12.033308 [info ] [Thread-1 (]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:25:12.034372 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m21:25:12.034897 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m21:25:12.038589 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m21:25:12.040171 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m21:25:12.044986 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m21:25:12.045985 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.046989 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m21:25:12.047987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.054531 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.055531 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.055531 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m21:25:12.063532 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m21:25:12.067532 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.067532 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:25:12.069532 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.073532 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.074531 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:25:12.075531 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.077535 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:25:12.077535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.078535 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:25:12.081533 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.084534 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:25:12.085535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:25:12.085535 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:25:12.090534 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:25:12.091535 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m21:25:12.092535 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFAB3A40>]}
[0m21:25:12.093533 [info ] [Thread-1 (]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m21:25:12.094533 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m21:25:12.095670 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m21:25:12.096742 [info ] [Thread-1 (]: 11 of 21 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:25:12.097268 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m21:25:12.097806 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m21:25:12.101009 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m21:25:12.102087 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m21:25:12.107844 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m21:25:12.108845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.109844 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m21:25:12.109844 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.116843 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.117845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.117845 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:25:12.119841 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m21:25:12.179855 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.180855 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:25:12.182855 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.185854 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.186854 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:25:12.187854 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.189854 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:25:12.189854 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.190854 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:25:12.194853 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.196853 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:25:12.197853 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:25:12.198855 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:25:12.202857 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.203854 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m21:25:12.204857 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFF1B950>]}
[0m21:25:12.205855 [info ] [Thread-1 (]: 11 of 21 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m21:25:12.207920 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m21:25:12.208447 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m21:25:12.208968 [info ] [Thread-1 (]: 12 of 21 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:25:12.209482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m21:25:12.210008 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m21:25:12.213150 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m21:25:12.214228 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m21:25:12.219090 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m21:25:12.219610 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.220601 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m21:25:12.220601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.228602 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m21:25:12.229602 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.230602 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m21:25:12.233601 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m21:25:12.237604 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.237604 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m21:25:12.239602 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.243601 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.243601 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:25:12.245601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.247602 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:25:12.248601 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.248601 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:25:12.252114 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.255114 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:25:12.256117 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:25:12.256117 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:25:12.260115 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.262115 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m21:25:12.263116 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFED4470>]}
[0m21:25:12.264116 [info ] [Thread-1 (]: 12 of 21 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m21:25:12.265119 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m21:25:12.266228 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m21:25:12.266764 [info ] [Thread-1 (]: 13 of 21 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:25:12.267821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m21:25:12.268357 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m21:25:12.272014 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m21:25:12.273086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m21:25:12.277313 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m21:25:12.278311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.278311 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m21:25:12.279311 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.286306 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m21:25:12.287307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.288306 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:25:12.290306 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m21:25:12.294307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.295306 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:25:12.296307 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.301308 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.302308 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:25:12.303308 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.305307 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:25:12.305307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.306867 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:25:12.309862 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.312864 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:25:12.313865 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:25:12.314867 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:25:12.317863 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.319865 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m21:25:12.320864 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFDEE0C0>]}
[0m21:25:12.320864 [info ] [Thread-1 (]: 13 of 21 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m21:25:12.322863 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m21:25:12.322939 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m21:25:12.323996 [info ] [Thread-1 (]: 14 of 21 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:25:12.324523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m21:25:12.325059 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m21:25:12.328191 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m21:25:12.329733 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m21:25:12.333428 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m21:25:12.334476 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.334476 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m21:25:12.335473 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.342473 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.342473 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.343473 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m21:25:12.353485 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m21:25:12.356485 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.357485 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m21:25:12.358485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.361484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.362484 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:25:12.363484 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.365484 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:25:12.366486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.366486 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:25:12.372485 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:25:12.375486 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:25:12.376489 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:25:12.376489 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:25:12.380487 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:25:12.382484 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m21:25:12.383486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADD02BCB90>]}
[0m21:25:12.384487 [info ] [Thread-1 (]: 14 of 21 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m21:25:12.386485 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m21:25:12.386793 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m21:25:12.387323 [info ] [Thread-1 (]: 15 of 21 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:25:12.388374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m21:25:12.388899 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m21:25:12.391528 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m21:25:12.393109 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m21:25:12.396784 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m21:25:12.397831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.398346 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m21:25:12.398346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.405343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.406342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.407343 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:25:12.410344 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m21:25:12.414347 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.415344 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:25:12.416343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.419345 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.419345 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:25:12.421342 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.422347 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:25:12.423346 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.423346 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:25:12.427343 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.429346 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:25:12.431346 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:25:12.431346 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:25:12.435344 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.436347 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m21:25:12.437346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADD02A8260>]}
[0m21:25:12.438346 [info ] [Thread-1 (]: 15 of 21 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:25:12.439345 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m21:25:12.440343 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m21:25:12.440343 [info ] [Thread-1 (]: 16 of 21 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:25:12.441855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m21:25:12.442395 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m21:25:12.447157 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m21:25:12.448223 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m21:25:12.451445 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m21:25:12.452438 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.453440 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m21:25:12.453440 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.460436 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.461436 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.461436 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:25:12.465437 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:25:12.468439 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.469439 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:25:12.470438 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.473438 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.474440 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:25:12.475437 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.477437 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:25:12.477437 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.478440 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:25:12.481437 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.484436 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:25:12.485436 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:25:12.486436 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:25:12.490437 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.492435 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m21:25:12.493435 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFEA23C0>]}
[0m21:25:12.493435 [info ] [Thread-1 (]: 16 of 21 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m21:25:12.494436 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m21:25:12.495643 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m21:25:12.496712 [info ] [Thread-1 (]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:25:12.497770 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m21:25:12.498299 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m21:25:12.501988 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.503049 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m21:25:12.528559 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.530560 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.530560 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m21:25:12.531561 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.539559 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.540557 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.541558 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:25:12.543558 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m21:25:12.547559 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.547559 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:25:12.549557 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.551578 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:25:12.552570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.552570 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:25:12.555570 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.558570 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:25:12.561568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:25:12.562568 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:25:12.564570 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m21:25:12.565570 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m21:25:12.566572 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFEA2ED0>]}
[0m21:25:12.567571 [info ] [Thread-1 (]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m21:25:12.568571 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m21:25:12.570569 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m21:25:12.570569 [info ] [Thread-1 (]: 18 of 21 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:25:12.571569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m21:25:12.572569 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m21:25:12.575574 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m21:25:12.576573 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m21:25:12.581572 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m21:25:12.582572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.583573 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m21:25:12.583573 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.590569 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.591570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.591570 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:25:12.599569 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m21:25:12.603570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.603570 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:25:12.605569 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.608572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.609569 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:25:12.610569 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.612569 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:25:12.613570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.613570 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:25:12.619570 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m21:25:12.623570 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:25:12.623570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:25:12.624571 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:25:12.628570 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.630570 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m21:25:12.631570 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE747B00>]}
[0m21:25:12.632572 [info ] [Thread-1 (]: 18 of 21 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m21:25:12.633570 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m21:25:12.634472 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m21:25:12.635533 [info ] [Thread-1 (]: 19 of 21 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:25:12.636125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m21:25:12.636653 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m21:25:12.639842 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m21:25:12.640867 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m21:25:12.644569 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m21:25:12.645610 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.645610 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m21:25:12.646606 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.652607 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:25:12.654606 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.654606 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:25:12.664605 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m21:25:12.668605 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.668605 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:25:12.670605 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.673606 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.674607 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:25:12.675607 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.677610 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:25:12.678609 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.678609 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:25:12.686606 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m21:25:12.689608 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:25:12.690610 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:25:12.690610 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:25:12.694607 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.695606 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m21:25:12.696606 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCF903320>]}
[0m21:25:12.697607 [info ] [Thread-1 (]: 19 of 21 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m21:25:12.699866 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m21:25:12.700398 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m21:25:12.700925 [info ] [Thread-1 (]: 20 of 21 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:25:12.701972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m21:25:12.702501 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m21:25:12.705675 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m21:25:12.706718 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m21:25:12.710363 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m21:25:12.711407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.711930 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m21:25:12.712457 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.719525 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.720524 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.720524 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:25:12.726524 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m21:25:12.730525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.731525 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:25:12.733526 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.736526 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.736526 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:25:12.738526 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.742524 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:25:12.742524 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.743524 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:25:12.746525 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:25:12.749525 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:25:12.750526 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:25:12.750526 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:25:12.754644 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:25:12.756644 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m21:25:12.756644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCFF3E5A0>]}
[0m21:25:12.757644 [info ] [Thread-1 (]: 20 of 21 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m21:25:12.759644 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m21:25:12.760769 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m21:25:12.761294 [info ] [Thread-1 (]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:25:12.762339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m21:25:12.762860 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m21:25:12.766029 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m21:25:12.767074 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m21:25:12.770748 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m21:25:12.771745 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:25:12.772744 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m21:25:12.772744 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:12.779744 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.780745 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:25:12.781749 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m21:25:12.805745 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.023 seconds
[0m21:25:12.809745 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:25:12.809745 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m21:25:12.811746 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:12.813747 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m21:25:12.813747 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:25:12.814745 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m21:25:12.819744 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:25:12.822744 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m21:25:12.822744 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:25:12.823746 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m21:25:12.824746 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:25:12.826745 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m21:25:12.826745 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a34875b-12f4-4874-8b2b-cedc1e936b07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADD02E7080>]}
[0m21:25:12.827746 [info ] [Thread-1 (]: 21 of 21 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.06s]
[0m21:25:12.829746 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m21:25:12.831092 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:12.831617 [debug] [MainThread]: On master: BEGIN
[0m21:25:12.832144 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:25:12.839053 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:25:12.840185 [debug] [MainThread]: On master: COMMIT
[0m21:25:12.840717 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:12.841254 [debug] [MainThread]: On master: COMMIT
[0m21:25:12.842773 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:25:12.842773 [debug] [MainThread]: On master: Close
[0m21:25:12.843773 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:25:12.843773 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_mart' was properly closed.
[0m21:25:12.844772 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediete' was properly closed.
[0m21:25:12.844772 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m21:25:12.845773 [info ] [MainThread]: 
[0m21:25:12.846857 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 1.77 seconds (1.77s).
[0m21:25:12.851130 [debug] [MainThread]: Command end result
[0m21:25:12.886542 [info ] [MainThread]: 
[0m21:25:12.886542 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:25:12.887545 [info ] [MainThread]: 
[0m21:25:12.888542 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m21:25:12.889542 [debug] [MainThread]: Command `dbt run` succeeded at 21:25:12.889542 after 2.77 seconds
[0m21:25:12.890545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE714BC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCD9D18E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002ADCE1238F0>]}
[0m21:25:12.890545 [debug] [MainThread]: Flushing usage events
[0m21:29:49.753637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F526F8B740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F527E6D6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5278AB140>]}


============================== 21:29:49.758637 | f21bbbb5-7519-4bd7-a83e-c2e3477e75c7 ==============================
[0m21:29:49.758637 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:29:49.759640 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:29:49.976792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F528013A70>]}
[0m21:29:50.033790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5276A1A30>]}
[0m21:29:50.034790 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:29:50.042791 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:29:50.206424 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:29:50.207424 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:29:50.249423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5284EFEF0>]}
[0m21:29:50.277424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52965AB10>]}
[0m21:29:50.278424 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:29:50.279423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F528379520>]}
[0m21:29:50.282423 [info ] [MainThread]: 
[0m21:29:50.283423 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:29:50.287423 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m21:29:50.368980 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:29:50.369981 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m21:29:50.369981 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:29:50.379980 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m21:29:50.379980 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:29:50.380979 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:29:50.383983 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m21:29:50.385981 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m21:29:50.386981 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m21:29:50.386981 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m21:29:50.392980 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:29:50.393981 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m21:29:50.394981 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:29:50.400981 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:29:50.401979 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:29:50.401979 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:29:50.404983 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m21:29:50.406981 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m21:29:50.407979 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m21:29:50.407979 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediete)
[0m21:29:50.411921 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:29:50.412457 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m21:29:50.413068 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:29:50.419910 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:29:50.420437 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m21:29:50.420968 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:29:50.423538 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m21:29:50.425536 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m21:29:50.426537 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m21:29:50.427541 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_mart)
[0m21:29:50.431536 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:29:50.432537 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m21:29:50.432537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:29:50.438536 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:29:50.438536 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:29:50.439535 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:29:50.442535 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m21:29:50.444547 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m21:29:50.445536 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m21:29:50.452535 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:50.453536 [debug] [MainThread]: On master: BEGIN
[0m21:29:50.453536 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:29:50.460536 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:29:50.461537 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:50.462536 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:29:50.470536 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m21:29:50.472537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f21bbbb5-7519-4bd7-a83e-c2e3477e75c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5284BFBF0>]}
[0m21:29:50.473536 [debug] [MainThread]: On master: ROLLBACK
[0m21:29:50.474539 [debug] [MainThread]: On master: Close
[0m21:29:50.474539 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:29:50.475537 [info ] [MainThread]: 
[0m21:29:50.480372 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m21:29:50.481425 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m21:29:50.481953 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m21:29:50.489279 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m21:29:50.490267 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m21:29:50.491268 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m21:29:50.493267 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m21:29:50.494267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m21:29:50.494267 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m21:29:50.498267 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m21:29:50.499266 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m21:29:50.500269 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m21:29:50.500269 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m21:29:50.501267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m21:29:50.501267 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m21:29:50.505269 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m21:29:50.506268 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m21:29:50.506268 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m21:29:50.507268 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m21:29:50.508267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m21:29:50.508267 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m21:29:50.512296 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m21:29:50.514266 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m21:29:50.515266 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m21:29:50.515266 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m21:29:50.516266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m21:29:50.517267 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m21:29:50.519265 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m21:29:50.520265 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m21:29:50.521268 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m21:29:50.522267 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m21:29:50.523266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m21:29:50.523266 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m21:29:50.527271 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m21:29:50.528267 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m21:29:50.529267 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m21:29:50.530267 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m21:29:50.531266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m21:29:50.531266 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m21:29:50.534266 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m21:29:50.535333 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m21:29:50.535855 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m21:29:50.535855 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m21:29:50.536851 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m21:29:50.537851 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m21:29:50.539848 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m21:29:50.540848 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m21:29:50.541848 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m21:29:50.542850 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m21:29:50.543894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m21:29:50.544853 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m21:29:50.549849 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m21:29:50.551405 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m21:29:50.552402 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m21:29:50.552402 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m21:29:50.553402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m21:29:50.554402 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m21:29:50.556402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m21:29:50.557403 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m21:29:50.558403 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m21:29:50.559402 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m21:29:50.560406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m21:29:50.560406 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m21:29:50.563402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m21:29:50.564402 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m21:29:50.565402 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m21:29:50.566402 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m21:29:50.566402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m21:29:50.567402 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m21:29:50.569402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m21:29:50.570403 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m21:29:50.571403 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m21:29:50.572402 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m21:29:50.572402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m21:29:50.573403 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m21:29:50.576404 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m21:29:50.577405 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m21:29:50.578402 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m21:29:50.579458 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m21:29:50.579458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m21:29:50.580404 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m21:29:50.583402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m21:29:50.583402 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m21:29:50.584405 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m21:29:50.585403 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m21:29:50.585403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m21:29:50.586402 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m21:29:50.588401 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m21:29:50.589401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m21:29:50.590401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m21:29:50.590401 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m21:29:50.591401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m21:29:50.591401 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m21:29:50.595402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m21:29:50.596402 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m21:29:50.597402 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m21:29:50.597402 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m21:29:50.598401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m21:29:50.599402 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m21:29:50.601402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m21:29:50.602401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m21:29:50.603401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m21:29:50.603401 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:29:50.604401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m21:29:50.605401 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:29:50.617401 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:29:50.618401 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:29:50.619401 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:29:50.620401 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m21:29:50.621403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m21:29:50.621403 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m21:29:50.631404 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m21:29:50.632404 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m21:29:50.633404 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m21:29:50.634404 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m21:29:50.635403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m21:29:50.635403 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m21:29:50.638401 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m21:29:50.639402 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m21:29:50.640401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m21:29:50.640401 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m21:29:50.641402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m21:29:50.641402 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m21:29:50.645402 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m21:29:50.646402 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m21:29:50.647402 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m21:29:50.647402 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m21:29:50.648401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m21:29:50.648401 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m21:29:50.652401 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m21:29:50.653401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m21:29:50.653401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m21:29:50.654401 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m21:29:50.654401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m21:29:50.655401 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m21:29:50.658401 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m21:29:50.660405 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m21:29:50.661402 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m21:29:50.661402 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m21:29:50.662402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m21:29:50.662402 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m21:29:50.666402 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:29:50.667401 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m21:29:50.668401 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m21:29:50.668401 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m21:29:50.669401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.total_revenue)
[0m21:29:50.669401 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m21:29:50.672401 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m21:29:50.673401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m21:29:50.674401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m21:29:50.675402 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:29:50.675402 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_mart' was properly closed.
[0m21:29:50.676404 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m21:29:50.681402 [debug] [MainThread]: Command end result
[0m21:29:50.993732 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m21:29:50.993732 [info ] [MainThread]: Building catalog
[0m21:29:51.005731 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m21:29:51.014730 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m21:29:51.014730 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m21:29:51.015731 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:29:51.021730 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:29:51.022733 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m21:29:51.022733 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m21:29:51.030732 [debug] [ThreadPool]: SQL status: SELECT 202 in 0.007 seconds
[0m21:29:51.041731 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m21:29:51.043734 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m21:29:51.087953 [info ] [MainThread]: Catalog written to C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\target\catalog.json
[0m21:29:51.089954 [debug] [MainThread]: Command `dbt docs generate` succeeded at 21:29:51.089954 after 1.44 seconds
[0m21:29:51.090955 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m21:29:51.090955 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m21:29:51.091954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F526F8B740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5282336B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5284986E0>]}
[0m21:29:51.091954 [debug] [MainThread]: Flushing usage events
[0m21:34:36.714260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C1ABF770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C3D5A780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C3D5BBF0>]}


============================== 21:34:36.718262 | bedbfef7-cc89-483d-90b4-526e20d91215 ==============================
[0m21:34:36.718262 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:34:36.719263 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:34:36.930375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bedbfef7-cc89-483d-90b4-526e20d91215', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C0BECC20>]}
[0m21:34:36.984375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bedbfef7-cc89-483d-90b4-526e20d91215', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C41BF440>]}
[0m21:35:31.458703 [error] [MainThread]: Encountered an error:

[0m21:35:31.494705 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Users\RickyS-PC\miniconda3\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m21:35:31.497704 [debug] [MainThread]: Command `dbt docs serve` failed at 21:35:31.497704 after 54.90 seconds
[0m21:35:31.498705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C1ABF770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C46DF920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2C4981910>]}
[0m21:35:31.499705 [debug] [MainThread]: Flushing usage events
[0m21:55:54.203316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCAE25220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BC8C3B9B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCB641BE0>]}


============================== 21:55:54.210316 | f9ecfb13-4c77-486c-9b63-65c10de37d78 ==============================
[0m21:55:54.210316 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:55:54.212317 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:55:54.447410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9ecfb13-4c77-486c-9b63-65c10de37d78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCB2703B0>]}
[0m21:55:54.499411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9ecfb13-4c77-486c-9b63-65c10de37d78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCA7E8CB0>]}
[0m22:11:49.509637 [error] [MainThread]: Encountered an error:

[0m22:11:49.516638 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Users\RickyS-PC\miniconda3\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m22:11:49.520639 [debug] [MainThread]: Command `dbt docs serve` failed at 22:11:49.520639 after 955.44 seconds
[0m22:11:49.521639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCAE25220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCBA24E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000010BCB88F4D0>]}
[0m22:11:49.522640 [debug] [MainThread]: Flushing usage events
[0m14:52:26.200951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9BA650350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9B6D26A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9B9B9B5C0>]}


============================== 14:52:26.208269 | 1ec7ed92-88af-44d7-ba19-18f562f779dd ==============================
[0m14:52:26.208269 [info ] [MainThread]: Running with dbt=1.8.5
[0m14:52:26.209270 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:52:26.469768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ec7ed92-88af-44d7-ba19-18f562f779dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9BA4AF6E0>]}
[0m14:52:26.531420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ec7ed92-88af-44d7-ba19-18f562f779dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9BA86C500>]}
[0m14:53:21.552673 [error] [MainThread]: Encountered an error:

[0m14:53:21.584894 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Users\RickyS-PC\miniconda3\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m14:53:21.588894 [debug] [MainThread]: Command `dbt docs serve` failed at 14:53:21.588894 after 55.53 seconds
[0m14:53:21.589895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9B9F5AC60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9BAA96FC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A9BA9C20C0>]}
[0m14:53:21.589895 [debug] [MainThread]: Flushing usage events
[0m15:37:00.965231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4C40CF50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F48ADCD40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4C40D730>]}


============================== 15:37:00.971635 | d1d461a6-ae60-45e9-8fd3-315cee6bdc22 ==============================
[0m15:37:00.971635 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:37:00.972649 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:37:00.996999 [info ] [MainThread]: dbt version: 1.8.5
[0m15:37:00.997998 [info ] [MainThread]: python version: 3.12.4
[0m15:37:00.997998 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m15:37:00.998997 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m15:37:01.110971 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m15:37:01.111971 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m15:37:01.112972 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m15:37:01.114973 [info ] [MainThread]: adapter type: postgres
[0m15:37:01.114973 [info ] [MainThread]: adapter version: 1.8.2
[0m15:37:01.201968 [info ] [MainThread]: Configuration:
[0m15:37:01.201968 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:37:01.202970 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:37:01.203968 [info ] [MainThread]: Required dependencies:
[0m15:37:01.203968 [debug] [MainThread]: Executing "git --help"
[0m15:37:01.238971 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:37:01.238971 [debug] [MainThread]: STDERR: "b''"
[0m15:37:01.239968 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:37:01.240968 [info ] [MainThread]: Connection:
[0m15:37:01.241971 [info ] [MainThread]:   host: localhost
[0m15:37:01.241971 [info ] [MainThread]:   port: 5433
[0m15:37:01.242969 [info ] [MainThread]:   user: postgres
[0m15:37:01.242969 [info ] [MainThread]:   database: data_warehouse
[0m15:37:01.243967 [info ] [MainThread]:   schema: dbt_dev
[0m15:37:01.243967 [info ] [MainThread]:   connect_timeout: 10
[0m15:37:01.244972 [info ] [MainThread]:   role: None
[0m15:37:01.244972 [info ] [MainThread]:   search_path: None
[0m15:37:01.245970 [info ] [MainThread]:   keepalives_idle: 0
[0m15:37:01.246968 [info ] [MainThread]:   sslmode: None
[0m15:37:01.246968 [info ] [MainThread]:   sslcert: None
[0m15:37:01.247968 [info ] [MainThread]:   sslkey: None
[0m15:37:01.247968 [info ] [MainThread]:   sslrootcert: None
[0m15:37:01.248968 [info ] [MainThread]:   application_name: dbt
[0m15:37:01.248968 [info ] [MainThread]:   retries: 1
[0m15:37:01.249969 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:37:01.250969 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m15:37:03.063141 [debug] [MainThread]: Using postgres connection "debug"
[0m15:37:03.064140 [debug] [MainThread]: On debug: select 1 as id
[0m15:37:03.064140 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:37:03.084139 [debug] [MainThread]: SQL status: SELECT 1 in 0.020 seconds
[0m15:37:03.085138 [debug] [MainThread]: On debug: Close
[0m15:37:03.086139 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:37:03.086139 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:37:03.088140 [debug] [MainThread]: Command `dbt debug` succeeded at 15:37:03.088140 after 2.25 seconds
[0m15:37:03.088140 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m15:37:03.089140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F48ADCD40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4C3B2BA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4C4DEE40>]}
[0m15:37:03.089140 [debug] [MainThread]: Flushing usage events
[0m15:37:16.176742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218D9F7D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218D9F7C860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DC721310>]}


============================== 15:37:16.181742 | 538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe ==============================
[0m15:37:16.181742 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:37:16.181742 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:37:16.383690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DC87D6A0>]}
[0m15:37:16.435262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DC515AC0>]}
[0m15:37:16.436265 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:37:16.456262 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:37:17.246868 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:37:17.247868 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\best_selling_film.sql
[0m15:37:17.493462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DDEBB830>]}
[0m15:37:17.605462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DDF040B0>]}
[0m15:37:17.605462 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:37:17.606462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DDE41D60>]}
[0m15:37:17.609463 [info ] [MainThread]: 
[0m15:37:17.610462 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:37:17.614463 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m15:37:17.684034 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:17.684034 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:17.685034 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:17.694034 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m15:37:17.695034 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:17.697035 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:17.698035 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:17.698035 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.705827 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:37:17.707385 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:17.709467 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:17.710056 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:17.710577 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.716921 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:37:17.718478 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:17.720569 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:17.721098 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:17.721619 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.728394 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:37:17.729448 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:17.732106 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m15:37:17.738349 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:37:17.738367 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:37:17.738899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:17.745597 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m15:37:17.745597 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:37:17.746596 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:37:17.753597 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m15:37:17.754601 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:37:17.755601 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:37:17.756601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m15:37:17.761203 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:37:17.761724 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:37:17.761735 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.768641 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m15:37:17.769177 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:37:17.769705 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:37:17.772226 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:37:17.774223 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:37:17.775222 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:37:17.775222 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_raw)
[0m15:37:17.779348 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:37:17.779876 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:37:17.780404 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.787246 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m15:37:17.787767 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:37:17.788294 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:37:17.790332 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:37:17.792336 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:37:17.793335 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:37:17.794334 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m15:37:17.797660 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:37:17.798189 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:37:17.798189 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:17.804510 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:37:17.805036 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:37:17.805564 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:37:17.808186 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:37:17.809177 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:37:17.810179 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:37:17.815982 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:17.816506 [debug] [MainThread]: On master: BEGIN
[0m15:37:17.817031 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:37:17.822857 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:37:17.823884 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:17.824448 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:37:17.836445 [debug] [MainThread]: SQL status: SELECT 38 in 0.012 seconds
[0m15:37:17.838444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE15BA70>]}
[0m15:37:17.838444 [debug] [MainThread]: On master: ROLLBACK
[0m15:37:17.839445 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:17.840445 [debug] [MainThread]: On master: BEGIN
[0m15:37:17.841446 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:37:17.841446 [debug] [MainThread]: On master: COMMIT
[0m15:37:17.842449 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:17.842449 [debug] [MainThread]: On master: COMMIT
[0m15:37:17.843449 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:37:17.843449 [debug] [MainThread]: On master: Close
[0m15:37:17.844449 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:37:17.845448 [info ] [MainThread]: 
[0m15:37:17.849711 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:37:17.850238 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m15:37:17.851284 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:37:17.851810 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:37:17.859171 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:37:17.860232 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:37:17.896800 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m15:37:17.897799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.898799 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m15:37:17.898799 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:37:17.905800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:17.906800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.906800 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m15:37:17.920800 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.013 seconds
[0m15:37:17.926800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.927800 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m15:37:17.929799 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m15:37:17.932801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.933801 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m15:37:17.934801 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:17.954800 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:37:17.954800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.955802 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:37:17.958799 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:17.964803 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m15:37:17.969802 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:17.970803 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m15:37:17.976800 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m15:37:17.978800 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m15:37:17.979801 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DA2A0EC0>]}
[0m15:37:17.980801 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m15:37:17.982128 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:37:17.983171 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:37:17.983703 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m15:37:17.984231 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:37:17.984762 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:37:17.989472 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:37:17.990533 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:37:17.993145 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m15:37:17.993661 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:17.994659 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m15:37:17.994659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.001659 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.002659 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:18.003660 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m15:37:18.008660 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.005 seconds
[0m15:37:18.011660 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:18.012662 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m15:37:18.013658 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.017662 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:18.017662 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m15:37:18.019659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.021658 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:37:18.022657 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:18.022657 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:37:18.026663 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.028661 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m15:37:18.029662 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:18.029662 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m15:37:18.033659 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.035659 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m15:37:18.035659 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE375220>]}
[0m15:37:18.036660 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m15:37:18.037658 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:37:18.038659 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:37:18.039245 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m15:37:18.040280 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:37:18.040309 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:37:18.043454 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:37:18.044551 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:37:18.047706 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m15:37:18.049276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.049812 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m15:37:18.049812 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.056810 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.057809 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.057809 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m15:37:18.063810 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.005 seconds
[0m15:37:18.067810 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.067810 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m15:37:18.069809 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.072808 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.072808 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m15:37:18.073811 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.075382 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:37:18.076380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.076380 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:37:18.079377 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:37:18.082380 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m15:37:18.083380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:18.084382 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m15:37:18.088380 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.090381 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m15:37:18.090381 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE324A10>]}
[0m15:37:18.091380 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m15:37:18.092379 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:37:18.093417 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:37:18.093949 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m15:37:18.095014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:37:18.095544 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:37:18.098172 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:37:18.099228 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:37:18.104507 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m15:37:18.106506 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.106506 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m15:37:18.107505 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.113505 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.114504 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.114504 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m15:37:18.129505 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.014 seconds
[0m15:37:18.132504 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.133507 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m15:37:18.135506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.138506 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.138506 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m15:37:18.140504 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.141505 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:37:18.142503 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.142503 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:37:18.146504 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.148504 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m15:37:18.149506 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:18.150508 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m15:37:18.155506 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m15:37:18.157505 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m15:37:18.157505 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE70FE30>]}
[0m15:37:18.158505 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m15:37:18.159503 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:37:18.160310 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:37:18.160837 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m15:37:18.161892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:37:18.162419 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:37:18.165047 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:37:18.166108 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:37:18.169791 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m15:37:18.170832 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.171360 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m15:37:18.171877 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.177876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.177876 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.178873 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m15:37:18.185875 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.006 seconds
[0m15:37:18.188875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.189874 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m15:37:18.190875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.193876 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.194878 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m15:37:18.195876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.197875 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:37:18.197875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.198873 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:37:18.202874 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.205875 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m15:37:18.206874 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:18.207874 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m15:37:18.211876 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.212878 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m15:37:18.213878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE2AE4B0>]}
[0m15:37:18.214875 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m15:37:18.215879 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:37:18.216984 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:37:18.217516 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m15:37:18.218589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:37:18.219655 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:37:18.222806 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:37:18.223855 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:37:18.227018 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m15:37:18.227540 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.228540 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m15:37:18.228540 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.235537 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.236537 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.236537 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m15:37:18.243535 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.006 seconds
[0m15:37:18.252536 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.253537 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m15:37:18.255538 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.260539 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.261538 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m15:37:18.262538 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.264535 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:37:18.264535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.265537 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:37:18.269537 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.271537 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m15:37:18.272536 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:18.273536 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m15:37:18.277537 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:18.278535 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m15:37:18.279537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE3BD460>]}
[0m15:37:18.280538 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m15:37:18.281536 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:37:18.282286 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:37:18.283345 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m15:37:18.283872 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:37:18.284400 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:37:18.287564 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.288079 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:37:18.291821 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.292874 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.293392 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m15:37:18.293392 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.300392 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.301393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.302390 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m15:37:18.303390 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m15:37:18.307393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.307393 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m15:37:18.308391 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.311389 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.311389 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m15:37:18.312391 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.314391 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:37:18.315389 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.315389 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:37:18.318391 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:37:18.321393 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m15:37:18.322394 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:18.322394 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m15:37:18.329391 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m15:37:18.330389 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m15:37:18.331391 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE374650>]}
[0m15:37:18.331391 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m15:37:18.333390 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:37:18.334512 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:37:18.335041 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m15:37:18.336071 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:37:18.336119 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:37:18.339238 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:37:18.340292 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:37:18.343453 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m15:37:18.344493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.345025 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m15:37:18.345025 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.351540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.351540 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.352538 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m15:37:18.363539 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.011 seconds
[0m15:37:18.367539 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.367539 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m15:37:18.369539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.372538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.372538 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m15:37:18.373539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.375541 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:37:18.375541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.376542 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:37:18.380537 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:18.384540 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m15:37:18.385544 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:18.386542 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m15:37:18.390541 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.391539 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m15:37:18.392538 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE702C00>]}
[0m15:37:18.393540 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m15:37:18.394541 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:37:18.395211 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:37:18.395740 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m15:37:18.396263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:37:18.396788 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:37:18.402056 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:37:18.403120 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:37:18.406282 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m15:37:18.406794 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.407791 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m15:37:18.407791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.413792 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.414795 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.415792 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m15:37:18.429805 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.014 seconds
[0m15:37:18.432805 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.433807 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m15:37:18.434806 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.437804 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.438804 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m15:37:18.439804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.441804 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:37:18.441804 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.442804 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:37:18.446805 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:18.449805 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m15:37:18.450807 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:18.450807 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m15:37:18.454806 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.455806 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m15:37:18.456805 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE263D10>]}
[0m15:37:18.457805 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m15:37:18.458806 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:37:18.459934 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:37:18.460491 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m15:37:18.461020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:37:18.461548 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:37:18.464684 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:37:18.465738 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:37:18.468895 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m15:37:18.469945 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.470460 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m15:37:18.470460 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.476457 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.477460 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.477460 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m15:37:18.485461 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m15:37:18.488459 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.489460 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m15:37:18.490460 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.493572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.493572 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m15:37:18.494561 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.496561 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:37:18.496561 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.497561 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:37:18.500558 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.503562 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m15:37:18.504563 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:18.504563 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m15:37:18.508560 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:18.510558 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m15:37:18.511559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE3234D0>]}
[0m15:37:18.512559 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m15:37:18.513559 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:37:18.513982 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:37:18.514515 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m15:37:18.515573 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:37:18.516095 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:37:18.519274 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:37:18.520335 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:37:18.525118 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m15:37:18.526117 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.527117 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m15:37:18.527117 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.534118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.534118 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.535119 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m15:37:18.537120 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:37:18.595701 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.595701 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m15:37:18.597701 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.599701 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.600703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m15:37:18.601702 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.603700 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:37:18.604699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.604699 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:37:18.607700 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:37:18.609700 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m15:37:18.610701 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:18.611700 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m15:37:18.614700 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.616701 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m15:37:18.617701 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE708E60>]}
[0m15:37:18.618702 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m15:37:18.619702 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:37:18.620942 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:37:18.621480 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m15:37:18.622542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:37:18.623049 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:37:18.626251 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:37:18.627302 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:37:18.630491 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m15:37:18.631561 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.632111 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m15:37:18.632111 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.639077 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.640080 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.641077 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m15:37:18.643077 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:37:18.646077 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.646077 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m15:37:18.648154 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.651147 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.652146 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m15:37:18.653145 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.655145 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:37:18.656145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.656145 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:37:18.659146 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.662145 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m15:37:18.663145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:18.663145 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m15:37:18.667147 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.669145 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m15:37:18.670146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE3A5220>]}
[0m15:37:18.671147 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m15:37:18.672146 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:37:18.673364 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:37:18.673897 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m15:37:18.674959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:37:18.675487 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:37:18.678711 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:37:18.680300 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:37:18.684989 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m15:37:18.685992 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.686991 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m15:37:18.686991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.693989 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.693989 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.694989 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m15:37:18.696997 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:37:18.699992 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.700990 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m15:37:18.701990 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.704993 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.705992 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m15:37:18.706990 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.711991 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:37:18.712991 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.712991 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:37:18.716992 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.719990 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m15:37:18.719990 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:18.720990 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m15:37:18.725191 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.726771 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m15:37:18.727813 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE37F410>]}
[0m15:37:18.728348 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m15:37:18.729404 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:37:18.730469 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:37:18.730999 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m15:37:18.731532 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:37:18.732061 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:37:18.736293 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:37:18.737871 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:37:18.741616 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m15:37:18.743202 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.743723 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m15:37:18.744252 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.751122 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.751639 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.752731 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m15:37:18.762221 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m15:37:18.765222 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.765222 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m15:37:18.767221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.770220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.770220 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m15:37:18.772219 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.773220 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:37:18.774218 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.774218 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:37:18.778221 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.780222 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m15:37:18.781223 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:18.782223 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m15:37:18.786221 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:18.787223 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m15:37:18.788223 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE37D730>]}
[0m15:37:18.789221 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m15:37:18.790219 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:37:18.791048 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:37:18.791582 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m15:37:18.792104 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:37:18.792637 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:37:18.795772 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:37:18.796823 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:37:18.799972 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m15:37:18.801070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.802131 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m15:37:18.802131 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.809125 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:18.809125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.810125 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m15:37:18.813124 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:37:18.817128 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.817128 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m15:37:18.819125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.822125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.822125 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m15:37:18.823125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.825126 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:37:18.826124 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.826124 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:37:18.830127 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.832128 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m15:37:18.833129 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:18.834128 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m15:37:18.838128 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:18.840125 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m15:37:18.840125 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE3908F0>]}
[0m15:37:18.841126 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m15:37:18.842126 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:37:18.843390 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:37:18.843917 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m15:37:18.844445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:37:18.844977 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:37:18.851893 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:37:18.853474 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:37:18.857522 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m15:37:18.858525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.859522 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m15:37:18.859522 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.866521 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.866521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.867522 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m15:37:18.871524 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:37:18.874524 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.874524 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m15:37:18.875525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.878525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.879523 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m15:37:18.881525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.884524 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:37:18.885523 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.886524 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:37:18.891522 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:18.895523 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m15:37:18.896523 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:18.897522 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m15:37:18.903525 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m15:37:18.905522 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m15:37:18.906522 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DC85D550>]}
[0m15:37:18.908522 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m15:37:18.910524 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:37:18.911332 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:37:18.912401 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m15:37:18.912930 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:37:18.913456 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:37:18.916629 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.917681 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:37:18.936908 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.938908 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.938908 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m15:37:18.939911 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.945909 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.946911 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.947911 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m15:37:18.952909 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m15:37:18.956909 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.956909 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m15:37:18.958908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:18.959910 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:37:18.960908 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.960908 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:37:18.963908 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:18.966908 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m15:37:18.969907 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:18.970912 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m15:37:18.971909 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:37:18.973908 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m15:37:18.974908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DDDC5B20>]}
[0m15:37:18.974908 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m15:37:18.976908 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:37:18.977259 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:37:18.977776 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m15:37:18.978833 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m15:37:18.979358 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:37:18.981978 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:37:18.983042 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:37:18.986277 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m15:37:18.987337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:18.987858 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m15:37:18.988387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:18.994375 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:18.995376 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:18.995376 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m15:37:19.004377 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m15:37:19.009377 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:19.010379 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m15:37:19.011377 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.014375 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:19.014375 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m15:37:19.015375 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.018378 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:37:19.018378 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:19.019376 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:37:19.023375 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:19.026375 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m15:37:19.027376 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:19.027376 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m15:37:19.031377 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:19.032375 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m15:37:19.033379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE285460>]}
[0m15:37:19.034380 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m15:37:19.035380 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:37:19.036440 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:37:19.036969 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m15:37:19.038022 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:37:19.038552 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:37:19.041169 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:37:19.042240 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:37:19.045408 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m15:37:19.046447 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.046976 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m15:37:19.047496 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.053492 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:19.054492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.055492 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m15:37:19.064493 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:37:19.069493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.070495 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m15:37:19.071493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.075493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.075493 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m15:37:19.076494 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.078493 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:37:19.079492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.079492 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:37:19.084492 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:37:19.087492 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m15:37:19.088491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:19.088491 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m15:37:19.092496 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:19.093492 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m15:37:19.094492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DDDC5EB0>]}
[0m15:37:19.095496 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m15:37:19.096493 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:37:19.097492 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:37:19.097492 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m15:37:19.098492 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:37:19.099492 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:37:19.102493 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:37:19.103492 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:37:19.106492 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m15:37:19.107492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.108492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m15:37:19.108492 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.115493 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:19.116491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.117492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m15:37:19.124493 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m15:37:19.128494 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.129493 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m15:37:19.130494 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.134492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.135492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m15:37:19.136494 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.138492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:37:19.138492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.139492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:37:19.142492 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:19.147490 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m15:37:19.148492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:19.148492 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m15:37:19.152491 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:19.154491 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m15:37:19.155491 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE7355E0>]}
[0m15:37:19.156495 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m15:37:19.157494 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:37:19.158493 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:37:19.159492 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m15:37:19.159492 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m15:37:19.160492 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:37:19.164493 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:37:19.165491 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:37:19.168492 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m15:37:19.169491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:37:19.170493 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m15:37:19.170493 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.176492 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:19.177492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:37:19.178493 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    MAX(fct_pay.amount)
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY film_id
  );
  
[0m15:37:19.180492 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column reference "film_id" is ambiguous
LINE 25: GROUP BY film_id
                  ^

[0m15:37:19.181492 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: ROLLBACK
[0m15:37:19.182492 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m15:37:19.262991 [debug] [Thread-1 (]: Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column reference "film_id" is ambiguous
  LINE 25: GROUP BY film_id
                    ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:37:19.263990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DE72B3B0>]}
[0m15:37:19.264991 [error] [Thread-1 (]: 21 of 22 ERROR creating sql table model dbt_dev_mart.best_selling_film ......... [[31mERROR[0m in 0.10s]
[0m15:37:19.265988 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:37:19.266988 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:37:19.267988 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m15:37:19.268988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:37:19.268988 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:37:19.271987 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:37:19.272991 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:37:19.276990 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m15:37:19.277991 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.278991 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m15:37:19.278991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.284988 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:19.285990 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.285990 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m15:37:19.309989 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.022 seconds
[0m15:37:19.312509 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.313509 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m15:37:19.314508 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.317102 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.318103 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m15:37:19.320101 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:19.322101 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:37:19.322101 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.322101 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:37:19.327100 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:19.329103 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m15:37:19.330105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:19.330105 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m15:37:19.334100 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:19.336101 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m15:37:19.337100 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '538a4b2b-9791-4df1-9a4f-6b5e7a7fbdfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DC471610>]}
[0m15:37:19.338104 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m15:37:19.339100 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:37:19.340517 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:19.341045 [debug] [MainThread]: On master: BEGIN
[0m15:37:19.341574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:37:19.347417 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:37:19.347942 [debug] [MainThread]: On master: COMMIT
[0m15:37:19.348476 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:19.349012 [debug] [MainThread]: On master: COMMIT
[0m15:37:19.350096 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:37:19.350631 [debug] [MainThread]: On master: Close
[0m15:37:19.351162 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:37:19.351689 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m15:37:19.352223 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m15:37:19.352753 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:37:19.353286 [info ] [MainThread]: 
[0m15:37:19.353819 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m15:37:19.358072 [debug] [MainThread]: Command end result
[0m15:37:19.389971 [info ] [MainThread]: 
[0m15:37:19.390971 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:37:19.391969 [info ] [MainThread]: 
[0m15:37:19.392970 [error] [MainThread]:   Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column reference "film_id" is ambiguous
  LINE 25: GROUP BY film_id
                    ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:37:19.393969 [info ] [MainThread]: 
[0m15:37:19.393969 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m15:37:19.394969 [debug] [MainThread]: Command `dbt run` failed at 15:37:19.394969 after 3.31 seconds
[0m15:37:19.395972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DCD87620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DCD402F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218DBF8C5C0>]}
[0m15:37:21.210422 [debug] [MainThread]: Flushing usage events
[0m15:37:53.131458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C4369430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C798DEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7BC5490>]}


============================== 15:37:53.136459 | 5924953f-d593-4c8d-9626-114583ec40ef ==============================
[0m15:37:53.136459 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:37:53.137460 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:37:53.330582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7D65E20>]}
[0m15:37:53.382148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7E10D10>]}
[0m15:37:53.384146 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:37:53.396147 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:37:53.561288 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:37:53.561288 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m15:37:53.785404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C92BB380>]}
[0m15:37:53.884404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C92D27E0>]}
[0m15:37:53.885405 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:37:53.885405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C90EB260>]}
[0m15:37:53.889018 [info ] [MainThread]: 
[0m15:37:53.889018 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:37:53.894017 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m15:37:53.963017 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:53.964016 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:53.964016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:53.976016 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.011 seconds
[0m15:37:53.977017 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:53.980132 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:53.980709 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:53.981240 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:53.987580 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:37:53.989128 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:53.991236 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:53.992128 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:53.992650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:53.998983 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:37:54.000515 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:54.002640 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:37:54.003702 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:37:54.003702 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:54.009990 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:37:54.011600 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:37:54.014614 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m15:37:54.020379 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:37:54.020903 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:37:54.021425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:54.027164 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.027164 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:37:54.028163 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:37:54.031163 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:37:54.032163 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:37:54.033163 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:37:54.034163 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_mart)
[0m15:37:54.039043 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:37:54.039563 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:37:54.040106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:54.046420 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.046944 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:37:54.047462 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:37:54.049978 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.002 seconds
[0m15:37:54.050978 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:37:54.051979 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:37:54.052978 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m15:37:54.056131 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:37:54.056131 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:37:54.056657 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:54.063007 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.063532 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:37:54.064060 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:37:54.066668 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:37:54.068664 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:37:54.069666 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:37:54.070665 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m15:37:54.075054 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:37:54.075577 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:37:54.076100 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:54.081864 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.082383 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:37:54.082901 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:37:54.086457 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:37:54.087645 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:37:54.088725 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:37:54.095027 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:54.095561 [debug] [MainThread]: On master: BEGIN
[0m15:37:54.096088 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:37:54.102417 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m15:37:54.103445 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:54.104012 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:37:54.111831 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m15:37:54.114500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C971CCB0>]}
[0m15:37:54.115028 [debug] [MainThread]: On master: ROLLBACK
[0m15:37:54.116075 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:54.116589 [debug] [MainThread]: On master: BEGIN
[0m15:37:54.118169 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:37:54.118739 [debug] [MainThread]: On master: COMMIT
[0m15:37:54.119259 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:54.119781 [debug] [MainThread]: On master: COMMIT
[0m15:37:54.120818 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:37:54.120836 [debug] [MainThread]: On master: Close
[0m15:37:54.121889 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:37:54.122436 [info ] [MainThread]: 
[0m15:37:54.125584 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:37:54.126636 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m15:37:54.127159 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:37:54.127682 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:37:54.135028 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:37:54.136543 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:37:54.176085 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m15:37:54.177085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.178085 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m15:37:54.178085 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:37:54.184086 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.185085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.186085 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m15:37:54.188084 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:37:54.194085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.194085 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m15:37:54.196085 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.198085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.199085 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m15:37:54.200086 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.219085 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:37:54.220085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.220085 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:37:54.223084 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.229084 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m15:37:54.234084 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:37:54.235086 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m15:37:54.238084 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.240084 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m15:37:54.242086 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C5740E60>]}
[0m15:37:54.243086 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.11s]
[0m15:37:54.244277 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:37:54.244802 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:37:54.245330 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m15:37:54.246375 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:37:54.246896 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:37:54.251575 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:37:54.252621 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:37:54.255219 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m15:37:54.256218 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.256218 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m15:37:54.257218 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.263219 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:54.264218 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.265218 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m15:37:54.268220 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:37:54.271218 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.272218 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m15:37:54.273221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.276220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.276220 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m15:37:54.277219 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.279219 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:37:54.280219 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.280219 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:37:54.283218 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.287220 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m15:37:54.287220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:37:54.288219 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m15:37:54.292218 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.294219 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m15:37:54.294219 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C97A4680>]}
[0m15:37:54.295220 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m15:37:54.296219 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:37:54.297164 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:37:54.298215 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m15:37:54.298748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:37:54.299262 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:37:54.302936 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:37:54.303978 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:37:54.307669 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m15:37:54.308182 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.308694 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m15:37:54.308694 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.314694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.315694 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.315694 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m15:37:54.318696 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:37:54.322696 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.322696 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m15:37:54.324695 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.327695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.327695 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m15:37:54.328694 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.330695 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:37:54.330695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.331697 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:37:54.334695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.336696 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m15:37:54.338696 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:37:54.338696 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m15:37:54.342695 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.343696 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m15:37:54.344695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C977C680>]}
[0m15:37:54.345697 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m15:37:54.346698 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:37:54.347405 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:37:54.347933 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m15:37:54.348972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:37:54.349489 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:37:54.352115 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:37:54.353726 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:37:54.358413 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m15:37:54.358929 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.359927 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m15:37:54.359927 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.365926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.366926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.366926 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m15:37:54.375928 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:37:54.379926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.379926 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m15:37:54.380925 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.383927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.383927 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m15:37:54.386927 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.388926 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:37:54.388926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.389927 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:37:54.394925 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:37:54.397926 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m15:37:54.398927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:37:54.398927 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m15:37:54.403928 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:54.405927 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m15:37:54.406926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C97B6420>]}
[0m15:37:54.407928 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m15:37:54.408928 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:37:54.408928 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:37:54.409926 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m15:37:54.410926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:37:54.410926 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:37:54.413926 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:37:54.414926 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:37:54.418927 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m15:37:54.419926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.419926 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m15:37:54.420927 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.426926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.427927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.427927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m15:37:54.431927 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:37:54.434926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.435927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m15:37:54.436925 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.439926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.439926 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m15:37:54.440927 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.442927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:37:54.443927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.443927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:37:54.449927 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:37:54.452927 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m15:37:54.453926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:37:54.453926 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m15:37:54.458927 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:54.459927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m15:37:54.460925 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9724860>]}
[0m15:37:54.461926 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m15:37:54.462927 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:37:54.463356 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:37:54.464410 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m15:37:54.464928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:37:54.465457 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:37:54.468613 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:37:54.469656 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:37:54.473286 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m15:37:54.474335 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.474335 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m15:37:54.474858 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.480851 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.481852 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.481852 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m15:37:54.485853 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:37:54.488852 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.489852 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m15:37:54.490851 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.495852 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.495852 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m15:37:54.497852 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.498853 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:37:54.499852 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.499852 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:37:54.503851 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.506852 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m15:37:54.507852 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:37:54.507852 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m15:37:54.510851 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.512853 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m15:37:54.513852 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B1B290>]}
[0m15:37:54.513852 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m15:37:54.514853 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:37:54.516045 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:37:54.517098 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m15:37:54.517626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:37:54.518157 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:37:54.521291 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.522322 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:37:54.525518 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.526557 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.527081 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m15:37:54.527596 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.533594 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.533594 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.534594 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m15:37:54.536598 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m15:37:54.539595 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.540594 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m15:37:54.541595 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.544593 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.545596 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m15:37:54.546594 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.547594 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:37:54.548593 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.548593 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:37:54.552594 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.554593 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m15:37:54.555594 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:37:54.556594 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m15:37:54.560595 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:54.561595 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m15:37:54.562595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B01D60>]}
[0m15:37:54.563595 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.04s]
[0m15:37:54.564596 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:37:54.565241 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:37:54.565772 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m15:37:54.566815 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:37:54.567342 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:37:54.571063 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:37:54.572104 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:37:54.575220 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m15:37:54.576281 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.576802 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m15:37:54.576802 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.582799 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.583798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.583798 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m15:37:54.591797 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m15:37:54.595798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.595798 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m15:37:54.596798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.599798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.599798 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m15:37:54.601798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.603799 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:37:54.603799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.604799 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:37:54.607799 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:37:54.609799 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m15:37:54.610799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:37:54.610799 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m15:37:54.614799 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.615798 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m15:37:54.616799 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C971CDD0>]}
[0m15:37:54.617800 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.05s]
[0m15:37:54.619800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:37:54.619800 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:37:54.620798 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m15:37:54.621799 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:37:54.621799 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:37:54.626798 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:37:54.627799 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:37:54.630799 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m15:37:54.631798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.631798 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m15:37:54.632799 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.638798 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:54.639798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.640798 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m15:37:54.649800 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:37:54.653799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.653799 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m15:37:54.655798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.657799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.658799 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m15:37:54.659799 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.661798 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:37:54.661798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.661798 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:37:54.666797 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:54.669799 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m15:37:54.670799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:37:54.670799 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m15:37:54.674798 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:54.676799 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m15:37:54.676799 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C97B71A0>]}
[0m15:37:54.677799 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m15:37:54.678799 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:37:54.679797 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:37:54.679797 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m15:37:54.680798 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:37:54.681798 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:37:54.684798 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:37:54.685799 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:37:54.688798 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m15:37:54.689797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.689797 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m15:37:54.690799 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.696798 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.697799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.697799 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m15:37:54.704800 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m15:37:54.707799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.708799 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m15:37:54.709798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.712801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.712801 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m15:37:54.714798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.715799 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:37:54.716799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.716799 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:37:54.719798 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.722798 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m15:37:54.723799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:37:54.723799 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m15:37:54.727798 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.728799 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m15:37:54.729799 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9727560>]}
[0m15:37:54.730799 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m15:37:54.731799 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:37:54.732220 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:37:54.732754 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m15:37:54.733814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:37:54.734348 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:37:54.737471 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:37:54.738519 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:37:54.743287 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m15:37:54.743804 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.744803 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m15:37:54.744803 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.750804 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.751805 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.752803 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m15:37:54.754801 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:37:54.812358 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.813359 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m15:37:54.814359 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.817361 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.818361 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m15:37:54.819361 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.821360 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:37:54.822360 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.822360 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:37:54.825358 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.827360 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m15:37:54.828360 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:37:54.828360 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m15:37:54.832359 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.833359 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m15:37:54.834359 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9782930>]}
[0m15:37:54.835361 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m15:37:54.837232 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:37:54.837755 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:37:54.838278 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m15:37:54.839322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:37:54.839845 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:37:54.842441 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:37:54.843491 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:37:54.846624 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m15:37:54.847140 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.847672 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m15:37:54.848204 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.854719 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:54.855718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.855718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m15:37:54.858717 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m15:37:54.862717 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.862717 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m15:37:54.864717 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.866718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.867718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m15:37:54.869719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.871718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:37:54.872718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.872718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:37:54.876717 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.878718 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m15:37:54.879718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:37:54.880718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m15:37:54.884719 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:54.886718 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m15:37:54.887717 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7F84AA0>]}
[0m15:37:54.888719 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m15:37:54.889719 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:37:54.889719 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:37:54.890718 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m15:37:54.891719 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:37:54.891719 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:37:54.894717 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:37:54.895716 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:37:54.899718 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m15:37:54.901722 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.902721 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m15:37:54.903718 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.920717 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m15:37:54.920717 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.921716 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m15:37:54.924717 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:37:54.927717 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.927717 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m15:37:54.929716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.932720 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.932720 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m15:37:54.934718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.938718 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:37:54.938718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.939718 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:37:54.943717 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:54.945716 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m15:37:54.946717 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:37:54.947716 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m15:37:54.950718 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:54.952718 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m15:37:54.953718 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B15FA0>]}
[0m15:37:54.954718 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m15:37:54.955716 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:37:54.956408 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:37:54.957476 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m15:37:54.958003 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:37:54.958533 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:37:54.961740 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:37:54.962800 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:37:54.966994 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m15:37:54.968511 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:54.968511 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m15:37:54.969512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:54.975513 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:54.975513 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:54.976509 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m15:37:54.984512 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:37:54.988510 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:54.988510 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m15:37:54.990510 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.993511 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:54.993511 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m15:37:54.995512 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:54.997511 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:37:54.998511 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:54.998511 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:37:55.003510 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:37:55.006510 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m15:37:55.007511 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:37:55.008512 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m15:37:55.013510 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:55.014512 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m15:37:55.015510 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B14680>]}
[0m15:37:55.016511 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m15:37:55.017511 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:37:55.018996 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:37:55.019512 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m15:37:55.020592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:37:55.021112 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:37:55.024282 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:37:55.025329 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:37:55.029003 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m15:37:55.030057 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.031040 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m15:37:55.031040 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.059041 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m15:37:55.059041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.060042 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m15:37:55.064042 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:37:55.067041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.067041 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m15:37:55.069044 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.072042 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.072042 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m15:37:55.073042 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.075042 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:37:55.076041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.076041 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:37:55.080042 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:55.082042 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m15:37:55.083042 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:37:55.083042 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m15:37:55.087125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:55.088126 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m15:37:55.089126 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C809B680>]}
[0m15:37:55.090123 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.07s]
[0m15:37:55.091121 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:37:55.091121 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:37:55.092318 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m15:37:55.092845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:37:55.093382 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:37:55.098116 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:37:55.099174 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:37:55.102910 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m15:37:55.103910 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.103910 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m15:37:55.104910 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.110907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.110907 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.111909 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m15:37:55.114907 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:37:55.118908 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.119907 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m15:37:55.120906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.123905 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.123905 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m15:37:55.124908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.126906 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:37:55.127906 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.127906 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:37:55.131908 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:55.134910 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m15:37:55.135911 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:37:55.135911 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m15:37:55.139909 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:55.141910 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m15:37:55.141910 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C928C1A0>]}
[0m15:37:55.142908 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m15:37:55.143906 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:37:55.144988 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:37:55.145518 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m15:37:55.146570 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:37:55.147104 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:37:55.149779 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.151370 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:37:55.171303 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.172302 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.172302 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m15:37:55.173304 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.178304 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.179303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.179994 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m15:37:55.181987 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m15:37:55.184989 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.185988 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m15:37:55.186985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.188989 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:37:55.189988 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.189988 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:37:55.192986 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:37:55.194988 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m15:37:55.197989 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:37:55.198989 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m15:37:55.199985 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:37:55.200985 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m15:37:55.201985 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7E3E090>]}
[0m15:37:55.202986 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m15:37:55.203988 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:37:55.205329 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:37:55.205856 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m15:37:55.206385 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m15:37:55.206913 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:37:55.209526 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:37:55.210625 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:37:55.213804 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m15:37:55.214861 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.215391 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m15:37:55.215906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.221904 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:55.222903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.222903 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m15:37:55.230903 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m15:37:55.236907 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.236907 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m15:37:55.238904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.240903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.241904 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m15:37:55.242904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.244903 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:37:55.244903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.245904 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:37:55.250904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:55.253906 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m15:37:55.254908 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:37:55.254908 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m15:37:55.258906 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:55.260908 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m15:37:55.261905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B0EE10>]}
[0m15:37:55.261905 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.05s]
[0m15:37:55.262905 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:37:55.263971 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:37:55.265002 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m15:37:55.265557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:37:55.266091 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:37:55.269808 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:37:55.270867 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:37:55.274119 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m15:37:55.275171 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.275171 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m15:37:55.276171 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.282167 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.282167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.283167 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m15:37:55.292168 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:37:55.295167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.296167 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m15:37:55.297170 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.299166 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.300166 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m15:37:55.301169 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.303169 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:37:55.304167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.304167 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:37:55.309167 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:37:55.312166 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m15:37:55.313167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:37:55.313167 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m15:37:55.317172 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:55.319171 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m15:37:55.320168 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7E139E0>]}
[0m15:37:55.320168 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.05s]
[0m15:37:55.321169 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:37:55.322616 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:37:55.323147 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m15:37:55.323673 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:37:55.324205 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:37:55.327365 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:37:55.327896 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:37:55.331087 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m15:37:55.332145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.332679 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m15:37:55.333201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.339718 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:37:55.339718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.340727 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m15:37:55.347720 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m15:37:55.351718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.351718 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m15:37:55.353719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.356718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.356718 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m15:37:55.357719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.359718 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:37:55.359718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.360718 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:37:55.363718 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:37:55.368721 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m15:37:55.369717 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:37:55.369717 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m15:37:55.373717 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:37:55.375718 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m15:37:55.376717 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9741D60>]}
[0m15:37:55.376717 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m15:37:55.377719 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:37:55.378977 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:37:55.379496 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m15:37:55.380024 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m15:37:55.380558 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:37:55.384906 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:37:55.385945 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:37:55.389065 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m15:37:55.390101 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:37:55.390101 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m15:37:55.391100 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.397100 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.398101 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:37:55.398101 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    MAX(fct_pay.amount)
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id
  );
  
[0m15:37:55.400099 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "dim_fm.title" must appear in the GROUP BY clause or be used in an aggregate function
LINE 16:     dim_fm.title,
             ^

[0m15:37:55.402101 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: ROLLBACK
[0m15:37:55.404101 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m15:37:55.409562 [debug] [Thread-1 (]: Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column "dim_fm.title" must appear in the GROUP BY clause or be used in an aggregate function
  LINE 16:     dim_fm.title,
               ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:37:55.410081 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B3D5E0>]}
[0m15:37:55.410616 [error] [Thread-1 (]: 21 of 22 ERROR creating sql table model dbt_dev_mart.best_selling_film ......... [[31mERROR[0m in 0.03s]
[0m15:37:55.412199 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:37:55.412758 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:37:55.413811 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m15:37:55.414335 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:37:55.415375 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:37:55.417975 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:37:55.418971 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:37:55.421970 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m15:37:55.422972 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.423970 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m15:37:55.423970 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:55.430971 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.430971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.431969 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m15:37:55.452972 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.021 seconds
[0m15:37:55.456970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.456970 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m15:37:55.457970 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.460971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.461970 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m15:37:55.462971 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:37:55.464973 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:37:55.464973 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.464973 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:37:55.470972 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:37:55.472972 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m15:37:55.473973 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:37:55.474970 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m15:37:55.477973 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:37:55.479995 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m15:37:55.480987 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5924953f-d593-4c8d-9626-114583ec40ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C91FAD50>]}
[0m15:37:55.480987 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m15:37:55.481986 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:37:55.483865 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:55.484388 [debug] [MainThread]: On master: BEGIN
[0m15:37:55.484912 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:37:55.490751 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:37:55.491279 [debug] [MainThread]: On master: COMMIT
[0m15:37:55.491808 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:55.492850 [debug] [MainThread]: On master: COMMIT
[0m15:37:55.493915 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:37:55.494433 [debug] [MainThread]: On master: Close
[0m15:37:55.494433 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:37:55.495430 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m15:37:55.495430 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m15:37:55.496429 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:37:55.496429 [info ] [MainThread]: 
[0m15:37:55.497412 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.61 seconds (1.61s).
[0m15:37:55.501632 [debug] [MainThread]: Command end result
[0m15:37:55.532480 [info ] [MainThread]: 
[0m15:37:55.533481 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:37:55.534484 [info ] [MainThread]: 
[0m15:37:55.535481 [error] [MainThread]:   Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column "dim_fm.title" must appear in the GROUP BY clause or be used in an aggregate function
  LINE 16:     dim_fm.title,
               ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:37:55.536483 [info ] [MainThread]: 
[0m15:37:55.536483 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m15:37:55.538481 [debug] [MainThread]: Command `dbt run` failed at 15:37:55.538481 after 2.50 seconds
[0m15:37:55.538481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C7BF1D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B23A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C9B23DA0>]}
[0m15:37:56.796623 [debug] [MainThread]: Flushing usage events
[0m15:38:28.853098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E095DCF0E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E097211430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E099726FF0>]}


============================== 15:38:28.857096 | f1f11d24-505b-4315-af80-ea8cd074465a ==============================
[0m15:38:28.857096 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:38:28.858097 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:38:29.049196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09A429BE0>]}
[0m15:38:29.101195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09A34EF30>]}
[0m15:38:29.102195 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:38:29.110197 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:38:29.270766 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:38:29.271766 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m15:38:29.516163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B7EB740>]}
[0m15:38:29.618820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B8300B0>]}
[0m15:38:29.618820 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:38:29.619819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09A56DCD0>]}
[0m15:38:29.622817 [info ] [MainThread]: 
[0m15:38:29.623817 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:38:29.627817 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m15:38:29.697263 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:38:29.697794 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:38:29.698327 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:29.708642 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.010 seconds
[0m15:38:29.709642 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:38:29.712644 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:38:29.713716 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:38:29.713716 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.720565 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:38:29.722142 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:38:29.725227 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:38:29.725747 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:38:29.726271 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.732607 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:38:29.734197 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:38:29.737312 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:38:29.738135 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:38:29.738666 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.745036 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:38:29.746086 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:38:29.749234 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m15:38:29.755063 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:38:29.755591 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:38:29.756128 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:29.761371 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.762373 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:38:29.762373 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:38:29.765373 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.002 seconds
[0m15:38:29.766373 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:38:29.767373 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:38:29.768370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m15:38:29.773224 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:38:29.774283 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:38:29.774283 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.780578 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.781102 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:38:29.781632 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:38:29.784190 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:38:29.785189 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:38:29.786190 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:38:29.787192 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_intermediete)
[0m15:38:29.791502 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:38:29.792032 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:38:29.792032 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.798342 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.798872 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:38:29.799400 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:38:29.801968 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m15:38:29.803971 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:38:29.804969 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:38:29.805968 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m15:38:29.808848 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:38:29.809386 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:38:29.809918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:29.816273 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.816799 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:38:29.817324 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:38:29.819898 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:38:29.821898 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:38:29.822895 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:38:29.828663 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:29.829199 [debug] [MainThread]: On master: BEGIN
[0m15:38:29.829719 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:38:29.836139 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.836671 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:29.837191 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:38:29.844188 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m15:38:29.846188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BC4D2B0>]}
[0m15:38:29.847191 [debug] [MainThread]: On master: ROLLBACK
[0m15:38:29.848190 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:29.849192 [debug] [MainThread]: On master: BEGIN
[0m15:38:29.850189 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:38:29.850189 [debug] [MainThread]: On master: COMMIT
[0m15:38:29.851188 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:29.851188 [debug] [MainThread]: On master: COMMIT
[0m15:38:29.852189 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:38:29.852189 [debug] [MainThread]: On master: Close
[0m15:38:29.853188 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:38:29.854190 [info ] [MainThread]: 
[0m15:38:29.857862 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:38:29.858383 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m15:38:29.859437 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:38:29.859970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:38:29.867418 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:38:29.869412 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:38:29.907414 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m15:38:29.908414 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.908414 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m15:38:29.909414 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:38:29.915412 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:29.915412 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.916411 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m15:38:29.918413 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:38:29.924414 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.925414 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m15:38:29.926411 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:29.929413 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.930414 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m15:38:29.931015 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:29.950007 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:38:29.951008 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.951008 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:38:29.955006 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:29.961004 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m15:38:29.966004 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:38:29.966004 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m15:38:29.970004 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:29.972008 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m15:38:29.973583 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09998E1B0>]}
[0m15:38:29.974584 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.11s]
[0m15:38:29.975977 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:38:29.976502 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:38:29.977024 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m15:38:29.978076 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:38:29.978076 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:38:29.982799 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:38:29.983315 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:38:29.986988 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m15:38:29.987984 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:29.987984 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m15:38:29.987984 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:29.994985 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:29.995988 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:29.995988 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m15:38:29.998983 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:38:30.001987 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:30.002985 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m15:38:30.004984 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.007985 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:30.007985 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m15:38:30.008985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.010985 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:38:30.010985 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:30.011984 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:38:30.014984 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.017983 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m15:38:30.018986 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:38:30.018986 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m15:38:30.022985 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.024986 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m15:38:30.025984 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCB0F80>]}
[0m15:38:30.026987 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m15:38:30.027988 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:38:30.028669 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:38:30.029194 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m15:38:30.029711 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:38:30.030581 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:38:30.033190 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:38:30.034255 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:38:30.039054 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m15:38:30.040101 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.040101 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m15:38:30.041099 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.047097 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.047097 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.048102 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m15:38:30.050097 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:38:30.055100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.055100 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m15:38:30.057098 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.060100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.060100 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m15:38:30.062100 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.063101 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:38:30.064102 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.064102 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:38:30.067097 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.070100 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m15:38:30.071098 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:38:30.072098 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m15:38:30.075098 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.077101 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m15:38:30.077101 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B833BC0>]}
[0m15:38:30.078101 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m15:38:30.079097 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:38:30.079921 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:38:30.080440 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m15:38:30.081501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:38:30.082034 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:38:30.084757 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:38:30.085830 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:38:30.091110 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m15:38:30.092100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.092100 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m15:38:30.093100 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.099100 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.099100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.100100 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m15:38:30.109102 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:38:30.112103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.112103 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m15:38:30.113104 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.116103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.117103 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m15:38:30.118103 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.121100 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:38:30.121100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.122100 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:38:30.126101 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:38:30.129102 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m15:38:30.129102 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:38:30.130104 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m15:38:30.134100 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.136099 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m15:38:30.136099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BB919D0>]}
[0m15:38:30.137101 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m15:38:30.138099 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:38:30.139100 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:38:30.139641 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m15:38:30.140688 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:38:30.140688 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:38:30.143846 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:38:30.144881 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:38:30.148061 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m15:38:30.149113 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.149637 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m15:38:30.150167 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.156200 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:30.157199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.157199 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m15:38:30.161199 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:38:30.164202 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.165202 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m15:38:30.166198 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.169199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.170203 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m15:38:30.171200 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.173201 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:38:30.173201 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.174202 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:38:30.177315 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.179837 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m15:38:30.180839 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:38:30.180839 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m15:38:30.184834 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.186837 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m15:38:30.186837 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BC723C0>]}
[0m15:38:30.187837 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m15:38:30.188838 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:38:30.189837 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:38:30.190917 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m15:38:30.191441 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:38:30.191970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:38:30.195147 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:38:30.195673 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:38:30.199325 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m15:38:30.199867 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.200388 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m15:38:30.200919 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.207431 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.207431 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.208435 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m15:38:30.212433 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:38:30.215433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.215433 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m15:38:30.216432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.223431 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.224432 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m15:38:30.225432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.227432 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:38:30.228432 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.228432 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:38:30.232434 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.234434 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m15:38:30.235434 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:38:30.235434 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m15:38:30.239431 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.241435 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m15:38:30.242431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCD64B0>]}
[0m15:38:30.242431 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m15:38:30.244434 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:38:30.244833 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:38:30.245366 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m15:38:30.246422 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:38:30.246953 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:38:30.249585 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.250644 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:38:30.254923 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.255983 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.255983 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m15:38:30.256981 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.262979 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.263979 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.263979 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m15:38:30.265979 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m15:38:30.269977 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.269977 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m15:38:30.271978 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.274976 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.275976 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m15:38:30.276976 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.278977 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:38:30.278977 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.279976 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:38:30.281976 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:38:30.284977 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m15:38:30.286977 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:38:30.287977 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m15:38:30.291977 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.292982 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m15:38:30.293981 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09C0740B0>]}
[0m15:38:30.294981 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m15:38:30.296241 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:38:30.296766 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:38:30.297813 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m15:38:30.298339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:38:30.298895 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:38:30.302570 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:38:30.303602 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:38:30.307284 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m15:38:30.307798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.308796 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m15:38:30.308796 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.314797 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.315797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.316797 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m15:38:30.325796 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m15:38:30.328797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.329798 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m15:38:30.330798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.333797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.333797 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m15:38:30.335798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.337798 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:38:30.337798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.338797 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:38:30.343798 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:38:30.345797 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m15:38:30.346798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:38:30.346798 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m15:38:30.350798 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.353799 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m15:38:30.354798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCE4CE0>]}
[0m15:38:30.355799 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m15:38:30.356798 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:38:30.357353 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:38:30.358411 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m15:38:30.358941 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:38:30.359471 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:38:30.364271 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:38:30.365343 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:38:30.368511 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m15:38:30.369510 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.369510 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m15:38:30.370510 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.376507 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:30.377509 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.378507 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m15:38:30.387509 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:38:30.390509 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.390509 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m15:38:30.392133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.395130 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.395130 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m15:38:30.396130 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.398133 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:38:30.399133 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.399133 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:38:30.404131 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:38:30.407132 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m15:38:30.407132 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:38:30.408133 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m15:38:30.412129 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:38:30.414133 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m15:38:30.414133 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09A3BE300>]}
[0m15:38:30.415132 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m15:38:30.416129 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:38:30.416993 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:38:30.417531 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m15:38:30.418589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:38:30.419124 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:38:30.422274 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:38:30.423330 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:38:30.426470 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m15:38:30.426994 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.427529 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m15:38:30.428071 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.434140 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.434140 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.435141 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m15:38:30.442145 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m15:38:30.445141 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.445141 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m15:38:30.446142 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.449142 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.450143 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m15:38:30.451139 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.453141 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:38:30.453141 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.454139 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:38:30.457138 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.460138 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m15:38:30.461138 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:38:30.461138 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m15:38:30.465139 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.466139 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m15:38:30.467143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCDFEF0>]}
[0m15:38:30.468140 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m15:38:30.469143 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:38:30.470139 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:38:30.470139 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m15:38:30.471701 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:38:30.472228 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:38:30.474840 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:38:30.475890 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:38:30.480617 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m15:38:30.481147 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.481684 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m15:38:30.482204 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.490201 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m15:38:30.490201 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.491201 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m15:38:30.493204 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:38:30.551199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.552201 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m15:38:30.553200 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.556204 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.557204 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m15:38:30.558203 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.560204 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:38:30.560204 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.561204 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:38:30.564200 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.566203 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m15:38:30.567203 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:38:30.568202 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m15:38:30.571200 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.573203 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m15:38:30.573203 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCA5EE0>]}
[0m15:38:30.574203 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m15:38:30.575199 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:38:30.576202 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:38:30.576558 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m15:38:30.577660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:38:30.578188 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:38:30.580827 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:38:30.581888 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:38:30.585064 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m15:38:30.586126 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.586667 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m15:38:30.587201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.593271 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.593271 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.594267 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m15:38:30.596267 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:38:30.600266 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.600266 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m15:38:30.602268 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.605269 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.605269 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m15:38:30.607269 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.609269 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:38:30.609269 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.610270 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:38:30.613266 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.615270 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m15:38:30.616270 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:38:30.617270 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m15:38:30.621270 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:38:30.623269 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m15:38:30.623269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E099A5E900>]}
[0m15:38:30.624268 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m15:38:30.625268 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:38:30.626422 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:38:30.626952 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m15:38:30.627998 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:38:30.628007 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:38:30.631150 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:38:30.632209 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:38:30.635920 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m15:38:30.636963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.637485 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m15:38:30.637485 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.644481 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.644481 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.645480 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m15:38:30.647485 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:38:30.650483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.651481 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m15:38:30.652483 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.655483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.656485 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m15:38:30.657485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.661483 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:38:30.661483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.662483 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:38:30.665483 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.667483 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m15:38:30.668482 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:38:30.669481 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m15:38:30.672483 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.674482 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m15:38:30.675483 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCE6FC0>]}
[0m15:38:30.676481 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m15:38:30.677481 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:38:30.678448 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:38:30.678977 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m15:38:30.679509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:38:30.680036 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:38:30.682655 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:38:30.683707 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:38:30.688492 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m15:38:30.689031 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.690029 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m15:38:30.690029 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.705945 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m15:38:30.706944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.707941 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m15:38:30.716946 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m15:38:30.721941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.722940 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m15:38:30.723941 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.726940 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.726940 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m15:38:30.728942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.730943 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:38:30.730943 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.731948 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:38:30.735466 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:38:30.739470 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m15:38:30.739470 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:38:30.740470 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m15:38:30.744465 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.746467 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m15:38:30.747467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BB93C20>]}
[0m15:38:30.748467 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m15:38:30.749467 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:38:30.750277 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:38:30.750798 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m15:38:30.751862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:38:30.752398 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:38:30.755587 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:38:30.756655 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:38:30.759824 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m15:38:30.760885 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.761413 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m15:38:30.761413 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.768405 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:30.769407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.769407 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m15:38:30.774404 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m15:38:30.777403 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.777403 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m15:38:30.778403 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.782407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.782407 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m15:38:30.783407 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.786408 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:38:30.787407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.787407 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:38:30.791405 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.793406 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m15:38:30.794470 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:38:30.794995 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m15:38:30.798988 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:38:30.799989 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m15:38:30.801990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B6DFF80>]}
[0m15:38:30.802989 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m15:38:30.803990 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:38:30.804397 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:38:30.805462 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m15:38:30.805995 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:38:30.806526 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:38:30.811333 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:38:30.812401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:38:30.815577 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m15:38:30.816574 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.816574 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m15:38:30.817574 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.823576 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.824570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.824570 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m15:38:30.828572 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:38:30.831570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.831570 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m15:38:30.832640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.835632 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.836633 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m15:38:30.837631 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.839631 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:38:30.839631 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.840633 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:38:30.843629 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:30.845629 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m15:38:30.846628 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:38:30.847628 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m15:38:30.850629 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:30.852631 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m15:38:30.853633 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BCDBB30>]}
[0m15:38:30.854630 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m15:38:30.855629 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:38:30.856397 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:38:30.856989 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m15:38:30.858047 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:38:30.858573 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:38:30.861196 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.861720 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:38:30.880009 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.881010 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.882009 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m15:38:30.882009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.889009 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.890013 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.890013 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m15:38:30.892013 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.001 seconds
[0m15:38:30.895011 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.895011 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m15:38:30.897008 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.898007 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:38:30.899008 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.899008 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:38:30.902322 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:38:30.904323 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m15:38:30.907323 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:38:30.908320 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m15:38:30.909321 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:38:30.911319 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m15:38:30.911319 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B833A10>]}
[0m15:38:30.912321 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.05s]
[0m15:38:30.913319 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:38:30.914291 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:38:30.914820 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m15:38:30.915340 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m15:38:30.915858 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:38:30.919025 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:38:30.920179 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:38:30.923887 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m15:38:30.924413 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.924952 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m15:38:30.925469 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.931467 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:30.932467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.932467 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m15:38:30.940468 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m15:38:30.946467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.946467 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m15:38:30.947469 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.950467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.950467 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m15:38:30.952468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:30.955467 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:38:30.955467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.956468 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:38:30.961485 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:38:30.964483 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m15:38:30.964483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:38:30.965485 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m15:38:30.969485 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:38:30.971484 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m15:38:30.971484 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09C09AC30>]}
[0m15:38:30.972485 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m15:38:30.973484 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:38:30.974812 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:38:30.975338 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m15:38:30.976386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:38:30.976386 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:38:30.979507 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:38:30.980023 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:38:30.983706 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m15:38:30.985275 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:30.985800 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m15:38:30.986318 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.992314 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:30.993314 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:30.993314 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m15:38:31.002876 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:38:31.005876 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:31.006876 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m15:38:31.008876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.010875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:31.011877 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m15:38:31.012876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.014877 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:38:31.014877 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:31.015877 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:38:31.052875 [debug] [Thread-1 (]: SQL status: COMMIT in 0.037 seconds
[0m15:38:31.055875 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m15:38:31.056875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:38:31.056875 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m15:38:31.060876 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:31.061875 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m15:38:31.062875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09A395D90>]}
[0m15:38:31.063876 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.09s]
[0m15:38:31.064876 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:38:31.065383 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:38:31.065908 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m15:38:31.066428 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:38:31.066946 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:38:31.070111 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:38:31.071162 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:38:31.074888 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m15:38:31.075952 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.076471 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m15:38:31.076471 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:31.082468 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:38:31.083467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.084467 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m15:38:31.091467 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m15:38:31.094467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.095467 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m15:38:31.096468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.099467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.100466 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m15:38:31.101468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.103467 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:38:31.104467 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.104467 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:38:31.108466 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:31.112467 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m15:38:31.113468 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:38:31.113468 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m15:38:31.117467 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:31.119470 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m15:38:31.120468 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09BC99280>]}
[0m15:38:31.121468 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m15:38:31.122467 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:38:31.123245 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:38:31.123771 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m15:38:31.124829 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m15:38:31.125352 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:38:31.128993 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:38:31.130033 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:38:31.133686 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m15:38:31.134722 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:38:31.134722 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m15:38:31.135719 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:31.142718 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:38:31.142718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:38:31.143718 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    MAX(fct_pay.amount)
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id, dim_fm.title
  );
  
[0m15:38:31.738381 [debug] [Thread-1 (]: SQL status: SELECT 958 in 0.594 seconds
[0m15:38:31.741381 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:38:31.742381 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m15:38:31.743380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.744380 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m15:38:31.745379 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:38:31.745379 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m15:38:31.748381 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:38:31.751380 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m15:38:31.751380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:38:31.752381 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m15:38:31.753380 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:38:31.754381 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m15:38:31.755380 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09B6F3650>]}
[0m15:38:31.756381 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 958[0m in 0.63s]
[0m15:38:31.756381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:38:31.757380 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:38:31.758379 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m15:38:31.758379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:38:31.759379 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:38:31.761380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:38:31.762381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:38:31.765380 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m15:38:31.766381 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.767381 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m15:38:31.767381 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:31.795505 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m15:38:31.795505 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.796505 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m15:38:31.817505 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.021 seconds
[0m15:38:31.821505 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.821505 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m15:38:31.824083 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.826084 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.827084 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m15:38:31.828083 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:38:31.830083 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:38:31.830083 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.831084 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:38:31.836789 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:38:31.838789 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m15:38:31.839789 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:38:31.839789 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m15:38:31.843789 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:38:31.844789 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m15:38:31.845789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1f11d24-505b-4315-af80-ea8cd074465a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0997C3C20>]}
[0m15:38:31.846791 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m15:38:31.847791 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:38:31.849103 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:31.849619 [debug] [MainThread]: On master: BEGIN
[0m15:38:31.850138 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:38:31.856555 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:38:31.857070 [debug] [MainThread]: On master: COMMIT
[0m15:38:31.857589 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:31.857589 [debug] [MainThread]: On master: COMMIT
[0m15:38:31.858639 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:38:31.859159 [debug] [MainThread]: On master: Close
[0m15:38:31.859672 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:38:31.859672 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m15:38:31.860669 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m15:38:31.860669 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:38:31.861671 [info ] [MainThread]: 
[0m15:38:31.862086 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.24 seconds (2.24s).
[0m15:38:31.866243 [debug] [MainThread]: Command end result
[0m15:38:31.896587 [info ] [MainThread]: 
[0m15:38:31.897588 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:38:31.897588 [info ] [MainThread]: 
[0m15:38:31.898589 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m15:38:31.899589 [debug] [MainThread]: Command `dbt run` succeeded at 15:38:31.899589 after 3.14 seconds
[0m15:38:31.900588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E09C097230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E099E70680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E099E703E0>]}
[0m15:38:44.265812 [debug] [MainThread]: Flushing usage events
[0m15:39:09.154075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F353BB88C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F353BBABA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F353BB9A00>]}


============================== 15:39:09.159075 | ed90e351-ef41-4cc0-9138-ae1d2516f462 ==============================
[0m15:39:09.159075 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:39:09.160078 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m15:39:09.358213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3545A2D80>]}
[0m15:39:09.410213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3545CA900>]}
[0m15:39:09.412214 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:39:09.421216 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:39:09.583833 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:39:09.583833 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:39:09.624834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3544D35C0>]}
[0m15:39:09.647833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F355916DE0>]}
[0m15:39:09.648833 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:39:09.648833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35483BCE0>]}
[0m15:39:09.651831 [info ] [MainThread]: 
[0m15:39:09.652833 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:39:09.657395 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m15:39:09.731457 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:39:09.732457 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:39:09.732457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:09.741457 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m15:39:09.742459 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:39:09.742459 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:39:09.745457 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:39:09.747458 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:39:09.748458 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:39:09.748458 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m15:39:09.751768 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:39:09.752290 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:39:09.752831 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:39:09.759143 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:39:09.759671 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:39:09.760189 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:39:09.762814 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:39:09.763803 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:39:09.764803 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:39:09.765803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_mart)
[0m15:39:09.769253 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:39:09.769788 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:39:09.770322 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:39:09.776084 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:39:09.776609 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:39:09.777131 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:39:09.779790 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:39:09.781786 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:39:09.781786 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:39:09.782785 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m15:39:09.785870 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:39:09.786399 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:39:09.786928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:39:09.792758 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:39:09.793282 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:39:09.793863 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:39:09.796473 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m15:39:09.797473 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:39:09.798473 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:39:09.805466 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:09.805988 [debug] [MainThread]: On master: BEGIN
[0m15:39:09.806511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:39:09.812321 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:39:09.813364 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:09.813364 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:39:09.819361 [debug] [MainThread]: SQL status: SELECT 38 in 0.005 seconds
[0m15:39:09.821362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed90e351-ef41-4cc0-9138-ae1d2516f462', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F354675A90>]}
[0m15:39:09.822361 [debug] [MainThread]: On master: ROLLBACK
[0m15:39:09.822361 [debug] [MainThread]: On master: Close
[0m15:39:09.823361 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:39:09.824360 [info ] [MainThread]: 
[0m15:39:09.827348 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:39:09.828395 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:39:09.828926 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:39:09.836218 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:39:09.837283 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:39:09.837800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:39:09.838799 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:39:09.838799 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:39:09.839909 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:39:09.842426 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:39:09.843426 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:39:09.844427 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:39:09.845429 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:39:09.846426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:39:09.846426 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:39:09.849425 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:39:09.850428 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:39:09.851427 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:39:09.851427 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:39:09.852427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:39:09.852427 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:39:09.855760 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:39:09.856763 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:39:09.857760 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:39:09.857760 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:39:09.858760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:39:09.858760 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:39:09.861760 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:39:09.862761 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:39:09.863761 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:39:09.863761 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:39:09.864759 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:39:09.864759 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:39:09.867761 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:39:09.868763 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:39:09.869801 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:39:09.870319 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:39:09.871317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:39:09.871317 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:39:09.874315 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:39:09.875315 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:39:09.876318 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:39:09.877315 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:39:09.877315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:39:09.878315 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:39:09.882314 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:39:09.882314 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:39:09.883322 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:39:09.884316 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:39:09.884316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:39:09.885315 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:39:09.888316 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:39:09.890317 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:39:09.890317 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:39:09.891315 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:39:09.891315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:39:09.892315 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:39:09.895315 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:39:09.895315 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:39:09.896318 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:39:09.897316 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:39:09.897316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:39:09.898316 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:39:09.900314 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:39:09.901317 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:39:09.902318 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:39:09.902318 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:39:09.903317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:39:09.904317 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:39:09.906315 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:39:09.907316 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:39:09.908316 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:39:09.908316 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:39:09.909315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:39:09.909315 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:39:09.912318 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:39:09.913318 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:39:09.914319 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:39:09.914319 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:39:09.915317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:39:09.915317 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:39:09.918316 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:39:09.919315 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:39:09.920318 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:39:09.921316 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:39:09.921316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:39:09.922316 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:39:09.924316 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:39:09.925317 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:39:09.926317 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:39:09.927316 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:39:09.927316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:39:09.927316 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:39:09.930316 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:39:09.931316 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:39:09.932317 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:39:09.932317 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:39:09.933316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:39:09.933316 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:39:09.936318 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:39:09.937316 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:39:09.938316 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:39:09.939316 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:39:09.939316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m15:39:09.940316 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:39:09.951316 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:39:09.952316 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:39:09.953318 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:39:09.953318 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:39:09.954742 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m15:39:09.954742 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:39:09.960729 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m15:39:09.961729 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:39:09.962732 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:39:09.962732 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:39:09.963730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m15:39:09.963730 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:39:09.967729 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:39:09.968730 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:39:09.969732 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:39:09.970730 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:39:09.970730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:39:09.971729 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:39:09.973730 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:39:09.974728 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:39:09.975731 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:39:09.975731 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:39:09.976729 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:39:09.976729 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:39:09.979729 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:39:09.980731 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:39:09.980731 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:39:09.981731 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:39:09.981731 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m15:39:09.982729 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:39:09.985729 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m15:39:09.987731 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:39:09.987731 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:39:09.988729 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:39:09.988729 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m15:39:09.989729 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:39:09.992729 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m15:39:09.993730 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:39:09.994731 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:39:09.995729 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:39:09.995729 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.best_selling_film)
[0m15:39:09.996730 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:39:09.999730 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:39:10.000730 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:39:10.001730 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:39:10.001730 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:39:10.002730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:39:10.002730 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:39:10.005730 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:39:10.006730 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:39:10.007730 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:39:10.008730 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:39:10.008730 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediete' was properly closed.
[0m15:39:10.008730 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:39:10.012729 [debug] [MainThread]: Command end result
[0m15:39:10.101312 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m15:39:10.101312 [info ] [MainThread]: Building catalog
[0m15:39:10.113314 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m15:39:10.120313 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m15:39:10.120313 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m15:39:10.120313 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:10.127312 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:39:10.128312 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m15:39:10.128312 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_selling_film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m15:39:10.139311 [debug] [ThreadPool]: SQL status: SELECT 205 in 0.010 seconds
[0m15:39:10.149310 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m15:39:10.150310 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m15:39:10.195732 [info ] [MainThread]: Catalog written to C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\target\catalog.json
[0m15:39:10.197731 [debug] [MainThread]: Command `dbt docs generate` succeeded at 15:39:10.197731 after 1.14 seconds
[0m15:39:10.198732 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m15:39:10.198732 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m15:39:10.198732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3537F0860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35422A9C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3535285C0>]}
[0m15:39:10.199732 [debug] [MainThread]: Flushing usage events
[0m15:43:39.373296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACBE14BCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC0BACF50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC0BAD8E0>]}


============================== 15:43:39.378299 | 0f12be09-2ca2-4fa5-9477-7bb43eda43ca ==============================
[0m15:43:39.378299 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:43:39.379296 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:43:39.570574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC03EBB00>]}
[0m15:43:39.623086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC08B4350>]}
[0m15:43:39.624087 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:43:39.632086 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:43:39.790310 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:43:39.791315 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m15:43:40.016884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC22AB7D0>]}
[0m15:43:40.116884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC22F4140>]}
[0m15:43:40.117885 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:43:40.118885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC0DBCE00>]}
[0m15:43:40.120885 [info ] [MainThread]: 
[0m15:43:40.121885 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:43:40.126883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m15:43:40.197884 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:43:40.198883 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:43:40.198883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:40.207886 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m15:43:40.209885 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:43:40.212885 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:43:40.212885 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:43:40.213885 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.220554 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:43:40.222109 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:43:40.225159 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:43:40.225688 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:43:40.226217 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.233062 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:43:40.234627 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:43:40.236716 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:43:40.237312 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:43:40.237844 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.247805 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.010 seconds
[0m15:43:40.248839 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:43:40.252142 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_intermediete'
[0m15:43:40.257918 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:43:40.258450 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:43:40.258450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:40.264689 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.264689 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:43:40.265694 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:43:40.268689 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:43:40.269693 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:43:40.270689 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:43:40.271693 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m15:43:40.276976 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:43:40.277508 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:43:40.278029 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.283811 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.284336 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:43:40.284855 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:43:40.287366 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:43:40.288367 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:43:40.289367 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:43:40.290369 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m15:43:40.292368 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:43:40.293787 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:43:40.293787 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.300102 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.300647 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:43:40.301175 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:43:40.303759 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:43:40.304806 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:43:40.305805 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:43:40.306803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m15:43:40.309682 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:43:40.309682 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:43:40.310208 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:40.316572 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.317100 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:43:40.317622 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:43:40.320223 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:43:40.321223 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:43:40.322221 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:43:40.329735 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:40.330257 [debug] [MainThread]: On master: BEGIN
[0m15:43:40.330779 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:43:40.337084 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.337084 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:40.338083 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:43:40.344083 [debug] [MainThread]: SQL status: SELECT 38 in 0.006 seconds
[0m15:43:40.346084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC267B920>]}
[0m15:43:40.347082 [debug] [MainThread]: On master: ROLLBACK
[0m15:43:40.348084 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:40.348084 [debug] [MainThread]: On master: BEGIN
[0m15:43:40.349083 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:43:40.350082 [debug] [MainThread]: On master: COMMIT
[0m15:43:40.350082 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:40.351084 [debug] [MainThread]: On master: COMMIT
[0m15:43:40.352082 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:43:40.352082 [debug] [MainThread]: On master: Close
[0m15:43:40.353082 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:43:40.353082 [info ] [MainThread]: 
[0m15:43:40.356780 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:43:40.357302 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m15:43:40.358357 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:43:40.358883 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:43:40.366763 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:43:40.367764 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:43:40.406762 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m15:43:40.407762 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.407762 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m15:43:40.408763 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:43:40.415368 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:40.416367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.416367 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m15:43:40.419367 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:43:40.425367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.425367 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m15:43:40.427368 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.430368 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.430368 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m15:43:40.432367 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.451368 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:43:40.452367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.452367 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:43:40.456406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:40.461926 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m15:43:40.466926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:43:40.466926 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m15:43:40.472925 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m15:43:40.475532 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m15:43:40.478233 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACBE6A1100>]}
[0m15:43:40.479281 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m15:43:40.480337 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:43:40.480861 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:43:40.481908 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m15:43:40.482432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:43:40.482947 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:43:40.487673 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:43:40.488730 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:43:40.492815 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m15:43:40.493814 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.494817 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m15:43:40.494817 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.501815 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:40.501815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.502814 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m15:43:40.504814 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:43:40.507815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.508815 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m15:43:40.509815 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.512815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.513815 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m15:43:40.514815 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.516815 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:43:40.516815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.517815 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:43:40.520815 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:40.522815 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m15:43:40.523814 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:43:40.524814 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m15:43:40.528815 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:40.530816 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m15:43:40.530816 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2769850>]}
[0m15:43:40.531815 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m15:43:40.532815 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:43:40.533815 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:43:40.534814 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m15:43:40.534814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:43:40.535815 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:43:40.538815 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:43:40.539815 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:43:40.542814 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m15:43:40.543815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.544815 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m15:43:40.544815 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.550815 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.551815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.551815 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m15:43:40.554813 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:43:40.557813 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.557813 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m15:43:40.558813 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.562813 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.563813 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m15:43:40.564813 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.566816 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:43:40.567814 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.567814 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:43:40.570816 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:40.573815 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m15:43:40.574815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:43:40.575814 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m15:43:40.579816 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.581816 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m15:43:40.582815 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2668710>]}
[0m15:43:40.582815 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m15:43:40.583815 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:43:40.584948 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:43:40.585999 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m15:43:40.586520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:43:40.587043 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:43:40.589653 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:43:40.590705 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:43:40.596543 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m15:43:40.597541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.598541 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m15:43:40.598541 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.604540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.605541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.605541 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m15:43:40.613541 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:43:40.617540 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.617540 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m15:43:40.618541 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.621541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.622541 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m15:43:40.623540 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.624541 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:43:40.625541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.625541 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:43:40.629540 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:40.632541 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m15:43:40.633541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:43:40.633541 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m15:43:40.637540 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:40.639541 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m15:43:40.640540 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC26530E0>]}
[0m15:43:40.640540 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m15:43:40.641541 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:43:40.642541 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:43:40.643540 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m15:43:40.644541 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:43:40.645540 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:43:40.648540 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:43:40.648540 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:43:40.652539 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m15:43:40.653541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.653541 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m15:43:40.654541 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.660120 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.661121 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.662119 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m15:43:40.666119 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m15:43:40.669119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.669119 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m15:43:40.671119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.673120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.673120 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m15:43:40.675119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.677120 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:43:40.678120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.678120 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:43:40.685118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m15:43:40.688119 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m15:43:40.689119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:43:40.689119 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m15:43:40.692118 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.695120 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m15:43:40.696120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC26762A0>]}
[0m15:43:40.697122 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m15:43:40.698118 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:43:40.699120 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:43:40.700119 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m15:43:40.700119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:43:40.701119 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:43:40.704120 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:43:40.705119 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:43:40.708119 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m15:43:40.709120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.710120 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m15:43:40.710120 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.717118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:40.718120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.718120 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m15:43:40.722119 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:43:40.725119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.725119 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m15:43:40.727119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.733118 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.734122 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m15:43:40.735119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.737120 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:43:40.737120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.738120 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:43:40.741118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:40.744121 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m15:43:40.745119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:43:40.745119 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m15:43:40.749119 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.750120 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m15:43:40.751120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC27ABDA0>]}
[0m15:43:40.752119 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m15:43:40.753119 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:43:40.753119 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:43:40.754120 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m15:43:40.755120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:43:40.755120 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:43:40.758118 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.759122 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:43:40.763119 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.764118 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.765120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m15:43:40.765120 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.771118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:40.772119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.773120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m15:43:40.775118 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m15:43:40.778120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.779120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m15:43:40.780118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.783119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.784120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m15:43:40.785119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.787120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:43:40.787120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.787120 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:43:40.790117 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:43:40.793119 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m15:43:40.794122 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:43:40.794122 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m15:43:40.798119 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.800118 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m15:43:40.801121 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2B100B0>]}
[0m15:43:40.802120 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.04s]
[0m15:43:40.803120 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:43:40.803120 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:43:40.804119 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m15:43:40.805118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:43:40.805118 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:43:40.808119 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:43:40.809119 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:43:40.812119 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m15:43:40.813120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.814119 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m15:43:40.814119 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.821120 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:40.822120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.822120 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m15:43:40.830119 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m15:43:40.834120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.835118 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m15:43:40.836119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.839119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.840120 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m15:43:40.841118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.843120 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:43:40.843120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.844119 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:43:40.852118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m15:43:40.855119 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m15:43:40.856119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:43:40.856119 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m15:43:40.860120 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.862120 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m15:43:40.863120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2AFF890>]}
[0m15:43:40.864120 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m15:43:40.865687 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:43:40.866216 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:43:40.867267 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m15:43:40.867795 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:43:40.868324 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:43:40.872484 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:43:40.873484 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:43:40.877485 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m15:43:40.878485 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.879484 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m15:43:40.879484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.886483 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:40.887484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.887484 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m15:43:40.897484 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m15:43:40.900484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.901484 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m15:43:40.902483 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.905483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.906484 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m15:43:40.907483 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.908484 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:43:40.909484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.909484 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:43:40.920486 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m15:43:40.922484 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m15:43:40.923484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:43:40.924484 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m15:43:40.928483 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.929484 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m15:43:40.930484 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2711B20>]}
[0m15:43:40.931484 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m15:43:40.932483 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:43:40.933485 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:43:40.933485 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m15:43:40.934482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:43:40.934482 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:43:40.937483 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:43:40.938484 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:43:40.941483 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m15:43:40.942484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.943484 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m15:43:40.943484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:40.963484 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m15:43:40.964484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.964484 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m15:43:40.971486 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m15:43:40.974484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.975484 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m15:43:40.976484 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.979484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.980484 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m15:43:40.981483 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:40.983484 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:43:40.983484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.984484 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:43:40.987482 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:43:40.989483 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m15:43:40.990484 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:43:40.990484 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m15:43:40.994485 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:40.995484 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m15:43:40.996484 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2773DA0>]}
[0m15:43:40.997484 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m15:43:40.998483 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:43:40.998483 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:43:41.000076 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m15:43:41.000602 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:43:41.001131 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:43:41.004263 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:43:41.004787 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:43:41.010575 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m15:43:41.012090 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.012090 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m15:43:41.013090 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.018605 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.019606 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.019606 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m15:43:41.021608 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.001 seconds
[0m15:43:41.081158 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.081158 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m15:43:41.083159 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.086159 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.086159 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m15:43:41.087158 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.089159 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:43:41.089159 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.090159 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:43:41.093157 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:41.096158 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m15:43:41.097157 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:43:41.097157 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m15:43:41.101159 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:41.102159 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m15:43:41.103158 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC27ABDD0>]}
[0m15:43:41.104159 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m15:43:41.105158 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:43:41.105548 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:43:41.106079 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m15:43:41.107118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:43:41.107644 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:43:41.110258 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:43:41.111308 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:43:41.114956 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m15:43:41.115481 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.116006 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m15:43:41.117103 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.136103 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m15:43:41.136103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.137103 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m15:43:41.139101 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:43:41.142103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.142103 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m15:43:41.144104 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.148103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.148103 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m15:43:41.150103 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.152103 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:43:41.152103 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.153103 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:43:41.155104 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:43:41.158103 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m15:43:41.159104 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:43:41.159104 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m15:43:41.163103 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:41.165104 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m15:43:41.166103 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2775D90>]}
[0m15:43:41.167103 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m15:43:41.168103 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:43:41.168827 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:43:41.169352 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m15:43:41.170408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:43:41.170408 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:43:41.173516 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:43:41.174562 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:43:41.178262 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m15:43:41.179349 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.179877 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m15:43:41.180393 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.186391 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.187391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.187391 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m15:43:41.190390 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:43:41.193391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.193391 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m15:43:41.195392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.198391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.199391 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m15:43:41.200393 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.204391 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:43:41.204391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.205390 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:43:41.208391 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:41.212393 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m15:43:41.213394 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:43:41.214888 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m15:43:41.218872 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:41.220873 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m15:43:41.221872 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC27A2150>]}
[0m15:43:41.222873 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m15:43:41.224873 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:43:41.225891 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:43:41.226724 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m15:43:41.228311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:43:41.229381 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:43:41.233763 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:43:41.234826 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:43:41.240435 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m15:43:41.241435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.242437 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m15:43:41.244439 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.252434 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m15:43:41.253434 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.253434 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m15:43:41.262435 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:43:41.266437 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.267438 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m15:43:41.268435 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.271994 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.271994 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m15:43:41.273988 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.276989 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:43:41.277990 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.277990 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:43:41.285988 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m15:43:41.287989 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m15:43:41.288989 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:43:41.289988 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m15:43:41.293992 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:41.295987 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m15:43:41.296987 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2316600>]}
[0m15:43:41.296987 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m15:43:41.297988 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:43:41.299262 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:43:41.299789 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m15:43:41.300311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:43:41.300841 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:43:41.304044 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:43:41.305103 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:43:41.308271 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m15:43:41.309332 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.309864 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m15:43:41.310383 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.316897 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.316897 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.317898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m15:43:41.321897 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:43:41.324898 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.324898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m15:43:41.325898 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.328899 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.329898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m15:43:41.330897 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.332898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:43:41.333898 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.333898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:43:41.336896 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:41.339898 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m15:43:41.339898 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:43:41.340898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m15:43:41.344899 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:41.346898 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m15:43:41.346898 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC11B3EC0>]}
[0m15:43:41.347898 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m15:43:41.349897 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:43:41.350249 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:43:41.350779 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m15:43:41.351825 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:43:41.352352 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:43:41.356511 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:43:41.357561 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:43:41.361244 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m15:43:41.361765 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.362762 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m15:43:41.363762 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.369760 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.370761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.370761 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m15:43:41.374760 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:43:41.377761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.378761 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m15:43:41.379760 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.383760 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.384760 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m15:43:41.385761 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.387760 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:43:41.387760 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.388761 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:43:41.391759 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:43:41.394761 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m15:43:41.396761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:43:41.396761 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m15:43:41.400761 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:41.401760 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m15:43:41.402760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2711760>]}
[0m15:43:41.403759 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m15:43:41.404762 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:43:41.405293 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:43:41.405830 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m15:43:41.406877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:43:41.407394 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:43:41.410569 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.411625 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:43:41.434362 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.435954 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.436488 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m15:43:41.437021 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.443314 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:43:41.444963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.445498 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m15:43:41.448105 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m15:43:41.451221 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.451741 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m15:43:41.453300 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.454872 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:43:41.455393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.455921 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:43:41.458625 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:43:41.462845 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m15:43:41.465955 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:43:41.467000 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m15:43:41.468052 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:43:41.469614 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m15:43:41.469614 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2B46660>]}
[0m15:43:41.470614 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m15:43:41.471615 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:43:41.472615 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:43:41.472615 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m15:43:41.473614 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m15:43:41.474613 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:43:41.477617 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:43:41.478613 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:43:41.482612 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m15:43:41.482612 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.483615 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m15:43:41.483615 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.489613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.490615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.491615 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m15:43:41.499612 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m15:43:41.504613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.505614 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m15:43:41.506614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.509613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.510614 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m15:43:41.511614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.513614 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:43:41.514614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.514614 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:43:41.520613 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m15:43:41.523614 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m15:43:41.524614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:43:41.524614 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m15:43:41.528614 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:41.530613 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m15:43:41.531615 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2B1A090>]}
[0m15:43:41.531615 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m15:43:41.532615 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:43:41.533613 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:43:41.534612 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m15:43:41.535613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:43:41.535613 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:43:41.538614 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:43:41.539614 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:43:41.542613 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m15:43:41.543615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.544615 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m15:43:41.544615 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.550614 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.551614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.551614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m15:43:41.561614 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m15:43:41.564613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.565613 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m15:43:41.566614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.569614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.570614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m15:43:41.571615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.573614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:43:41.573614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.573614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:43:41.581615 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m15:43:41.583614 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m15:43:41.584615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:43:41.585614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m15:43:41.588613 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:43:41.590614 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m15:43:41.591613 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC1106B70>]}
[0m15:43:41.591613 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m15:43:41.592615 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:43:41.593614 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:43:41.594616 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m15:43:41.595614 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:43:41.595614 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:43:41.598614 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:43:41.599615 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:43:41.602614 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m15:43:41.603614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.604614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m15:43:41.604614 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.611613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.611613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.612615 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m15:43:41.619613 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m15:43:41.622614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.623614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m15:43:41.624615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.627616 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.628614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m15:43:41.629614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.631614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:43:41.632614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.632614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:43:41.635614 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:43:41.640614 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m15:43:41.641614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:43:41.641614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m15:43:41.645614 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:41.647614 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m15:43:41.648614 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2712F00>]}
[0m15:43:41.649615 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m15:43:41.650614 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:43:41.651367 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:43:41.651898 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m15:43:41.652935 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m15:43:41.653458 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:43:41.657115 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:43:41.657639 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:43:41.661910 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m15:43:41.663424 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:43:41.663424 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m15:43:41.664424 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.670424 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.671423 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:43:41.671423 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    MAX(fct_pay.amount)
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id, dim_fm.title
ORDER BY fct_pay.amount DESC
  );
  
[0m15:43:41.673423 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "fct_pay.amount" must appear in the GROUP BY clause or be used in an aggregate function
LINE 26: ORDER BY fct_pay.amount DESC
                  ^

[0m15:43:41.674423 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: ROLLBACK
[0m15:43:41.675484 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m15:43:41.682351 [debug] [Thread-1 (]: Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column "fct_pay.amount" must appear in the GROUP BY clause or be used in an aggregate function
  LINE 26: ORDER BY fct_pay.amount DESC
                    ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:43:41.682865 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2AF84A0>]}
[0m15:43:41.683919 [error] [Thread-1 (]: 21 of 22 ERROR creating sql table model dbt_dev_mart.best_selling_film ......... [[31mERROR[0m in 0.03s]
[0m15:43:41.684972 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:43:41.685496 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:43:41.686550 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m15:43:41.687600 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:43:41.688126 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:43:41.690782 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:43:41.691780 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:43:41.696780 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m15:43:41.697780 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.698780 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m15:43:41.698780 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:41.704778 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.705778 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.706779 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m15:43:41.729779 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.023 seconds
[0m15:43:41.733304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.734295 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m15:43:41.735294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.738294 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.738294 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m15:43:41.740295 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:43:41.741295 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:43:41.742294 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.742294 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:43:41.750296 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m15:43:41.753293 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m15:43:41.754295 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:43:41.754295 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m15:43:41.758294 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m15:43:41.760295 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m15:43:41.761295 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f12be09-2ca2-4fa5-9477-7bb43eda43ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC2AFBD10>]}
[0m15:43:41.762295 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m15:43:41.763295 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:43:41.764821 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:41.765345 [debug] [MainThread]: On master: BEGIN
[0m15:43:41.765345 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:43:41.771711 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:43:41.772233 [debug] [MainThread]: On master: COMMIT
[0m15:43:41.772752 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:41.773273 [debug] [MainThread]: On master: COMMIT
[0m15:43:41.774324 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:43:41.774841 [debug] [MainThread]: On master: Close
[0m15:43:41.774841 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:43:41.775838 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m15:43:41.775838 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m15:43:41.776838 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:43:41.777677 [info ] [MainThread]: 
[0m15:43:41.778210 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.65 seconds (1.65s).
[0m15:43:41.782471 [debug] [MainThread]: Command end result
[0m15:43:41.814728 [info ] [MainThread]: 
[0m15:43:41.814728 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:43:41.815719 [info ] [MainThread]: 
[0m15:43:41.816719 [error] [MainThread]:   Database Error in model best_selling_film (models\mart\best_selling_film.sql)
  column "fct_pay.amount" must appear in the GROUP BY clause or be used in an aggregate function
  LINE 26: ORDER BY fct_pay.amount DESC
                    ^
  compiled Code at target\run\data_warehouse\models\mart\best_selling_film.sql
[0m15:43:41.817719 [info ] [MainThread]: 
[0m15:43:41.817719 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m15:43:41.818719 [debug] [MainThread]: Command `dbt run` failed at 15:43:41.818719 after 2.56 seconds
[0m15:43:41.819720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC0820800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC25FCB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ACC25FF230>]}
[0m15:43:43.330338 [debug] [MainThread]: Flushing usage events
[0m15:45:20.321221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADD85F7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADA694FB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADF8351F0>]}


============================== 15:45:20.326222 | 39b7a81d-cafc-4e3b-bd23-bd2614e8dddc ==============================
[0m15:45:20.326222 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:45:20.327222 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:45:20.535309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE020CCB0>]}
[0m15:45:20.588310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADFFC46E0>]}
[0m15:45:20.590309 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:45:20.598310 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:45:20.763085 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:45:20.763085 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m15:45:20.989235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADFA9A1B0>]}
[0m15:45:21.089234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE068FFB0>]}
[0m15:45:21.089234 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:45:21.090236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE05C62A0>]}
[0m15:45:21.093236 [info ] [MainThread]: 
[0m15:45:21.093236 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:45:21.098234 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m15:45:21.168808 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:45:21.169808 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:45:21.169808 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:45:21.180809 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.010 seconds
[0m15:45:21.181807 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:45:21.184808 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:45:21.185866 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:45:21.185866 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.192755 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m15:45:21.194319 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:45:21.196956 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:45:21.197586 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:45:21.198113 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.204482 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:45:21.206059 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:45:21.208156 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m15:45:21.208856 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m15:45:21.209385 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.215717 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m15:45:21.217315 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m15:45:21.220178 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_intermediete'
[0m15:45:21.225923 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:45:21.226440 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:45:21.226440 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:45:21.232740 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.233740 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:45:21.233740 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:45:21.236738 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:45:21.238740 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:45:21.239740 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:45:21.240739 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m15:45:21.245373 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:45:21.245931 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:45:21.246450 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.252798 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.253324 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:45:21.253835 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:45:21.256833 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:45:21.257834 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:45:21.258834 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:45:21.259835 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m15:45:21.262471 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:45:21.262999 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:45:21.263525 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.270471 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m15:45:21.270991 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:45:21.271516 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:45:21.274081 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m15:45:21.275079 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:45:21.276077 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:45:21.277078 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m15:45:21.280024 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:45:21.280552 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:45:21.280552 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:21.286862 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.287385 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:45:21.287913 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:45:21.290516 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:45:21.292028 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:45:21.293028 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:45:21.299750 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:21.300273 [debug] [MainThread]: On master: BEGIN
[0m15:45:21.300796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:45:21.306575 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.307660 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:21.307660 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:45:21.314657 [debug] [MainThread]: SQL status: SELECT 38 in 0.006 seconds
[0m15:45:21.316658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1CEC2F0>]}
[0m15:45:21.317658 [debug] [MainThread]: On master: ROLLBACK
[0m15:45:21.317658 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:21.318658 [debug] [MainThread]: On master: BEGIN
[0m15:45:21.319656 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:45:21.320656 [debug] [MainThread]: On master: COMMIT
[0m15:45:21.320656 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:21.321658 [debug] [MainThread]: On master: COMMIT
[0m15:45:21.322685 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:45:21.323204 [debug] [MainThread]: On master: Close
[0m15:45:21.323204 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:45:21.324202 [info ] [MainThread]: 
[0m15:45:21.327887 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:45:21.328885 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m15:45:21.328885 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:45:21.329887 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:45:21.338888 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:45:21.339887 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:45:21.381614 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m15:45:21.383199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.383775 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m15:45:21.384365 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:45:21.391737 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:21.392735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.392735 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m15:45:21.396735 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.003 seconds
[0m15:45:21.404736 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.405736 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m15:45:21.407734 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.411735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.412735 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m15:45:21.414735 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.437735 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:45:21.438735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.438735 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m15:45:21.441734 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:21.447736 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m15:45:21.452735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m15:45:21.453736 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m15:45:21.456733 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.459733 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m15:45:21.460735 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE05C5CA0>]}
[0m15:45:21.461737 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m15:45:21.463387 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:45:21.464443 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:45:21.464979 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m15:45:21.466034 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:45:21.466549 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:45:21.471250 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:45:21.472301 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:45:21.475391 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m15:45:21.476392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.476392 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m15:45:21.477394 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.484391 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:21.484391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.485390 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m15:45:21.487393 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:45:21.490390 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.491390 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m15:45:21.492392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.496391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.496391 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m15:45:21.498392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.500392 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:45:21.501390 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.502391 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m15:45:21.505393 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:21.507392 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m15:45:21.508392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m15:45:21.508392 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m15:45:21.512392 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.514393 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m15:45:21.515392 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1DF66C0>]}
[0m15:45:21.515392 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m15:45:21.516393 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:45:21.517393 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:45:21.518390 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m15:45:21.518390 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:45:21.519390 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:45:21.522392 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:45:21.523391 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:45:21.526391 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m15:45:21.527392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.527392 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m15:45:21.528392 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.556392 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m15:45:21.556392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.557392 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m15:45:21.559394 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:45:21.562392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.563393 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m15:45:21.565391 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.568392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.568392 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m15:45:21.570392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.571392 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:45:21.572392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.572392 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m15:45:21.575390 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:21.578390 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m15:45:21.579391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m15:45:21.580393 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m15:45:21.583390 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.585392 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m15:45:21.586392 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1D12000>]}
[0m15:45:21.586392 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.07s]
[0m15:45:21.587393 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:45:21.588621 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:45:21.589666 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m15:45:21.590191 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:45:21.590708 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:45:21.593844 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:45:21.594360 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:45:21.600647 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m15:45:21.601691 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.602207 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m15:45:21.602207 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.608205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.609205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.610206 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m15:45:21.618206 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:45:21.621206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.622206 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m15:45:21.623206 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.626206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.626206 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m15:45:21.627206 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.630209 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:45:21.631205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.631205 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m15:45:21.635205 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:21.637205 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m15:45:21.638206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m15:45:21.639206 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m15:45:21.642204 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.644206 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m15:45:21.644206 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1D76870>]}
[0m15:45:21.645206 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m15:45:21.647205 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:45:21.648205 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:45:21.649205 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m15:45:21.650205 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:45:21.650205 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:45:21.653206 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:45:21.654206 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:45:21.657206 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m15:45:21.658206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.658206 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m15:45:21.659206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.666205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:21.667205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.668207 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m15:45:21.672208 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m15:45:21.675206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.675206 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m15:45:21.677206 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.680208 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.680208 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m15:45:21.682205 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.684207 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:45:21.684207 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.685206 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m15:45:21.690204 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m15:45:21.693207 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m15:45:21.694206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m15:45:21.694206 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m15:45:21.698208 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.700207 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m15:45:21.701206 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1C4B3B0>]}
[0m15:45:21.702207 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m15:45:21.703207 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:45:21.704128 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:45:21.704658 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m15:45:21.705183 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:45:21.705705 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:45:21.708864 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:45:21.709913 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:45:21.713585 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m15:45:21.714636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.715155 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m15:45:21.715155 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.721152 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.722151 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.723153 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m15:45:21.727150 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m15:45:21.730153 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.731153 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m15:45:21.732152 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.736150 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.737151 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m15:45:21.738152 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.740152 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:45:21.741151 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.741151 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m15:45:21.744149 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:21.747153 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m15:45:21.748153 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m15:45:21.748153 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m15:45:21.752706 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.753699 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m15:45:21.754700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE2171160>]}
[0m15:45:21.755700 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m15:45:21.756699 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:45:21.757701 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:45:21.757701 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m15:45:21.758700 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:45:21.758700 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:45:21.761700 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.762700 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:45:21.766699 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.767700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.768699 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m15:45:21.768699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.774700 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.775700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.775700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m15:45:21.777699 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m15:45:21.781700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.781700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m15:45:21.783701 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.786699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.786699 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m15:45:21.788699 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.789700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:45:21.790700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.790700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m15:45:21.793698 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:45:21.796701 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m15:45:21.797700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m15:45:21.797700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m15:45:21.801698 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.803700 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m15:45:21.804700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE218C3B0>]}
[0m15:45:21.804700 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m15:45:21.805700 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:45:21.806699 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:45:21.807700 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m15:45:21.807700 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:45:21.808700 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:45:21.811700 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:45:21.811700 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:45:21.815699 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m15:45:21.816700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.817700 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m15:45:21.817700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.823698 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.824700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.824700 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m15:45:21.832700 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m15:45:21.835699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.836700 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m15:45:21.837699 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.840699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.840699 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m15:45:21.841701 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.843700 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:45:21.843700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.844700 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m15:45:21.850699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m15:45:21.853698 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m15:45:21.853698 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m15:45:21.854698 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m15:45:21.857698 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.859700 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m15:45:21.859700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1DD4320>]}
[0m15:45:21.860700 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.05s]
[0m15:45:21.861700 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:45:21.863388 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:45:21.863931 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m15:45:21.865509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:45:21.866026 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:45:21.870746 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:45:21.871804 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:45:21.874412 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m15:45:21.875408 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.876411 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m15:45:21.876411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.883923 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:21.883923 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.884924 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m15:45:21.892922 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:45:21.895924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.896925 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m15:45:21.898924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.901924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.902924 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m15:45:21.903924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.904924 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:45:21.905924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.905924 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m15:45:21.916919 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m15:45:21.919919 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m15:45:21.920925 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m15:45:21.920925 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m15:45:21.924919 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.925919 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m15:45:21.926922 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE2195E80>]}
[0m15:45:21.927920 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m15:45:21.928919 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:45:21.929542 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:45:21.930073 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m15:45:21.931135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:45:21.931659 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:45:21.934785 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:45:21.935315 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:45:21.938433 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m15:45:21.939535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.940061 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m15:45:21.940585 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:21.946098 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:21.947096 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.948097 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m15:45:21.954676 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m15:45:21.957673 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.958674 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m15:45:21.959673 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.961675 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.962673 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m15:45:21.964675 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:21.966673 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:45:21.966673 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.967673 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m15:45:21.970674 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:45:21.972673 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m15:45:21.973673 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m15:45:21.973673 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m15:45:21.977673 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:21.978746 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m15:45:21.979740 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1971070>]}
[0m15:45:21.980740 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m15:45:21.981741 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:45:21.982739 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:45:21.983863 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m15:45:21.984409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:45:21.984930 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:45:21.987527 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:45:21.988580 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:45:21.993277 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m15:45:21.993800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:21.994317 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m15:45:21.994830 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.001828 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:22.002827 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:22.002827 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m15:45:22.004827 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m15:45:22.068828 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:22.069827 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m15:45:22.071827 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.073827 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:22.074827 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m15:45:22.075827 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.077827 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:45:22.077827 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:22.078744 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m15:45:22.082735 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.084735 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m15:45:22.085735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m15:45:22.086735 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m15:45:22.089735 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.090735 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m15:45:22.091735 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1DC6F30>]}
[0m15:45:22.092738 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m15:45:22.093738 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:45:22.094398 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:45:22.094969 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m15:45:22.095495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:45:22.096019 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:45:22.099152 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:45:22.100184 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:45:22.103327 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m15:45:22.104362 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.104886 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m15:45:22.105422 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.110934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.111934 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.112934 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m15:45:22.115933 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m15:45:22.118934 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.118934 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m15:45:22.120936 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.122932 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.123932 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m15:45:22.124933 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.126933 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:45:22.126933 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.127935 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m15:45:22.130936 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:22.135933 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m15:45:22.137935 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m15:45:22.138933 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m15:45:22.141933 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.143933 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m15:45:22.144938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE217B350>]}
[0m15:45:22.145935 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m15:45:22.146934 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:45:22.148318 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:45:22.148852 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m15:45:22.149894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:45:22.149894 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:45:22.154632 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:45:22.155689 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:45:22.161388 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m15:45:22.162388 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.163392 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m15:45:22.164391 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.170389 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.171390 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.171390 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m15:45:22.173390 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m15:45:22.176388 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.177387 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m15:45:22.178389 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.181388 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.182388 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m15:45:22.183388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.187387 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:45:22.187387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.188388 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m15:45:22.191389 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:45:22.193387 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m15:45:22.194387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m15:45:22.194387 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m15:45:22.198389 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.199388 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m15:45:22.200388 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1E06A50>]}
[0m15:45:22.201391 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m15:45:22.202390 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:45:22.203172 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:45:22.203721 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m15:45:22.204769 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:45:22.204769 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:45:22.207893 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:45:22.208415 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:45:22.212069 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m15:45:22.213132 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.213661 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m15:45:22.214195 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.220709 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.221709 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.222707 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m15:45:22.231272 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m15:45:22.234988 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.235511 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m15:45:22.237094 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.239734 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.240250 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m15:45:22.241831 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.243911 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:45:22.244427 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.244943 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m15:45:22.249118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.252283 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m15:45:22.252283 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m15:45:22.253282 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m15:45:22.257282 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.258283 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m15:45:22.259285 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE04CE450>]}
[0m15:45:22.260284 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m15:45:22.261283 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:45:22.263008 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:45:22.264086 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m15:45:22.265142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:45:22.265697 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:45:22.268323 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:45:22.269370 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:45:22.273060 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m15:45:22.273060 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.274056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m15:45:22.274056 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.301057 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m15:45:22.302056 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.303057 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m15:45:22.307056 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m15:45:22.310056 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.310056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m15:45:22.311058 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.315057 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.316056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m15:45:22.317056 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.319056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:45:22.319056 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.320056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m15:45:22.323056 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:22.326056 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m15:45:22.326056 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m15:45:22.327057 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m15:45:22.331056 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.333056 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m15:45:22.333056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE0709460>]}
[0m15:45:22.334057 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.07s]
[0m15:45:22.335056 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:45:22.336381 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:45:22.336896 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m15:45:22.337416 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:45:22.338476 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:45:22.343799 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:45:22.344863 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:45:22.349491 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m15:45:22.350491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.351492 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m15:45:22.351492 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.357491 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.358492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.359543 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m15:45:22.364062 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m15:45:22.368059 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.368059 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m15:45:22.370060 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.373059 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.373059 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m15:45:22.375059 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.378060 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:45:22.378060 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.379059 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m15:45:22.383059 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.386063 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m15:45:22.387060 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m15:45:22.387060 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m15:45:22.391059 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.393059 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m15:45:22.394062 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE19218E0>]}
[0m15:45:22.394062 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m15:45:22.396059 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:45:22.397015 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:45:22.398069 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m15:45:22.399119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:45:22.399644 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:45:22.402788 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.403842 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:45:22.422053 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.423054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.424054 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m15:45:22.424054 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.430056 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.431054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.432053 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m15:45:22.434054 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m15:45:22.437053 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.437053 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m15:45:22.439054 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.440054 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:45:22.440054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.441054 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m15:45:22.444055 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m15:45:22.446053 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m15:45:22.450053 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m15:45:22.450053 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m15:45:22.452053 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:45:22.453054 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m15:45:22.454054 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1DD7F50>]}
[0m15:45:22.454054 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.05s]
[0m15:45:22.455054 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:45:22.456354 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:45:22.456869 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m15:45:22.457389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m15:45:22.457914 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:45:22.461055 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:45:22.461577 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:45:22.465244 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m15:45:22.466286 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.466798 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m15:45:22.467323 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.473834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.473834 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.474833 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m15:45:22.482833 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m15:45:22.488834 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.488834 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m15:45:22.490833 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.493833 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.493833 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m15:45:22.494833 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.496838 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:45:22.497834 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.497834 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m15:45:22.502833 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.505833 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m15:45:22.506833 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m15:45:22.506833 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m15:45:22.509833 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.511834 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m15:45:22.512835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE21AA6C0>]}
[0m15:45:22.513836 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m15:45:22.515773 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:45:22.516331 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:45:22.517357 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m15:45:22.517881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:45:22.518406 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:45:22.521535 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:45:22.522057 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:45:22.525201 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m15:45:22.526250 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.526763 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m15:45:22.527285 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.533275 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:22.534274 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.535275 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m15:45:22.544274 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m15:45:22.547276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.548274 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m15:45:22.549275 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.552274 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.553274 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m15:45:22.554274 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.556274 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:45:22.556274 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.557274 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m15:45:22.561274 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.564848 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m15:45:22.565846 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m15:45:22.566845 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m15:45:22.570845 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.571846 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m15:45:22.572846 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1D8DB20>]}
[0m15:45:22.572846 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.05s]
[0m15:45:22.573847 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:45:22.574847 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:45:22.575892 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m15:45:22.576413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:45:22.576924 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:45:22.580666 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:45:22.581712 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:45:22.585361 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m15:45:22.585883 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.586409 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m15:45:22.586923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.592433 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.593433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.593433 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m15:45:22.600433 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m15:45:22.604433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.605434 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m15:45:22.606434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.609433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.609433 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m15:45:22.610433 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.612434 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:45:22.613435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.614434 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m15:45:22.617433 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:22.621434 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m15:45:22.622433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m15:45:22.623433 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m15:45:22.626433 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.628433 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m15:45:22.628433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1D99F70>]}
[0m15:45:22.629434 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m15:45:22.631436 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:45:22.631935 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:45:22.632460 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m15:45:22.633505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m15:45:22.634023 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:45:22.637142 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:45:22.638193 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:45:22.641316 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m15:45:22.642351 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.642912 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m15:45:22.643431 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.650427 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m15:45:22.651427 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.651427 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    fct_pay.amount
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
ORDER BY fct_pay.amount DESC
  );
  
[0m15:45:22.867303 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.215 seconds
[0m15:45:22.870303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.871304 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film" rename to "best_selling_film__dbt_backup"
[0m15:45:22.872304 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.874303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.875303 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m15:45:22.876304 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.878304 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m15:45:22.878304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.879304 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m15:45:22.884304 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m15:45:22.886303 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m15:45:22.887304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m15:45:22.887304 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m15:45:22.891304 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.892303 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m15:45:22.893305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE218E4E0>]}
[0m15:45:22.894304 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 14596[0m in 0.26s]
[0m15:45:22.895305 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:45:22.895305 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:45:22.896305 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m15:45:22.896305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:45:22.897305 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:45:22.900705 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:45:22.901235 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:45:22.904855 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m15:45:22.905894 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.906411 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m15:45:22.906923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:45:22.914253 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m15:45:22.915252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.915252 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m15:45:22.937252 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.021 seconds
[0m15:45:22.940253 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.941254 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m15:45:22.942252 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.945252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.945252 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m15:45:22.947253 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:45:22.949253 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:45:22.950252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.950252 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m15:45:22.954252 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m15:45:22.957252 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m15:45:22.957252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m15:45:22.958252 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m15:45:22.962252 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m15:45:22.963255 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m15:45:22.964255 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39b7a81d-cafc-4e3b-bd23-bd2614e8dddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE17EBA70>]}
[0m15:45:22.965255 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m15:45:22.966253 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:45:22.968058 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:22.968585 [debug] [MainThread]: On master: BEGIN
[0m15:45:22.968585 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:45:22.974922 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:45:22.975444 [debug] [MainThread]: On master: COMMIT
[0m15:45:22.975968 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:22.975968 [debug] [MainThread]: On master: COMMIT
[0m15:45:22.976478 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:45:22.977497 [debug] [MainThread]: On master: Close
[0m15:45:22.978023 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:45:22.978557 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m15:45:22.979072 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m15:45:22.979072 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:45:22.980070 [info ] [MainThread]: 
[0m15:45:22.981017 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.89 seconds (1.89s).
[0m15:45:22.985940 [debug] [MainThread]: Command end result
[0m15:45:23.020681 [info ] [MainThread]: 
[0m15:45:23.021688 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:45:23.022683 [info ] [MainThread]: 
[0m15:45:23.023682 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m15:45:23.024682 [debug] [MainThread]: Command `dbt run` succeeded at 15:45:23.024682 after 2.81 seconds
[0m15:45:23.024682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADF732F00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017AE1BA9160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017ADFEC4E90>]}
[0m15:45:35.438683 [debug] [MainThread]: Flushing usage events
[0m15:45:40.845827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA55443E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA5E6F4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA5E6D730>]}


============================== 15:45:40.850829 | 290d0e93-bf9e-4677-9bde-0a664de77cb3 ==============================
[0m15:45:40.850829 [info ] [MainThread]: Running with dbt=1.8.5
[0m15:45:40.851829 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:45:41.045035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA636E7E0>]}
[0m15:45:41.097136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA611B770>]}
[0m15:45:41.099134 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m15:45:41.107136 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m15:45:41.267136 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:45:41.267136 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:45:41.308136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA665BFE0>]}
[0m15:45:41.331136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA7796E40>]}
[0m15:45:41.332136 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m15:45:41.333137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA661F740>]}
[0m15:45:41.336136 [info ] [MainThread]: 
[0m15:45:41.336136 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:45:41.341135 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m15:45:41.418135 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:45:41.419135 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m15:45:41.419135 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:45:41.430135 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m15:45:41.430135 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m15:45:41.431137 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m15:45:41.434134 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:45:41.436134 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m15:45:41.437136 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m15:45:41.437136 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m15:45:41.440394 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:45:41.440917 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m15:45:41.441440 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:41.447777 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:41.448302 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m15:45:41.448820 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m15:45:41.451910 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:45:41.452908 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m15:45:41.453906 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m15:45:41.454907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m15:45:41.456908 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:45:41.457931 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m15:45:41.458459 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:41.465312 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:41.465856 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m15:45:41.466376 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m15:45:41.468976 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m15:45:41.469976 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m15:45:41.470972 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m15:45:41.471974 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_raw)
[0m15:45:41.475569 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:45:41.476085 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m15:45:41.476649 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:41.482968 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:41.483492 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m15:45:41.484009 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m15:45:41.486583 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m15:45:41.487581 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m15:45:41.488581 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m15:45:41.495531 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:41.496052 [debug] [MainThread]: On master: BEGIN
[0m15:45:41.496571 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:45:41.502864 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m15:45:41.503381 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:41.503381 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:45:41.541378 [debug] [MainThread]: SQL status: SELECT 38 in 0.037 seconds
[0m15:45:41.544381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '290d0e93-bf9e-4677-9bde-0a664de77cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA60838F0>]}
[0m15:45:41.544381 [debug] [MainThread]: On master: ROLLBACK
[0m15:45:41.545380 [debug] [MainThread]: On master: Close
[0m15:45:41.546379 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:45:41.547382 [info ] [MainThread]: 
[0m15:45:41.551380 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m15:45:41.551380 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m15:45:41.552381 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m15:45:41.560381 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m15:45:41.561380 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m15:45:41.562381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m15:45:41.562381 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m15:45:41.563380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m15:45:41.564383 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m15:45:41.567381 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m15:45:41.568380 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m15:45:41.569381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m15:45:41.569381 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m15:45:41.570380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m15:45:41.571380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m15:45:41.573380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m15:45:41.574380 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m15:45:41.575381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m15:45:41.575381 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m15:45:41.576380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m15:45:41.576380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m15:45:41.579380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m15:45:41.580381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m15:45:41.581379 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m15:45:41.582378 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m15:45:41.582378 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m15:45:41.583380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m15:45:41.586380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m15:45:41.587380 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m15:45:41.588381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m15:45:41.589379 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m15:45:41.589379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m15:45:41.590380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m15:45:41.593379 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m15:45:41.594381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m15:45:41.594381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m15:45:41.595380 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m15:45:41.595380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m15:45:41.596380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m15:45:41.599380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m15:45:41.601381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m15:45:41.602379 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m15:45:41.602379 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m15:45:41.603380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m15:45:41.603380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m15:45:41.608378 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m15:45:41.609379 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m15:45:41.609379 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m15:45:41.610379 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m15:45:41.610379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m15:45:41.611379 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m15:45:41.614379 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m15:45:41.615381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m15:45:41.616380 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m15:45:41.616380 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m15:45:41.617379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m15:45:41.617379 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m15:45:41.620379 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m15:45:41.621381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m15:45:41.622381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m15:45:41.622381 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m15:45:41.623379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m15:45:41.623379 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m15:45:41.626379 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m15:45:41.627381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m15:45:41.627381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m15:45:41.628380 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m15:45:41.628380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m15:45:41.629380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m15:45:41.632378 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m15:45:41.633383 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m15:45:41.634380 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m15:45:41.634380 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m15:45:41.635379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m15:45:41.635379 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m15:45:41.638378 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m15:45:41.639381 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m15:45:41.640381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m15:45:41.640381 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m15:45:41.641381 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m15:45:41.642380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m15:45:41.644380 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m15:45:41.645380 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m15:45:41.646381 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m15:45:41.646381 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m15:45:41.647383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m15:45:41.648380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m15:45:41.651028 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m15:45:41.652029 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m15:45:41.653029 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m15:45:41.653029 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m15:45:41.654028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m15:45:41.654028 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m15:45:41.657029 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m15:45:41.658028 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m15:45:41.658028 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m15:45:41.659029 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m15:45:41.659029 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m15:45:41.660029 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m15:45:41.662027 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m15:45:41.663029 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m15:45:41.664030 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m15:45:41.665029 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:45:41.666028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m15:45:41.666028 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:45:41.678027 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:45:41.679029 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:45:41.680027 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:45:41.681028 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:45:41.681028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m15:45:41.682029 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:45:41.688029 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m15:45:41.689029 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:45:41.690029 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m15:45:41.690029 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m15:45:41.691030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m15:45:41.691030 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m15:45:41.695598 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m15:45:41.696598 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m15:45:41.697600 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m15:45:41.698600 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m15:45:41.699598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m15:45:41.699598 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m15:45:41.702599 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m15:45:41.703599 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m15:45:41.704599 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m15:45:41.704599 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m15:45:41.705598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m15:45:41.705598 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m15:45:41.708599 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m15:45:41.709598 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m15:45:41.710598 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m15:45:41.710598 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:45:41.711598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m15:45:41.711598 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:45:41.715597 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m15:45:41.717601 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:45:41.717601 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m15:45:41.718600 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:45:41.719598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m15:45:41.719598 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:45:41.723597 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m15:45:41.724599 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:45:41.725600 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m15:45:41.725600 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m15:45:41.726599 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.best_selling_film)
[0m15:45:41.726599 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m15:45:41.730598 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m15:45:41.731600 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m15:45:41.732599 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m15:45:41.732599 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m15:45:41.733601 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m15:45:41.733601 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m15:45:41.736597 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m15:45:41.737599 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m15:45:41.738597 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m15:45:41.739598 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:45:41.739598 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m15:45:41.740599 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m15:45:41.744598 [debug] [MainThread]: Command end result
[0m15:45:41.831599 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m15:45:41.832599 [info ] [MainThread]: Building catalog
[0m15:45:41.843597 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m15:45:41.850597 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m15:45:41.851597 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m15:45:41.851597 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:45:41.858598 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m15:45:41.858598 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m15:45:41.859598 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_selling_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m15:45:41.865597 [debug] [ThreadPool]: SQL status: SELECT 205 in 0.005 seconds
[0m15:45:41.877598 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m15:45:41.878599 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m15:45:41.925344 [info ] [MainThread]: Catalog written to C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\target\catalog.json
[0m15:45:41.927344 [debug] [MainThread]: Command `dbt docs generate` succeeded at 15:45:41.926345 after 1.17 seconds
[0m15:45:41.927344 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m15:45:41.927344 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m15:45:41.928345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA6173B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA5FEC740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BA5F34B30>]}
[0m15:45:41.928345 [debug] [MainThread]: Flushing usage events
[0m16:21:14.682881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019872698FE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001987206B890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019874831A30>]}


============================== 16:21:14.690088 | b2ca0c1d-5c47-4819-aa7d-e4353e43496f ==============================
[0m16:21:14.690088 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:21:14.691664 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:21:14.719552 [info ] [MainThread]: dbt version: 1.8.5
[0m16:21:14.720554 [info ] [MainThread]: python version: 3.12.4
[0m16:21:14.721553 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m16:21:14.722555 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m16:21:14.835552 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m16:21:14.836553 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m16:21:14.836553 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m16:21:14.838552 [info ] [MainThread]: adapter type: postgres
[0m16:21:14.839554 [info ] [MainThread]: adapter version: 1.8.2
[0m16:21:14.925109 [info ] [MainThread]: Configuration:
[0m16:21:14.926109 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:21:14.927109 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:21:14.927109 [info ] [MainThread]: Required dependencies:
[0m16:21:14.928110 [debug] [MainThread]: Executing "git --help"
[0m16:21:14.963109 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:21:14.964111 [debug] [MainThread]: STDERR: "b''"
[0m16:21:14.964111 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:21:14.965109 [info ] [MainThread]: Connection:
[0m16:21:14.966111 [info ] [MainThread]:   host: localhost
[0m16:21:14.966111 [info ] [MainThread]:   port: 5433
[0m16:21:14.967110 [info ] [MainThread]:   user: postgres
[0m16:21:14.967110 [info ] [MainThread]:   database: data_warehouse
[0m16:21:14.968110 [info ] [MainThread]:   schema: dbt_dev
[0m16:21:14.968110 [info ] [MainThread]:   connect_timeout: 10
[0m16:21:14.969110 [info ] [MainThread]:   role: None
[0m16:21:14.969110 [info ] [MainThread]:   search_path: None
[0m16:21:14.970109 [info ] [MainThread]:   keepalives_idle: 0
[0m16:21:14.970109 [info ] [MainThread]:   sslmode: None
[0m16:21:14.971110 [info ] [MainThread]:   sslcert: None
[0m16:21:14.972112 [info ] [MainThread]:   sslkey: None
[0m16:21:14.973111 [info ] [MainThread]:   sslrootcert: None
[0m16:21:14.973111 [info ] [MainThread]:   application_name: dbt
[0m16:21:14.974110 [info ] [MainThread]:   retries: 1
[0m16:21:14.975110 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:21:14.975110 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m16:21:15.040110 [debug] [MainThread]: Using postgres connection "debug"
[0m16:21:15.041109 [debug] [MainThread]: On debug: select 1 as id
[0m16:21:15.041109 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:21:15.058111 [debug] [MainThread]: SQL status: SELECT 1 in 0.017 seconds
[0m16:21:15.059111 [debug] [MainThread]: On debug: Close
[0m16:21:15.060109 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:21:15.061112 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:21:15.062777 [debug] [MainThread]: Command `dbt debug` succeeded at 16:21:15.062777 after 0.51 seconds
[0m16:21:15.063302 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m16:21:15.063826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019874DABB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001987206B890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019871CB5430>]}
[0m16:21:15.064348 [debug] [MainThread]: Flushing usage events
[0m16:21:20.763055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE12CEE40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE04308F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE149B740>]}


============================== 16:21:20.767054 | 78f5329a-27f9-4762-bad5-b02c6fe9c4cc ==============================
[0m16:21:20.767054 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:21:20.768053 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m16:21:20.978598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE3E50B90>]}
[0m16:21:21.031161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE3967440>]}
[0m16:21:21.033162 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:21:21.041162 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:21:21.218583 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:21:21.219583 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m16:21:21.448161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE540B410>]}
[0m16:21:21.555161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE418F620>]}
[0m16:21:21.556162 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m16:21:21.556162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE534ADE0>]}
[0m16:21:21.560162 [info ] [MainThread]: 
[0m16:21:21.561161 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:21:21.565161 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m16:21:21.635795 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:21:21.635795 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:21:21.636797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:21.645796 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m16:21:21.647796 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:21:21.649796 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:21:21.650309 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:21:21.650838 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.657804 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m16:21:21.659358 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:21:21.661456 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:21:21.661979 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:21:21.662504 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.668318 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m16:21:21.669924 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:21:21.672034 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:21:21.673098 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:21:21.673635 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.679959 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m16:21:21.681522 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:21:21.684393 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m16:21:21.691248 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:21:21.692300 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m16:21:21.692300 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:21.698956 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.698956 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:21:21.699955 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m16:21:21.702958 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m16:21:21.703957 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m16:21:21.705958 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m16:21:21.706956 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m16:21:21.711050 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:21:21.711564 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m16:21:21.711564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.717388 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.717911 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:21:21.718432 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m16:21:21.721508 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m16:21:21.722509 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m16:21:21.724508 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m16:21:21.725509 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m16:21:21.728826 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:21:21.729352 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m16:21:21.729352 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.735180 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.735703 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:21:21.736225 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m16:21:21.739307 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m16:21:21.740307 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m16:21:21.741308 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m16:21:21.742307 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m16:21:21.744888 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:21:21.745415 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m16:21:21.745415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:21.751232 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.751760 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:21:21.752280 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m16:21:21.755422 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m16:21:21.757417 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m16:21:21.758416 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m16:21:21.766571 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:21.767092 [debug] [MainThread]: On master: BEGIN
[0m16:21:21.767613 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:21:21.774369 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.774369 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:21.775370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:21:21.813368 [debug] [MainThread]: SQL status: SELECT 38 in 0.038 seconds
[0m16:21:21.815370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE57FDC10>]}
[0m16:21:21.816370 [debug] [MainThread]: On master: ROLLBACK
[0m16:21:21.817369 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:21.817369 [debug] [MainThread]: On master: BEGIN
[0m16:21:21.819369 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:21:21.819369 [debug] [MainThread]: On master: COMMIT
[0m16:21:21.819369 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:21.820370 [debug] [MainThread]: On master: COMMIT
[0m16:21:21.821369 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:21:21.821369 [debug] [MainThread]: On master: Close
[0m16:21:21.823370 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:21:21.824370 [info ] [MainThread]: 
[0m16:21:21.828601 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m16:21:21.829123 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m16:21:21.830169 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m16:21:21.830688 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m16:21:21.837945 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m16:21:21.838947 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m16:21:21.878945 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m16:21:21.879944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.880945 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m16:21:21.880945 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:21:21.887944 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.888944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.888944 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m16:21:21.891944 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m16:21:21.897944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.898945 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m16:21:21.899945 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:21.901945 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.902945 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m16:21:21.903945 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:21.923946 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m16:21:21.924946 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.924946 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m16:21:21.927943 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m16:21:21.933943 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m16:21:21.939944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:21:21.939944 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m16:21:21.943944 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:21.945943 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m16:21:21.947943 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE1850C80>]}
[0m16:21:21.947943 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m16:21:21.949838 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m16:21:21.950383 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m16:21:21.950912 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m16:21:21.951949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m16:21:21.951949 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m16:21:21.957160 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m16:21:21.958204 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m16:21:21.961800 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m16:21:21.962800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.962800 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m16:21:21.963801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:21.969802 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:21.970799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.970799 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m16:21:21.974800 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m16:21:21.977801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.978801 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m16:21:21.979801 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:21.982801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.982801 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m16:21:21.983800 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:21.985801 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m16:21:21.985801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.986801 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m16:21:21.989802 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:21.993799 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m16:21:21.994799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:21:21.994799 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m16:21:21.998800 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.000801 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m16:21:22.000801 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE58F68D0>]}
[0m16:21:22.001800 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m16:21:22.003800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m16:21:22.004356 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m16:21:22.005429 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m16:21:22.006520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m16:21:22.007051 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m16:21:22.010185 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m16:21:22.011226 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m16:21:22.014922 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m16:21:22.015921 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.015921 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m16:21:22.016922 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.022923 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.023924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.024925 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m16:21:22.026925 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m16:21:22.030486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.031487 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m16:21:22.032486 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.034487 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.035487 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m16:21:22.036486 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.038487 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m16:21:22.038487 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.039490 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m16:21:22.043487 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.046487 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m16:21:22.047486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:21:22.047486 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m16:21:22.051486 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.052487 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m16:21:22.053487 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE57D7680>]}
[0m16:21:22.054488 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m16:21:22.055486 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m16:21:22.056908 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m16:21:22.057966 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m16:21:22.058486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m16:21:22.059013 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m16:21:22.062188 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m16:21:22.063244 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m16:21:22.068429 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m16:21:22.069429 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.069429 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m16:21:22.070431 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.078431 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m16:21:22.079430 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.079430 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m16:21:22.088429 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m16:21:22.093430 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.094431 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m16:21:22.095430 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.098430 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.099430 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m16:21:22.100429 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.102430 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m16:21:22.102430 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.103430 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m16:21:22.107431 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.110431 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m16:21:22.111431 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:21:22.111431 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m16:21:22.115429 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:21:22.117431 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m16:21:22.118430 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE59025D0>]}
[0m16:21:22.119431 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m16:21:22.120429 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m16:21:22.121040 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m16:21:22.122097 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m16:21:22.123735 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m16:21:22.124263 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m16:21:22.127414 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m16:21:22.128480 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m16:21:22.132131 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m16:21:22.133125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.133125 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m16:21:22.134126 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.141129 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.142127 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.143129 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m16:21:22.147127 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m16:21:22.151125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.151125 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m16:21:22.152125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.157129 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.157129 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m16:21:22.159127 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.162128 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m16:21:22.163127 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.163127 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m16:21:22.167126 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.170126 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m16:21:22.171128 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:21:22.171128 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m16:21:22.176127 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:21:22.178127 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m16:21:22.179129 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE586E7E0>]}
[0m16:21:22.180127 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.06s]
[0m16:21:22.181126 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m16:21:22.182128 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m16:21:22.182128 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m16:21:22.183125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m16:21:22.184125 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m16:21:22.187126 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m16:21:22.188126 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m16:21:22.192126 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m16:21:22.193127 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.194127 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m16:21:22.194127 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.200125 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.201125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.202125 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m16:21:22.206128 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m16:21:22.209126 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.210125 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m16:21:22.211128 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.215125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.216126 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m16:21:22.217125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.219126 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m16:21:22.219126 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.220126 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m16:21:22.224128 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.227126 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m16:21:22.228125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:21:22.228125 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m16:21:22.232126 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.233127 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m16:21:22.234125 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE58D1310>]}
[0m16:21:22.235126 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m16:21:22.236126 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m16:21:22.236690 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m16:21:22.237218 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m16:21:22.238267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m16:21:22.238798 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m16:21:22.241941 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.243518 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m16:21:22.246643 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.247730 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.248247 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m16:21:22.248247 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.254245 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.255246 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.256247 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m16:21:22.258249 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m16:21:22.262245 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.262245 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m16:21:22.264247 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.267245 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.267245 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m16:21:22.268245 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.270246 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m16:21:22.270246 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.271246 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m16:21:22.274246 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.277246 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m16:21:22.277246 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:21:22.278246 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m16:21:22.282246 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.283246 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m16:21:22.284246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE5C70740>]}
[0m16:21:22.285245 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m16:21:22.286246 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m16:21:22.286665 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m16:21:22.287697 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m16:21:22.288236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m16:21:22.288764 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m16:21:22.292961 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m16:21:22.293999 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m16:21:22.297721 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m16:21:22.298721 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.298721 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m16:21:22.298721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.305719 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.305719 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.306724 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m16:21:22.314718 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m16:21:22.317719 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.318720 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m16:21:22.319720 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.322723 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.323722 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m16:21:22.325719 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.327720 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:21:22.327720 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.327720 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:21:22.332718 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:21:22.335719 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m16:21:22.336720 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:21:22.336720 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m16:21:22.340719 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.342720 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m16:21:22.342720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE5C50770>]}
[0m16:21:22.343720 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.05s]
[0m16:21:22.344721 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m16:21:22.345936 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m16:21:22.346460 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m16:21:22.347512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m16:21:22.348034 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m16:21:22.352153 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m16:21:22.353154 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m16:21:22.357155 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m16:21:22.359155 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.359155 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m16:21:22.360154 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.366154 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.366154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.367154 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m16:21:22.376154 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m16:21:22.379154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.380154 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m16:21:22.381153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.384154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.384154 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m16:21:22.385154 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.387154 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m16:21:22.387154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.388154 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m16:21:22.394153 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:21:22.397154 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m16:21:22.398154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:21:22.398154 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m16:21:22.402156 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.403155 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m16:21:22.404154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE5C62060>]}
[0m16:21:22.405154 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m16:21:22.407156 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m16:21:22.407156 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m16:21:22.408640 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m16:21:22.409164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m16:21:22.409685 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m16:21:22.412806 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m16:21:22.413856 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m16:21:22.416981 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m16:21:22.418089 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.418616 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m16:21:22.419128 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.425639 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.426638 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.426638 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m16:21:22.432637 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m16:21:22.436188 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.437187 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m16:21:22.438188 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.441190 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.442189 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m16:21:22.443187 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.445188 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m16:21:22.445188 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.446188 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m16:21:22.449186 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.451189 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m16:21:22.452188 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:21:22.453188 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m16:21:22.457188 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.458189 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m16:21:22.459189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE57CF710>]}
[0m16:21:22.460188 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m16:21:22.461189 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m16:21:22.462188 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m16:21:22.462188 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m16:21:22.463187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m16:21:22.463187 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m16:21:22.466186 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m16:21:22.467188 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m16:21:22.472187 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m16:21:22.473189 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.474188 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m16:21:22.474188 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.481188 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.482188 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.482188 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m16:21:22.484187 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.001 seconds
[0m16:21:22.545705 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.545705 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m16:21:22.547702 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.549703 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.550703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m16:21:22.551704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.553703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m16:21:22.553703 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.554703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m16:21:22.557703 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.560703 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m16:21:22.560703 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:21:22.561703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m16:21:22.564701 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.566703 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m16:21:22.566703 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE58A3BC0>]}
[0m16:21:22.567703 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.10s]
[0m16:21:22.568704 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m16:21:22.569664 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m16:21:22.570196 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m16:21:22.570728 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m16:21:22.571244 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m16:21:22.575545 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m16:21:22.576613 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m16:21:22.579779 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m16:21:22.580825 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.580825 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m16:21:22.581822 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.587820 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.587820 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.588821 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m16:21:22.591845 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m16:21:22.594822 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.595822 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m16:21:22.596821 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.599821 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.599821 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m16:21:22.600822 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.602822 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m16:21:22.602822 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.603822 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m16:21:22.606824 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.609821 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m16:21:22.610822 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:21:22.610822 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m16:21:22.614823 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.615822 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m16:21:22.616822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE52E9100>]}
[0m16:21:22.617822 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m16:21:22.618821 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m16:21:22.619458 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m16:21:22.620032 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m16:21:22.621105 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m16:21:22.621620 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m16:21:22.625318 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m16:21:22.626363 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m16:21:22.630022 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m16:21:22.631058 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.631058 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m16:21:22.632058 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.638613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.639617 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.640615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m16:21:22.643614 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m16:21:22.646614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.646614 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m16:21:22.648614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.650615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.651615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m16:21:22.652615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.656615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m16:21:22.657617 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.658615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m16:21:22.661617 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.663615 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m16:21:22.664615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:21:22.665615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m16:21:22.668615 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.670615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m16:21:22.670615 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE590F350>]}
[0m16:21:22.671615 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m16:21:22.674196 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m16:21:22.674721 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m16:21:22.675250 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m16:21:22.676302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m16:21:22.676827 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m16:21:22.679431 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m16:21:22.680475 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m16:21:22.684137 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m16:21:22.685185 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.685700 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m16:21:22.685700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.692699 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.693699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.693699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m16:21:22.701700 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.007 seconds
[0m16:21:22.705700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.706702 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m16:21:22.708698 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.710699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.711699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m16:21:22.712699 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.714699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m16:21:22.714699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.715699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m16:21:22.718697 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.721697 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m16:21:22.723699 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:21:22.723699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m16:21:22.727698 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.729699 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m16:21:22.730699 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE5903830>]}
[0m16:21:22.730699 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m16:21:22.731699 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m16:21:22.733031 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m16:21:22.733560 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m16:21:22.734611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m16:21:22.735130 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m16:21:22.737733 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m16:21:22.738786 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m16:21:22.742457 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m16:21:22.744061 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.744579 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m16:21:22.744579 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.763577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m16:21:22.763577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.764574 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m16:21:22.768579 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m16:21:22.771575 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.771575 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m16:21:22.773574 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.777575 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.777575 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m16:21:22.778576 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.780576 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m16:21:22.781576 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.781576 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m16:21:22.784574 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.786574 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m16:21:22.787574 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:21:22.788574 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m16:21:22.792575 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.794576 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m16:21:22.795575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE52EAF60>]}
[0m16:21:22.795575 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m16:21:22.796576 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m16:21:22.797834 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m16:21:22.798363 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m16:21:22.799408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m16:21:22.799408 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m16:21:22.804600 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m16:21:22.805686 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m16:21:22.810360 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m16:21:22.811362 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.811362 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m16:21:22.812364 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.818362 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.819362 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.819362 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m16:21:22.824362 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m16:21:22.827362 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.827362 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m16:21:22.829363 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.832362 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.832362 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m16:21:22.833362 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.835363 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m16:21:22.835363 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.836436 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m16:21:22.839951 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.842952 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m16:21:22.842952 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:21:22.843953 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m16:21:22.846951 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:22.848953 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m16:21:22.849953 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE39FE930>]}
[0m16:21:22.849953 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m16:21:22.850953 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m16:21:22.851953 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m16:21:22.852952 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m16:21:22.852952 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m16:21:22.853951 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m16:21:22.856954 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.857953 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m16:21:22.875953 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.876953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.877953 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m16:21:22.877953 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.884952 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:22.884952 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.885953 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m16:21:22.887953 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m16:21:22.891953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.891953 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m16:21:22.893954 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.895953 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m16:21:22.895953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.896953 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m16:21:22.899953 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:21:22.901952 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m16:21:22.905953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:21:22.906952 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m16:21:22.908953 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m16:21:22.909954 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m16:21:22.910953 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE57C36B0>]}
[0m16:21:22.911954 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m16:21:22.912953 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m16:21:22.913807 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m16:21:22.914406 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m16:21:22.915458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m16:21:22.915983 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m16:21:22.919127 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m16:21:22.919663 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m16:21:22.924430 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m16:21:22.925941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.925941 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m16:21:22.926941 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.933940 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.933940 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.934941 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m16:21:22.942943 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m16:21:22.948940 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.948940 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m16:21:22.950942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.953940 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.954942 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m16:21:22.956940 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:22.958941 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m16:21:22.958941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.959942 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m16:21:22.964939 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:21:22.967941 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m16:21:22.968941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:21:22.968941 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m16:21:22.973946 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:21:22.975940 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m16:21:22.976940 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE5C88A10>]}
[0m16:21:22.977942 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m16:21:22.978942 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m16:21:22.979774 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m16:21:22.980304 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m16:21:22.981335 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m16:21:22.981857 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m16:21:22.985029 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m16:21:22.985557 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m16:21:22.989797 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m16:21:22.990843 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:22.990843 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m16:21:22.991841 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:22.998841 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:22.998841 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:22.999840 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m16:21:23.009845 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m16:21:23.012840 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:23.013842 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m16:21:23.014841 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.017841 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:23.017841 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m16:21:23.018842 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.020842 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m16:21:23.021841 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:23.021841 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m16:21:23.029841 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m16:21:23.032841 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m16:21:23.032841 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:21:23.033841 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m16:21:23.036840 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:23.038842 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m16:21:23.039845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE57CFCB0>]}
[0m16:21:23.041492 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m16:21:23.042018 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m16:21:23.043178 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m16:21:23.043703 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m16:21:23.044752 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m16:21:23.045282 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m16:21:23.047902 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m16:21:23.048948 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m16:21:23.052069 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m16:21:23.052588 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.053647 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m16:21:23.054170 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:23.061684 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m16:21:23.062685 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.062685 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m16:21:23.069684 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m16:21:23.073686 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.073686 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m16:21:23.075685 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.078686 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.079685 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m16:21:23.080686 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.082685 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m16:21:23.082685 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.082685 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m16:21:23.085683 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m16:21:23.091685 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m16:21:23.093685 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:21:23.093685 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m16:21:23.097688 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:23.099686 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m16:21:23.099686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE521E720>]}
[0m16:21:23.100686 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m16:21:23.101685 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m16:21:23.102686 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m16:21:23.102686 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m16:21:23.103684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m16:21:23.104685 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m16:21:23.108685 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m16:21:23.110686 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m16:21:23.113684 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m16:21:23.114686 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.114686 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m16:21:23.115685 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:23.122686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:21:23.123687 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.124686 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    dim_rnt.customer_id,
    COUNT(dim_rnt.customer_id) AS total_customer
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id, dim_fm.title, dim_rnt.customer_id
ORDER BY total_customer DESC
  );
  
[0m16:21:23.385492 [debug] [Thread-1 (]: SQL status: SELECT 14423 in 0.260 seconds
[0m16:21:23.389493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.390493 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film" rename to "best_selling_film__dbt_backup"
[0m16:21:23.392494 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.394495 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.395495 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m16:21:23.396493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.398495 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m16:21:23.398495 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.398495 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m16:21:23.403492 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:21:23.406495 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m16:21:23.407495 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:21:23.407495 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m16:21:23.411492 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:23.412496 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m16:21:23.413492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE546D160>]}
[0m16:21:23.413492 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 14423[0m in 0.31s]
[0m16:21:23.414495 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m16:21:23.415492 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m16:21:23.415492 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m16:21:23.416493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m16:21:23.417492 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m16:21:23.420166 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m16:21:23.421206 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m16:21:23.425205 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m16:21:23.426207 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.426207 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m16:21:23.427206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:23.433207 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:21:23.433207 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.434203 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m16:21:23.456773 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.022 seconds
[0m16:21:23.459776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.460774 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m16:21:23.461773 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.464775 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.464775 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m16:21:23.465775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:21:23.467776 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m16:21:23.468776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.468776 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m16:21:23.473773 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:21:23.476773 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m16:21:23.477773 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:21:23.477773 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m16:21:23.481775 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:21:23.482777 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m16:21:23.483776 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78f5329a-27f9-4762-bad5-b02c6fe9c4cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE4083680>]}
[0m16:21:23.484776 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m16:21:23.485774 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m16:21:23.487034 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:23.487565 [debug] [MainThread]: On master: BEGIN
[0m16:21:23.488095 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:21:23.494431 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:21:23.494955 [debug] [MainThread]: On master: COMMIT
[0m16:21:23.495481 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:23.496034 [debug] [MainThread]: On master: COMMIT
[0m16:21:23.497093 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m16:21:23.497616 [debug] [MainThread]: On master: Close
[0m16:21:23.498611 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:21:23.498611 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m16:21:23.499616 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m16:21:23.499616 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m16:21:23.500611 [info ] [MainThread]: 
[0m16:21:23.501544 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.94 seconds (1.94s).
[0m16:21:23.505741 [debug] [MainThread]: Command end result
[0m16:21:23.546594 [info ] [MainThread]: 
[0m16:21:23.547597 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:21:23.547597 [info ] [MainThread]: 
[0m16:21:23.548595 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m16:21:23.549595 [debug] [MainThread]: Command `dbt run` succeeded at 16:21:23.549595 after 2.88 seconds
[0m16:21:23.550598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE3984EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE149B740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026DE4065E80>]}
[0m16:21:24.898800 [debug] [MainThread]: Flushing usage events
[0m16:21:41.762801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF808AF6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF823872F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF831877D0>]}


============================== 16:21:41.767805 | 96890b28-154d-4dfc-8fc1-03e9ef6436e0 ==============================
[0m16:21:41.767805 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:21:41.767805 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:21:41.967741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF8339E6F0>]}
[0m16:21:42.019841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF80E58F80>]}
[0m16:21:42.020842 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:21:42.029842 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:21:42.187869 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:21:42.188869 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:21:42.229427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF834DDD30>]}
[0m16:21:42.254414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF838B2F30>]}
[0m16:21:42.254428 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m16:21:42.255425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF837D05C0>]}
[0m16:21:42.258426 [info ] [MainThread]: 
[0m16:21:42.259425 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:21:42.264424 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m16:21:42.338422 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:21:42.338422 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m16:21:42.339425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:42.349423 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m16:21:42.349423 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:21:42.350422 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m16:21:42.353422 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m16:21:42.354444 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m16:21:42.355431 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m16:21:42.357433 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m16:21:42.360948 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:21:42.361483 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m16:21:42.361483 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:42.367307 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:42.367836 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:21:42.368360 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m16:21:42.370455 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m16:21:42.372483 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m16:21:42.374451 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m16:21:42.375452 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m16:21:42.377819 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:21:42.378339 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m16:21:42.378868 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:42.384674 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:21:42.385201 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:21:42.385729 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m16:21:42.388401 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m16:21:42.390408 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m16:21:42.392399 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m16:21:42.393401 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediete)
[0m16:21:42.395815 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:21:42.396342 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m16:21:42.396871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:21:42.403776 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m16:21:42.404300 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:21:42.404827 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m16:21:42.408404 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m16:21:42.410404 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m16:21:42.411402 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m16:21:42.417933 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:42.418464 [debug] [MainThread]: On master: BEGIN
[0m16:21:42.418998 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:21:42.425350 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m16:21:42.426346 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:42.427349 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:21:42.466355 [debug] [MainThread]: SQL status: SELECT 38 in 0.039 seconds
[0m16:21:42.468359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96890b28-154d-4dfc-8fc1-03e9ef6436e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF8366BE90>]}
[0m16:21:42.469360 [debug] [MainThread]: On master: ROLLBACK
[0m16:21:42.470355 [debug] [MainThread]: On master: Close
[0m16:21:42.470355 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:21:42.471357 [info ] [MainThread]: 
[0m16:21:42.475459 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m16:21:42.475985 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m16:21:42.476512 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m16:21:42.484455 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m16:21:42.484971 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m16:21:42.485970 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m16:21:42.486969 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m16:21:42.486969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m16:21:42.487969 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m16:21:42.491970 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m16:21:42.492969 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m16:21:42.493972 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m16:21:42.494969 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m16:21:42.494969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m16:21:42.495969 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m16:21:42.497968 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m16:21:42.498968 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m16:21:42.499970 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m16:21:42.500969 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m16:21:42.500969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m16:21:42.501969 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m16:21:42.503969 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m16:21:42.504968 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m16:21:42.505971 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m16:21:42.506972 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m16:21:42.506972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m16:21:42.507970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m16:21:42.510971 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m16:21:42.512969 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m16:21:42.512969 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m16:21:42.513970 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m16:21:42.514969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m16:21:42.514969 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m16:21:42.517968 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m16:21:42.517968 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m16:21:42.518969 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m16:21:42.519968 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m16:21:42.519968 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m16:21:42.520973 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m16:21:42.522970 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m16:21:42.524969 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m16:21:42.525970 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m16:21:42.525970 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m16:21:42.526972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m16:21:42.526972 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m16:21:42.530968 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m16:21:42.531968 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m16:21:42.532971 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m16:21:42.532971 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m16:21:42.533969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m16:21:42.533969 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m16:21:42.536968 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m16:21:42.537969 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m16:21:42.537969 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m16:21:42.538969 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m16:21:42.539970 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m16:21:42.539970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m16:21:42.543974 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m16:21:42.544973 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m16:21:42.544973 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m16:21:42.545973 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m16:21:42.545973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m16:21:42.546973 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m16:21:42.549973 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m16:21:42.549973 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m16:21:42.550973 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m16:21:42.551972 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m16:21:42.551972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m16:21:42.551972 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m16:21:42.554503 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m16:21:42.555497 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m16:21:42.556499 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m16:21:42.557498 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m16:21:42.557498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m16:21:42.558498 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m16:21:42.561498 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m16:21:42.561498 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m16:21:42.562497 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m16:21:42.563498 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m16:21:42.563498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m16:21:42.564497 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m16:21:42.566497 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m16:21:42.567498 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m16:21:42.568498 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m16:21:42.568498 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m16:21:42.569497 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m16:21:42.569497 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m16:21:42.571497 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m16:21:42.572498 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m16:21:42.573496 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m16:21:42.574499 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m16:21:42.575498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m16:21:42.575498 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m16:21:42.578498 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m16:21:42.579498 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m16:21:42.579498 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m16:21:42.580498 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m16:21:42.580498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m16:21:42.581498 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m16:21:42.583498 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m16:21:42.584498 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m16:21:42.584498 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m16:21:42.585498 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:21:42.585498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m16:21:42.586498 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:21:42.598497 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:21:42.599497 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:21:42.600498 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:21:42.601497 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m16:21:42.601497 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m16:21:42.602498 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m16:21:42.608087 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m16:21:42.609086 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m16:21:42.610087 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m16:21:42.610087 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m16:21:42.611086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m16:21:42.611086 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m16:21:42.615085 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m16:21:42.616086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m16:21:42.617087 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m16:21:42.617087 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m16:21:42.618083 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m16:21:42.618083 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m16:21:42.620085 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m16:21:42.621086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m16:21:42.622086 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m16:21:42.622086 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m16:21:42.623085 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m16:21:42.624087 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m16:21:42.626085 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m16:21:42.627086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m16:21:42.628086 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m16:21:42.628086 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m16:21:42.629086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m16:21:42.629086 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m16:21:42.633086 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m16:21:42.634087 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m16:21:42.634087 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m16:21:42.635087 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m16:21:42.635087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m16:21:42.636086 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m16:21:42.639086 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:21:42.640090 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m16:21:42.641084 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m16:21:42.642086 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m16:21:42.642086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.best_selling_film)
[0m16:21:42.643086 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m16:21:42.646086 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m16:21:42.647086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m16:21:42.648086 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m16:21:42.648086 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m16:21:42.648086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m16:21:42.649086 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m16:21:42.651086 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m16:21:42.652086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m16:21:42.653086 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m16:21:42.654489 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:21:42.654489 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediete' was properly closed.
[0m16:21:42.654489 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m16:21:42.658481 [debug] [MainThread]: Command end result
[0m16:21:42.747480 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:21:42.748480 [info ] [MainThread]: Building catalog
[0m16:21:42.759478 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m16:21:42.766481 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m16:21:42.767479 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m16:21:42.767479 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:42.774481 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m16:21:42.775478 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m16:21:42.775478 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_selling_film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:21:42.781479 [debug] [ThreadPool]: SQL status: SELECT 206 in 0.005 seconds
[0m16:21:42.792478 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m16:21:42.794479 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m16:21:42.842106 [info ] [MainThread]: Catalog written to C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\target\catalog.json
[0m16:21:42.843106 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:21:42.843106 after 1.18 seconds
[0m16:21:42.844106 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:21:42.844106 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m16:21:42.845106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF808AF6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF8292FE60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF83694E30>]}
[0m16:21:42.845106 [debug] [MainThread]: Flushing usage events
[0m16:26:54.205350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B46F9430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B73C0DA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B776C4A0>]}


============================== 16:26:54.209353 | 17628a76-cc30-43f6-bd95-2fdf1c1ae79d ==============================
[0m16:26:54.209353 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:26:54.210349 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:26:54.418395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17628a76-cc30-43f6-bd95-2fdf1c1ae79d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B817E480>]}
[0m16:26:54.472390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17628a76-cc30-43f6-bd95-2fdf1c1ae79d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B805EB10>]}
[0m16:29:21.737353 [error] [MainThread]: Encountered an error:

[0m16:29:21.743391 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\cli\main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Users\RickyS-PC\miniconda3\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RickyS-PC\miniconda3\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m16:29:21.746392 [debug] [MainThread]: Command `dbt docs serve` failed at 16:29:21.746392 after 147.65 seconds
[0m16:29:21.747393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B7C50FE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B7DDCEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172B8334890>]}
[0m16:29:21.747393 [debug] [MainThread]: Flushing usage events
[0m16:45:47.604287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157E025EFF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157DFF3E270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157E045F0E0>]}


============================== 16:45:47.608287 | 18356eba-a2d6-4926-acfb-06eb1b10f126 ==============================
[0m16:45:47.608287 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:45:47.609288 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:45:47.627292 [info ] [MainThread]: dbt version: 1.8.5
[0m16:45:47.628291 [info ] [MainThread]: python version: 3.12.4
[0m16:45:47.629287 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m16:45:47.630288 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m16:45:47.732291 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m16:45:47.733290 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m16:45:47.734287 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m16:45:47.736289 [info ] [MainThread]: adapter type: postgres
[0m16:45:47.736289 [info ] [MainThread]: adapter version: 1.8.2
[0m16:45:47.821269 [info ] [MainThread]: Configuration:
[0m16:45:47.822269 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:45:47.823270 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:45:47.823270 [info ] [MainThread]: Required dependencies:
[0m16:45:47.824268 [debug] [MainThread]: Executing "git --help"
[0m16:45:47.856270 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:45:47.857270 [debug] [MainThread]: STDERR: "b''"
[0m16:45:47.858269 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:45:47.858269 [info ] [MainThread]: Connection:
[0m16:45:47.859268 [info ] [MainThread]:   host: localhost
[0m16:45:47.860269 [info ] [MainThread]:   port: 5433
[0m16:45:47.860269 [info ] [MainThread]:   user: postgres
[0m16:45:47.861269 [info ] [MainThread]:   database: data_warehouse
[0m16:45:47.861269 [info ] [MainThread]:   schema: dbt_dev
[0m16:45:47.862268 [info ] [MainThread]:   connect_timeout: 10
[0m16:45:47.863272 [info ] [MainThread]:   role: None
[0m16:45:47.863272 [info ] [MainThread]:   search_path: None
[0m16:45:47.864270 [info ] [MainThread]:   keepalives_idle: 0
[0m16:45:47.864270 [info ] [MainThread]:   sslmode: None
[0m16:45:47.865269 [info ] [MainThread]:   sslcert: None
[0m16:45:47.866270 [info ] [MainThread]:   sslkey: None
[0m16:45:47.866270 [info ] [MainThread]:   sslrootcert: None
[0m16:45:47.867269 [info ] [MainThread]:   application_name: dbt
[0m16:45:47.867269 [info ] [MainThread]:   retries: 1
[0m16:45:47.868268 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:45:47.869269 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m16:45:47.932278 [debug] [MainThread]: Using postgres connection "debug"
[0m16:45:47.933278 [debug] [MainThread]: On debug: select 1 as id
[0m16:45:47.933278 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:45:47.942280 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m16:45:47.943278 [debug] [MainThread]: On debug: Close
[0m16:45:47.943278 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:45:47.945279 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:45:47.946917 [debug] [MainThread]: Command `dbt debug` succeeded at 16:45:47.946917 after 0.47 seconds
[0m16:45:47.947458 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m16:45:47.947988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157E025EFF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157E104F830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157E076D8B0>]}
[0m16:45:47.948538 [debug] [MainThread]: Flushing usage events
[0m16:45:54.476272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B65B9BB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B3D8BAA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B6763C20>]}


============================== 16:45:54.480273 | 3bcf5970-335b-4edc-9199-2aade4f0e0bb ==============================
[0m16:45:54.480273 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:45:54.481273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:45:54.682880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B6556210>]}
[0m16:45:54.735090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B4358EF0>]}
[0m16:45:54.736091 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m16:45:54.744089 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m16:45:54.905659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:45:54.905659 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_selling_film.sql
[0m16:45:55.142673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B7E3B7D0>]}
[0m16:45:55.261672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B7E53E60>]}
[0m16:45:55.262674 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m16:45:55.263674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B6BBF680>]}
[0m16:45:55.266672 [info ] [MainThread]: 
[0m16:45:55.267672 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:45:55.272672 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m16:45:55.346236 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:45:55.347236 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:45:55.347236 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:55.356235 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m16:45:55.358236 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:45:55.360237 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:45:55.361430 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:45:55.361957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.368892 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m16:45:55.370470 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:45:55.372040 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:45:55.373526 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:45:55.373526 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.381695 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m16:45:55.383270 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:45:55.385310 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m16:45:55.386293 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m16:45:55.386293 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.393245 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m16:45:55.395368 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m16:45:55.398509 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m16:45:55.406271 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:45:55.406787 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m16:45:55.407314 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:55.413534 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.414532 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m16:45:55.415532 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m16:45:55.418534 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m16:45:55.419534 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m16:45:55.420533 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m16:45:55.421533 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev)
[0m16:45:55.425752 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:45:55.426278 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m16:45:55.426807 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.433158 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m16:45:55.433684 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m16:45:55.434212 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m16:45:55.436725 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m16:45:55.437727 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m16:45:55.438727 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m16:45:55.439726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediete)
[0m16:45:55.442629 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:45:55.443157 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m16:45:55.443157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.450034 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.451069 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m16:45:55.451596 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m16:45:55.454177 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m16:45:55.456175 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m16:45:55.457173 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m16:45:55.457173 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_raw)
[0m16:45:55.461491 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:45:55.462015 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m16:45:55.462541 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:55.469421 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.470485 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m16:45:55.470485 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m16:45:55.473518 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m16:45:55.474518 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m16:45:55.475518 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m16:45:55.484640 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:55.485168 [debug] [MainThread]: On master: BEGIN
[0m16:45:55.485698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:45:55.491921 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:45:55.492921 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:55.492921 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:45:55.532562 [debug] [MainThread]: SQL status: SELECT 38 in 0.038 seconds
[0m16:45:55.534561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B80DA5D0>]}
[0m16:45:55.535562 [debug] [MainThread]: On master: ROLLBACK
[0m16:45:55.536562 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:55.536562 [debug] [MainThread]: On master: BEGIN
[0m16:45:55.537562 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:45:55.538562 [debug] [MainThread]: On master: COMMIT
[0m16:45:55.538562 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:55.539562 [debug] [MainThread]: On master: COMMIT
[0m16:45:55.540562 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:45:55.540562 [debug] [MainThread]: On master: Close
[0m16:45:55.541560 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:45:55.541560 [info ] [MainThread]: 
[0m16:45:55.545530 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m16:45:55.546594 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m16:45:55.548173 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m16:45:55.548704 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m16:45:55.556024 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m16:45:55.557024 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m16:45:55.598024 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m16:45:55.599022 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.599022 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m16:45:55.600022 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:45:55.606022 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:55.607022 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.607022 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m16:45:55.610022 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m16:45:55.617024 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.618024 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m16:45:55.619024 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.622025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.622025 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m16:45:55.624024 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.648023 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m16:45:55.648023 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.649022 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m16:45:55.652022 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:55.658024 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m16:45:55.663025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m16:45:55.664024 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m16:45:55.668024 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:55.670022 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m16:45:55.672024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B42E0FB0>]}
[0m16:45:55.673023 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m16:45:55.673931 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m16:45:55.674461 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m16:45:55.674992 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m16:45:55.676045 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m16:45:55.676572 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m16:45:55.681301 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m16:45:55.682351 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m16:45:55.685832 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m16:45:55.687417 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.687941 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m16:45:55.688472 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.694860 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.695914 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.696966 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m16:45:55.699963 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m16:45:55.702963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.703964 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m16:45:55.704963 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.707963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.707963 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m16:45:55.708964 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.710963 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m16:45:55.710963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.711964 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m16:45:55.715965 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:55.718963 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m16:45:55.719963 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m16:45:55.719963 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m16:45:55.723962 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:55.725963 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m16:45:55.726962 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B8304590>]}
[0m16:45:55.726962 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m16:45:55.727963 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m16:45:55.729335 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m16:45:55.730398 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m16:45:55.731450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m16:45:55.731974 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m16:45:55.735654 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m16:45:55.736706 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m16:45:55.739834 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m16:45:55.740878 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.741395 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m16:45:55.741395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.748393 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.749392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.750392 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m16:45:55.752392 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m16:45:55.757392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.758393 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m16:45:55.759392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.764392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.765395 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m16:45:55.767392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.770393 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m16:45:55.770393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.771393 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m16:45:55.775392 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:55.778392 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m16:45:55.780394 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m16:45:55.781394 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m16:45:55.786393 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:55.788392 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m16:45:55.789394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B829C080>]}
[0m16:45:55.790393 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m16:45:55.791396 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m16:45:55.791396 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m16:45:55.792395 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m16:45:55.793393 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m16:45:55.793393 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m16:45:55.797394 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m16:45:55.798394 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m16:45:55.803392 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m16:45:55.804393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.804393 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m16:45:55.805393 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.811391 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:55.811391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.812391 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m16:45:55.821394 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m16:45:55.825393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.825393 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m16:45:55.826392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.829394 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.830395 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m16:45:55.832395 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.834393 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m16:45:55.835392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.835392 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m16:45:55.839391 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:55.842391 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m16:45:55.843391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m16:45:55.843391 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m16:45:55.848392 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:55.849393 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m16:45:55.850393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B86A1040>]}
[0m16:45:55.851394 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m16:45:55.852391 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m16:45:55.853164 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m16:45:55.854216 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m16:45:55.854736 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m16:45:55.855260 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m16:45:55.857877 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m16:45:55.858923 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m16:45:55.862602 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m16:45:55.864695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.864695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m16:45:55.865694 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.871694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:55.872695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.872695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m16:45:55.876695 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.003 seconds
[0m16:45:55.880696 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.880696 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m16:45:55.882695 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.885694 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.885694 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m16:45:55.886696 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.888695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m16:45:55.889695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.889695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m16:45:55.893695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:55.896695 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m16:45:55.897696 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m16:45:55.898694 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m16:45:55.902694 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:55.904695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m16:45:55.904695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B81E1EE0>]}
[0m16:45:55.905695 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m16:45:55.906696 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m16:45:55.908303 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m16:45:55.908832 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m16:45:55.909357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m16:45:55.909880 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m16:45:55.913561 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m16:45:55.914621 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m16:45:55.918300 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m16:45:55.919345 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.919345 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m16:45:55.920343 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.926342 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.927342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.927342 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m16:45:55.932342 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m16:45:55.935343 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.936343 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m16:45:55.937343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.941913 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.941913 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m16:45:55.942912 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.944914 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m16:45:55.944914 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.945913 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m16:45:55.949912 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:55.952912 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m16:45:55.953913 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m16:45:55.954916 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m16:45:55.957913 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:55.959914 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m16:45:55.959914 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B8339400>]}
[0m16:45:55.960914 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m16:45:55.961914 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m16:45:55.963302 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m16:45:55.964365 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m16:45:55.964891 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m16:45:55.965418 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m16:45:55.968565 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.969091 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m16:45:55.972799 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.973850 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.974367 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m16:45:55.974367 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:55.981366 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:55.982364 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.982364 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m16:45:55.984368 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m16:45:55.988365 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.988365 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m16:45:55.989365 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.992365 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.993365 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m16:45:55.994365 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:55.995365 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m16:45:55.996367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:55.997367 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m16:45:56.000363 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.004365 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m16:45:56.005366 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m16:45:56.006366 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m16:45:56.010365 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.011366 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m16:45:56.012364 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B86C0350>]}
[0m16:45:56.014370 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m16:45:56.015835 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m16:45:56.016383 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m16:45:56.017444 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m16:45:56.017971 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m16:45:56.018500 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m16:45:56.021588 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m16:45:56.021588 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m16:45:56.025587 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m16:45:56.025587 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.026588 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m16:45:56.026588 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.034587 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.034587 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.035586 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m16:45:56.042586 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m16:45:56.046589 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.047589 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m16:45:56.048586 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.051587 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.052587 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m16:45:56.053587 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.055586 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:45:56.055586 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.055586 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m16:45:56.060587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:56.063589 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m16:45:56.064589 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m16:45:56.064589 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m16:45:56.068587 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.070588 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m16:45:56.071587 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B86A2CC0>]}
[0m16:45:56.071587 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.05s]
[0m16:45:56.072588 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m16:45:56.074029 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m16:45:56.074563 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m16:45:56.075087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m16:45:56.075615 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m16:45:56.080884 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m16:45:56.082466 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m16:45:56.086076 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m16:45:56.086076 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.087077 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m16:45:56.087077 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.094075 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:56.094075 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.095077 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m16:45:56.104592 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m16:45:56.107591 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.107591 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m16:45:56.108592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.111592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.112592 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m16:45:56.114591 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.116591 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m16:45:56.117592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.117592 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m16:45:56.122592 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:56.124591 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m16:45:56.125592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m16:45:56.125592 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m16:45:56.129591 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.131592 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m16:45:56.132591 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B8330C20>]}
[0m16:45:56.133592 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m16:45:56.135591 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m16:45:56.136295 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m16:45:56.136817 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m16:45:56.137336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m16:45:56.137855 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m16:45:56.141011 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m16:45:56.142061 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m16:45:56.145710 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m16:45:56.147310 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.148307 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m16:45:56.149307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.156308 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.157307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.157307 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m16:45:56.165308 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m16:45:56.168307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.169307 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m16:45:56.170308 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.173307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.173307 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m16:45:56.175308 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.176308 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m16:45:56.177308 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.177308 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m16:45:56.180309 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.185306 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m16:45:56.186306 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m16:45:56.187306 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m16:45:56.191307 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.192306 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m16:45:56.193306 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B81E2C90>]}
[0m16:45:56.194309 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m16:45:56.196132 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m16:45:56.197214 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m16:45:56.198281 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m16:45:56.199336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m16:45:56.199849 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m16:45:56.203495 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m16:45:56.205058 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m16:45:56.210634 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m16:45:56.211636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.212637 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m16:45:56.213639 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.220636 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.221636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.221636 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m16:45:56.223638 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.001 seconds
[0m16:45:56.287636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.288637 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m16:45:56.289635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.292637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.293637 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m16:45:56.294637 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.296638 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m16:45:56.297637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.297637 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m16:45:56.300635 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.303636 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m16:45:56.304637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m16:45:56.304637 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m16:45:56.308636 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.309636 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m16:45:56.310637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B86A5C70>]}
[0m16:45:56.311636 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m16:45:56.313637 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m16:45:56.315034 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m16:45:56.315555 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m16:45:56.316551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m16:45:56.317553 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m16:45:56.320553 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m16:45:56.321552 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m16:45:56.325552 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m16:45:56.326553 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.327554 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m16:45:56.327554 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.336551 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m16:45:56.337553 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.338554 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m16:45:56.342554 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m16:45:56.346155 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.348154 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m16:45:56.350153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.354154 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.355154 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m16:45:56.357153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.360152 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m16:45:56.360152 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.361154 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m16:45:56.366154 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:56.369153 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m16:45:56.370153 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m16:45:56.370153 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m16:45:56.375153 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:56.377155 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m16:45:56.378154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B7D10CE0>]}
[0m16:45:56.380157 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m16:45:56.382154 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m16:45:56.383739 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m16:45:56.385337 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m16:45:56.386394 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m16:45:56.387458 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m16:45:56.394015 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m16:45:56.395532 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m16:45:56.402534 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m16:45:56.403534 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.404534 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m16:45:56.405533 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.415531 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m16:45:56.416533 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.417534 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m16:45:56.423531 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.005 seconds
[0m16:45:56.430538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.431535 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m16:45:56.434535 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m16:45:56.440536 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.441533 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m16:45:56.444534 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m16:45:56.450534 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m16:45:56.451532 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.452531 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m16:45:56.455535 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.459533 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m16:45:56.460532 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m16:45:56.460532 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m16:45:56.465532 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:56.467531 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m16:45:56.469531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82BDB50>]}
[0m16:45:56.470533 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.08s]
[0m16:45:56.471532 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m16:45:56.472747 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m16:45:56.473281 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m16:45:56.474328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m16:45:56.475380 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m16:45:56.479051 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m16:45:56.480631 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m16:45:56.486900 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m16:45:56.487899 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.488900 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m16:45:56.488900 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.495901 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.496901 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.497901 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m16:45:56.506900 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m16:45:56.509901 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.510907 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m16:45:56.512902 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.516903 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.516903 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m16:45:56.518902 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.520899 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m16:45:56.521900 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.521900 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m16:45:56.525900 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.528901 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m16:45:56.530909 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m16:45:56.531902 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m16:45:56.535901 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.536901 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m16:45:56.537901 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82AA4B0>]}
[0m16:45:56.538901 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m16:45:56.539902 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m16:45:56.540505 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m16:45:56.541550 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m16:45:56.542079 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m16:45:56.542604 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m16:45:56.547440 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m16:45:56.548491 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m16:45:56.552158 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m16:45:56.553206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.553731 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m16:45:56.554256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.561567 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.561567 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.562568 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m16:45:56.567567 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m16:45:56.570567 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.570567 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m16:45:56.572567 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.574568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.575569 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m16:45:56.576568 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.578568 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m16:45:56.579569 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.580571 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m16:45:56.584566 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.586566 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m16:45:56.587566 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m16:45:56.588566 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m16:45:56.591567 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.593568 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m16:45:56.594567 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B6B9F290>]}
[0m16:45:56.595568 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m16:45:56.596875 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m16:45:56.597961 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m16:45:56.598493 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m16:45:56.599555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m16:45:56.600085 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m16:45:56.604779 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m16:45:56.605868 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m16:45:56.609979 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m16:45:56.609979 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.610979 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m16:45:56.611979 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.618978 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.618978 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.619980 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m16:45:56.623979 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m16:45:56.626979 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.626979 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m16:45:56.628978 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.632979 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.632979 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m16:45:56.634978 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.636977 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m16:45:56.637978 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.637978 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m16:45:56.641977 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.643977 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m16:45:56.644977 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m16:45:56.645978 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m16:45:56.664978 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.018 seconds
[0m16:45:56.666977 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m16:45:56.667979 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B8301790>]}
[0m16:45:56.667979 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.07s]
[0m16:45:56.669978 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m16:45:56.670602 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m16:45:56.671119 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m16:45:56.672167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m16:45:56.672689 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m16:45:56.675294 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.676342 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m16:45:56.695086 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.696085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.697086 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m16:45:56.697086 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.704084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:56.704084 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.705084 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m16:45:56.707084 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.001 seconds
[0m16:45:56.710085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.710085 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m16:45:56.712085 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.714088 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m16:45:56.715086 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.715086 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m16:45:56.719085 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:45:56.721085 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m16:45:56.724086 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m16:45:56.725085 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m16:45:56.726085 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m16:45:56.727086 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m16:45:56.728085 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B68BEFF0>]}
[0m16:45:56.728085 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.05s]
[0m16:45:56.730086 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m16:45:56.731086 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m16:45:56.732086 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m16:45:56.732086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m16:45:56.733085 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m16:45:56.736086 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m16:45:56.737085 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m16:45:56.740085 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m16:45:56.741085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.741085 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m16:45:56.742086 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.749085 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m16:45:56.750085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.751085 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m16:45:56.758084 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m16:45:56.764667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.765665 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m16:45:56.766667 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.769667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.770667 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m16:45:56.771670 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.773666 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m16:45:56.773666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.773666 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m16:45:56.778665 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:56.782667 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m16:45:56.783667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m16:45:56.783667 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m16:45:56.787665 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:56.788667 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m16:45:56.789667 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82A39B0>]}
[0m16:45:56.790667 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m16:45:56.791665 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m16:45:56.792667 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m16:45:56.792667 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m16:45:56.793665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m16:45:56.794665 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m16:45:56.797668 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m16:45:56.798667 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m16:45:56.802666 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m16:45:56.802666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.803667 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m16:45:56.803667 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.810665 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.811667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.811667 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m16:45:56.820667 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m16:45:56.824666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.824666 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m16:45:56.826666 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.828667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.829668 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m16:45:56.831665 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.833666 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m16:45:56.833666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.834666 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m16:45:56.838666 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:56.841667 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m16:45:56.841667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m16:45:56.842667 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m16:45:56.846669 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:56.848668 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m16:45:56.849666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B69D6030>]}
[0m16:45:56.850667 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m16:45:56.851666 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m16:45:56.852665 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m16:45:56.852665 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m16:45:56.853665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m16:45:56.853665 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m16:45:56.856666 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m16:45:56.857667 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m16:45:56.860666 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m16:45:56.861667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.862667 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m16:45:56.862667 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.869666 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:56.869666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.870667 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m16:45:56.876665 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m16:45:56.880670 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.881668 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m16:45:56.883666 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.886665 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.886665 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m16:45:56.887664 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:56.889664 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m16:45:56.890666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.890666 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m16:45:56.893666 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m16:45:56.899666 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m16:45:56.900667 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m16:45:56.900667 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m16:45:56.904665 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m16:45:56.906667 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m16:45:56.907666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82D3C50>]}
[0m16:45:56.907666 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m16:45:56.908667 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m16:45:56.909981 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m16:45:56.910510 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m16:45:56.911030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m16:45:56.911555 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m16:45:56.916808 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m16:45:56.917913 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m16:45:56.921571 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m16:45:56.922568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:56.923571 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m16:45:56.923571 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:56.930570 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m16:45:56.931570 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:56.931570 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    COUNT(dim_fm.film_id) AS total_rent
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id, dim_fm.title
ORDER BY total_rent DESC
  );
  
[0m16:45:57.178178 [debug] [Thread-1 (]: SQL status: SELECT 958 in 0.246 seconds
[0m16:45:57.182179 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:57.182179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film" rename to "best_selling_film__dbt_backup"
[0m16:45:57.184180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:57.187179 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:57.187179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m16:45:57.188178 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:57.190179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m16:45:57.190179 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:57.191179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m16:45:57.194181 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m16:45:57.196179 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m16:45:57.197179 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m16:45:57.198179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m16:45:57.201178 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:57.203179 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m16:45:57.204179 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82E9EB0>]}
[0m16:45:57.205179 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 958[0m in 0.29s]
[0m16:45:57.206179 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m16:45:57.206179 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m16:45:57.207178 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m16:45:57.207178 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m16:45:57.208180 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m16:45:57.211418 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m16:45:57.212477 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m16:45:57.217303 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m16:45:57.218366 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.218897 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m16:45:57.219429 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:57.225521 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m16:45:57.225521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.226522 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m16:45:57.251523 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.024 seconds
[0m16:45:57.254521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.254521 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m16:45:57.256521 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:57.258521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.259521 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m16:45:57.260521 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:45:57.261520 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m16:45:57.262520 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.263523 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m16:45:57.267522 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:45:57.270522 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m16:45:57.271522 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m16:45:57.271522 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m16:45:57.275521 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m16:45:57.276521 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m16:45:57.277520 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bcf5970-335b-4edc-9199-2aade4f0e0bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B7D13BC0>]}
[0m16:45:57.278521 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m16:45:57.280521 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m16:45:57.281522 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:57.282521 [debug] [MainThread]: On master: BEGIN
[0m16:45:57.282521 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:45:57.288520 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m16:45:57.289522 [debug] [MainThread]: On master: COMMIT
[0m16:45:57.289522 [debug] [MainThread]: Using postgres connection "master"
[0m16:45:57.290521 [debug] [MainThread]: On master: COMMIT
[0m16:45:57.290521 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:45:57.291521 [debug] [MainThread]: On master: Close
[0m16:45:57.292521 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:45:57.292521 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m16:45:57.293522 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m16:45:57.293522 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m16:45:57.294523 [info ] [MainThread]: 
[0m16:45:57.295522 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.03 seconds (2.03s).
[0m16:45:57.299520 [debug] [MainThread]: Command end result
[0m16:45:57.336524 [info ] [MainThread]: 
[0m16:45:57.337521 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:45:57.338523 [info ] [MainThread]: 
[0m16:45:57.338523 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m16:45:57.340522 [debug] [MainThread]: Command `dbt run` succeeded at 16:45:57.339521 after 2.96 seconds
[0m16:45:57.340522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B2E3F8C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82CBAA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000234B82BE6C0>]}
[0m16:45:58.623425 [debug] [MainThread]: Flushing usage events
[0m16:46:05.871138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CE209B140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CE20984D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CE2342D80>]}


============================== 16:46:05.875142 | 29f3aa61-4578-4289-aedd-659e8dae2834 ==============================
[0m16:46:05.875142 [info ] [MainThread]: Running with dbt=1.8.5
[0m16:46:05.876141 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:46:06.071730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '29f3aa61-4578-4289-aedd-659e8dae2834', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CE231E630>]}
[0m16:46:06.124729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '29f3aa61-4578-4289-aedd-659e8dae2834', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CE1A731A0>]}
[0m17:15:55.275923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A1FD4D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A51DDEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A5AF51C0>]}


============================== 17:15:55.280924 | d209b134-929c-4816-a27a-b01b64a06a32 ==============================
[0m17:15:55.280924 [info ] [MainThread]: Running with dbt=1.8.5
[0m17:15:55.281924 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:15:55.303926 [info ] [MainThread]: dbt version: 1.8.5
[0m17:15:55.304925 [info ] [MainThread]: python version: 3.12.4
[0m17:15:55.305927 [info ] [MainThread]: python path: C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\env\Scripts\python.exe
[0m17:15:55.306925 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m17:15:55.423015 [info ] [MainThread]: Using profiles dir at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse
[0m17:15:55.424015 [info ] [MainThread]: Using profiles.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\profiles.yml
[0m17:15:55.424015 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\dbt_project.yml
[0m17:15:55.426016 [info ] [MainThread]: adapter type: postgres
[0m17:15:55.426016 [info ] [MainThread]: adapter version: 1.8.2
[0m17:15:55.508645 [info ] [MainThread]: Configuration:
[0m17:15:55.509645 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:15:55.510643 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:15:55.510643 [info ] [MainThread]: Required dependencies:
[0m17:15:55.511643 [debug] [MainThread]: Executing "git --help"
[0m17:15:55.544407 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:15:55.545404 [debug] [MainThread]: STDERR: "b''"
[0m17:15:55.545404 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:15:55.546405 [info ] [MainThread]: Connection:
[0m17:15:55.547404 [info ] [MainThread]:   host: localhost
[0m17:15:55.548405 [info ] [MainThread]:   port: 5433
[0m17:15:55.548405 [info ] [MainThread]:   user: postgres
[0m17:15:55.549405 [info ] [MainThread]:   database: data_warehouse
[0m17:15:55.549405 [info ] [MainThread]:   schema: dbt_dev
[0m17:15:55.550405 [info ] [MainThread]:   connect_timeout: 10
[0m17:15:55.550405 [info ] [MainThread]:   role: None
[0m17:15:55.551405 [info ] [MainThread]:   search_path: None
[0m17:15:55.551405 [info ] [MainThread]:   keepalives_idle: 0
[0m17:15:55.552405 [info ] [MainThread]:   sslmode: None
[0m17:15:55.552405 [info ] [MainThread]:   sslcert: None
[0m17:15:55.553404 [info ] [MainThread]:   sslkey: None
[0m17:15:55.553404 [info ] [MainThread]:   sslrootcert: None
[0m17:15:55.554404 [info ] [MainThread]:   application_name: dbt
[0m17:15:55.554404 [info ] [MainThread]:   retries: 1
[0m17:15:55.555403 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:15:55.556405 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m17:15:55.618944 [debug] [MainThread]: Using postgres connection "debug"
[0m17:15:55.618944 [debug] [MainThread]: On debug: select 1 as id
[0m17:15:55.619945 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:15:55.627943 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m17:15:55.629944 [debug] [MainThread]: On debug: Close
[0m17:15:55.629944 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:15:55.630941 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:15:55.632942 [debug] [MainThread]: Command `dbt debug` succeeded at 17:15:55.632942 after 0.48 seconds
[0m17:15:55.633283 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:15:55.633819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A5088800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A5D0F6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220A5BEAC90>]}
[0m17:15:55.634353 [debug] [MainThread]: Flushing usage events
[0m17:16:04.439354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F0841370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208ECCAC3E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208ECF9CC50>]}


============================== 17:16:04.443355 | 3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53 ==============================
[0m17:16:04.443355 [info ] [MainThread]: Running with dbt=1.8.5
[0m17:16:04.444355 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m17:16:04.647607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F09E5D30>]}
[0m17:16:04.701298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208EFA18CB0>]}
[0m17:16:04.703297 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:16:04.710296 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m17:16:04.877374 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m17:16:04.878375 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\most_frequent_actor.sql
[0m17:16:05.107503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F1E82F60>]}
[0m17:16:05.211129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F0BD76B0>]}
[0m17:16:05.212128 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m17:16:05.213129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F09C1190>]}
[0m17:16:05.216129 [info ] [MainThread]: 
[0m17:16:05.217129 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:16:05.222128 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m17:16:05.291129 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:16:05.291129 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:16:05.292129 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:05.301128 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.009 seconds
[0m17:16:05.303127 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:16:05.305129 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:16:05.305630 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:16:05.306161 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.312995 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m17:16:05.314113 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:16:05.316739 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:16:05.317380 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:16:05.317906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.323046 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m17:16:05.325043 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:16:05.327041 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m17:16:05.328043 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m17:16:05.328043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.335042 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m17:16:05.336043 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m17:16:05.339047 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_intermediete'
[0m17:16:05.345043 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m17:16:05.346044 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m17:16:05.347043 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:05.353043 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.353043 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m17:16:05.354042 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m17:16:05.357042 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m17:16:05.358043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m17:16:05.359041 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m17:16:05.360042 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev_mart)
[0m17:16:05.366042 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m17:16:05.366042 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m17:16:05.367043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.373042 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.373042 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m17:16:05.374043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m17:16:05.377045 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m17:16:05.379043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m17:16:05.380043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m17:16:05.381042 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev)
[0m17:16:05.383042 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:16:05.384043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m17:16:05.384043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.390042 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.390042 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:16:05.391041 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m17:16:05.394042 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m17:16:05.395043 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m17:16:05.396042 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m17:16:05.397042 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m17:16:05.399876 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:16:05.400397 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m17:16:05.400397 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:05.406180 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.406701 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:16:05.407279 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m17:16:05.410427 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m17:16:05.411423 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m17:16:05.412424 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m17:16:05.420056 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:05.420578 [debug] [MainThread]: On master: BEGIN
[0m17:16:05.420578 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:16:05.426430 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.426947 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:05.427943 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:16:05.465945 [debug] [MainThread]: SQL status: SELECT 38 in 0.038 seconds
[0m17:16:05.467943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F233ACC0>]}
[0m17:16:05.468942 [debug] [MainThread]: On master: ROLLBACK
[0m17:16:05.469943 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:05.470945 [debug] [MainThread]: On master: BEGIN
[0m17:16:05.471944 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m17:16:05.471944 [debug] [MainThread]: On master: COMMIT
[0m17:16:05.472943 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:05.472943 [debug] [MainThread]: On master: COMMIT
[0m17:16:05.473944 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:16:05.473944 [debug] [MainThread]: On master: Close
[0m17:16:05.474944 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:16:05.475943 [info ] [MainThread]: 
[0m17:16:05.479725 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m17:16:05.480263 [info ] [Thread-1 (]: 1 of 23 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m17:16:05.481303 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m17:16:05.481834 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m17:16:05.489672 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m17:16:05.490673 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m17:16:05.530673 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m17:16:05.532672 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.533672 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m17:16:05.533672 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:16:05.539671 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.540671 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.540671 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m17:16:05.543671 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m17:16:05.550672 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.551672 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m17:16:05.552672 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.555672 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.555672 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m17:16:05.557671 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.576670 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m17:16:05.577672 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.577672 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m17:16:05.580671 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:05.586670 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m17:16:05.591670 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m17:16:05.592670 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m17:16:05.596371 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.598368 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m17:16:05.600368 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208EE3C1040>]}
[0m17:16:05.601369 [info ] [Thread-1 (]: 1 of 23 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m17:16:05.602369 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m17:16:05.603369 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m17:16:05.603369 [info ] [Thread-1 (]: 2 of 23 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m17:16:05.604369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m17:16:05.605368 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m17:16:05.609367 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m17:16:05.610367 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m17:16:05.613369 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m17:16:05.615746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.615746 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m17:16:05.616747 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.622747 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.622747 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.623745 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m17:16:05.625746 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m17:16:05.629746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.630747 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m17:16:05.631746 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.634747 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.635746 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m17:16:05.636746 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.638746 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m17:16:05.638746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.639745 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m17:16:05.642749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:16:05.644748 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m17:16:05.645748 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m17:16:05.646747 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m17:16:05.650748 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m17:16:05.652749 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m17:16:05.652749 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F2454DA0>]}
[0m17:16:05.653747 [info ] [Thread-1 (]: 2 of 23 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m17:16:05.654748 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m17:16:05.655925 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m17:16:05.656449 [info ] [Thread-1 (]: 3 of 23 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m17:16:05.656975 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m17:16:05.657502 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m17:16:05.660690 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m17:16:05.661735 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m17:16:05.666999 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m17:16:05.667996 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.668996 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m17:16:05.668996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.675996 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.676998 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.676998 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m17:16:05.679998 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m17:16:05.683997 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.683997 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m17:16:05.686325 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.691196 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.691717 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m17:16:05.693332 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.696582 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m17:16:05.697700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.698698 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m17:16:05.702698 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:05.705678 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m17:16:05.706724 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m17:16:05.707243 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m17:16:05.711395 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.713513 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m17:16:05.714573 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F2463710>]}
[0m17:16:05.715629 [info ] [Thread-1 (]: 3 of 23 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m17:16:05.717225 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m17:16:05.718291 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m17:16:05.718809 [info ] [Thread-1 (]: 4 of 23 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m17:16:05.719898 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m17:16:05.720427 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m17:16:05.723565 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m17:16:05.724090 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m17:16:05.729904 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m17:16:05.731577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.732101 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m17:16:05.732627 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.740183 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:05.740700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.741215 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m17:16:05.750067 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m17:16:05.753066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.754066 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m17:16:05.755066 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.758066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.758066 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m17:16:05.759067 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.761067 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m17:16:05.762067 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.762067 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m17:16:05.767066 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:05.770066 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m17:16:05.771067 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m17:16:05.771067 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m17:16:05.775066 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.777067 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m17:16:05.778067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27B8140>]}
[0m17:16:05.779069 [info ] [Thread-1 (]: 4 of 23 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m17:16:05.781067 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m17:16:05.781067 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m17:16:05.782065 [info ] [Thread-1 (]: 5 of 23 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m17:16:05.783067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m17:16:05.784066 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m17:16:05.787067 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m17:16:05.787067 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m17:16:05.791066 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m17:16:05.792067 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.793066 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m17:16:05.793066 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.800066 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:05.801066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.802065 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m17:16:05.807065 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m17:16:05.810066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.810066 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m17:16:05.812067 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.816065 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.816065 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m17:16:05.818067 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.820065 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m17:16:05.820065 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.821066 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m17:16:05.826064 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m17:16:05.829066 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m17:16:05.831066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m17:16:05.831066 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m17:16:05.835067 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.837065 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m17:16:05.838066 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F2463110>]}
[0m17:16:05.838066 [info ] [Thread-1 (]: 5 of 23 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m17:16:05.839066 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m17:16:05.840202 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m17:16:05.841245 [info ] [Thread-1 (]: 6 of 23 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m17:16:05.841772 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m17:16:05.842292 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m17:16:05.845505 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m17:16:05.846574 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m17:16:05.850267 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m17:16:05.851332 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.851856 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m17:16:05.851856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.857849 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:05.858847 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.858847 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m17:16:05.862849 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m17:16:05.866848 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.866848 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m17:16:05.868847 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.872846 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.873846 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m17:16:05.874847 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.876847 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m17:16:05.876847 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.876847 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m17:16:05.884846 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m17:16:05.887845 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m17:16:05.888845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m17:16:05.888845 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m17:16:05.892847 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.893847 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m17:16:05.894845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F246DEB0>]}
[0m17:16:05.895846 [info ] [Thread-1 (]: 6 of 23 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m17:16:05.896848 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m17:16:05.897891 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m17:16:05.898952 [info ] [Thread-1 (]: 7 of 23 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m17:16:05.899499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m17:16:05.900551 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m17:16:05.903159 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.904204 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m17:16:05.907398 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.908456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.908973 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m17:16:05.908973 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.915970 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:05.916971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.916971 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:16:05.918972 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m17:16:05.921970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.922971 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:16:05.923973 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.926970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.926970 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:16:05.927973 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.930970 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m17:16:05.930970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.931971 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m17:16:05.934971 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:05.937969 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m17:16:05.937969 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m17:16:05.938970 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m17:16:05.942973 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:05.943971 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m17:16:05.944971 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27D04D0>]}
[0m17:16:05.946976 [info ] [Thread-1 (]: 7 of 23 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m17:16:05.948228 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m17:16:05.948755 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m17:16:05.949284 [info ] [Thread-1 (]: 8 of 23 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m17:16:05.950341 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m17:16:05.950864 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m17:16:05.953469 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m17:16:05.954587 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m17:16:05.957741 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m17:16:05.958790 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:05.959306 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m17:16:05.959306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:05.966304 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:05.967304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:05.967304 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m17:16:05.976303 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m17:16:05.980305 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:05.980305 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m17:16:05.982305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.984303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:05.985302 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m17:16:05.986305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:05.988303 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m17:16:05.988303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:05.989302 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m17:16:05.995302 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m17:16:05.998303 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m17:16:05.999304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m17:16:06.000303 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m17:16:06.004474 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m17:16:06.006474 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m17:16:06.006474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27B0F20>]}
[0m17:16:06.007474 [info ] [Thread-1 (]: 8 of 23 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m17:16:06.008475 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m17:16:06.009747 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m17:16:06.010275 [info ] [Thread-1 (]: 9 of 23 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m17:16:06.011318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m17:16:06.011318 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m17:16:06.017205 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m17:16:06.018273 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m17:16:06.021920 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m17:16:06.022920 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.022920 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m17:16:06.023921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.029917 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.030921 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.030921 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m17:16:06.039917 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m17:16:06.043917 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.043917 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m17:16:06.045917 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.048920 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.049917 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m17:16:06.050918 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.052917 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m17:16:06.052917 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.053917 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m17:16:06.058917 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:06.060918 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m17:16:06.061918 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m17:16:06.062918 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m17:16:06.066918 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.068918 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m17:16:06.068918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27EE4B0>]}
[0m17:16:06.069918 [info ] [Thread-1 (]: 9 of 23 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m17:16:06.070919 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m17:16:06.072023 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m17:16:06.072547 [info ] [Thread-1 (]: 10 of 23 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m17:16:06.073604 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m17:16:06.074136 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m17:16:06.076751 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m17:16:06.077801 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m17:16:06.083259 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m17:16:06.084258 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.085258 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m17:16:06.086258 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.092256 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.093257 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.093257 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m17:16:06.101258 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m17:16:06.104258 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.105256 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m17:16:06.106260 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.109256 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.109256 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m17:16:06.110262 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.113257 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m17:16:06.113257 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.114261 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m17:16:06.117257 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:06.120261 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m17:16:06.121261 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m17:16:06.121261 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m17:16:06.125257 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.126259 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m17:16:06.127258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F234DBE0>]}
[0m17:16:06.128259 [info ] [Thread-1 (]: 10 of 23 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m17:16:06.129257 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m17:16:06.130927 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m17:16:06.132009 [info ] [Thread-1 (]: 11 of 23 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m17:16:06.132528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m17:16:06.133076 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m17:16:06.136219 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m17:16:06.137273 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m17:16:06.142009 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m17:16:06.143001 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.144002 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m17:16:06.144002 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.152001 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.153000 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.153000 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m17:16:06.155005 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m17:16:06.220653 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.221655 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m17:16:06.222653 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.225653 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.226652 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m17:16:06.227653 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.229654 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m17:16:06.230653 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.230653 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m17:16:06.233652 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:16:06.236652 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m17:16:06.237653 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m17:16:06.237653 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m17:16:06.241655 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.243653 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m17:16:06.243653 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208EFCE3260>]}
[0m17:16:06.244653 [info ] [Thread-1 (]: 11 of 23 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m17:16:06.246655 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m17:16:06.247363 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m17:16:06.247901 [info ] [Thread-1 (]: 12 of 23 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m17:16:06.248423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m17:16:06.248942 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m17:16:06.252065 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m17:16:06.253114 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m17:16:06.256237 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m17:16:06.257291 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.257814 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m17:16:06.258331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.264328 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.265330 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.266327 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m17:16:06.268328 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m17:16:06.271326 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.272326 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m17:16:06.273327 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.275327 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.276327 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m17:16:06.277329 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.280329 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m17:16:06.281327 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.281327 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m17:16:06.285677 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:06.288688 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m17:16:06.289687 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m17:16:06.289687 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m17:16:06.293689 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.294693 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m17:16:06.295691 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F2457FB0>]}
[0m17:16:06.297689 [info ] [Thread-1 (]: 12 of 23 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m17:16:06.298688 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m17:16:06.299094 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m17:16:06.300166 [info ] [Thread-1 (]: 13 of 23 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m17:16:06.300698 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m17:16:06.301220 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m17:16:06.304403 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m17:16:06.305469 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m17:16:06.308697 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m17:16:06.309738 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.310250 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m17:16:06.310250 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.317250 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.318249 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.318249 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m17:16:06.321249 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m17:16:06.324249 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.324249 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m17:16:06.325248 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.328250 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.328250 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m17:16:06.330249 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.334249 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m17:16:06.335250 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.336248 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m17:16:06.339248 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:16:06.341248 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m17:16:06.342248 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m17:16:06.342248 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m17:16:06.346440 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.347441 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m17:16:06.348439 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F2462690>]}
[0m17:16:06.349439 [info ] [Thread-1 (]: 13 of 23 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m17:16:06.350440 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m17:16:06.350440 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m17:16:06.351832 [info ] [Thread-1 (]: 14 of 23 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m17:16:06.352883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m17:16:06.353409 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m17:16:06.356041 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m17:16:06.357086 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m17:16:06.360220 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m17:16:06.361258 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.361785 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m17:16:06.362314 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.368829 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.369828 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.370833 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m17:16:06.378766 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.007 seconds
[0m17:16:06.381765 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.382766 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m17:16:06.383764 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.387765 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.388766 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m17:16:06.389763 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.391765 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m17:16:06.392766 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.392766 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m17:16:06.396762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:06.399763 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m17:16:06.400762 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m17:16:06.400762 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m17:16:06.405275 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m17:16:06.407273 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m17:16:06.407273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F1FCD100>]}
[0m17:16:06.408275 [info ] [Thread-1 (]: 14 of 23 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m17:16:06.409277 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m17:16:06.410264 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m17:16:06.410792 [info ] [Thread-1 (]: 15 of 23 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m17:16:06.411847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m17:16:06.412382 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m17:16:06.416063 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m17:16:06.417213 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m17:16:06.420870 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m17:16:06.421387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.421916 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m17:16:06.421916 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.427905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.428905 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.429906 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m17:16:06.434906 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m17:16:06.437905 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.438907 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m17:16:06.439906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.441906 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.442906 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m17:16:06.443907 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.445907 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m17:16:06.446908 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.446908 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m17:16:06.451033 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:06.453033 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m17:16:06.454033 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m17:16:06.455033 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m17:16:06.458032 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.459033 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m17:16:06.460033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F0D24350>]}
[0m17:16:06.461033 [info ] [Thread-1 (]: 15 of 23 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m17:16:06.462032 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m17:16:06.463034 [debug] [Thread-1 (]: Began running node model.data_warehouse.most_frequent_actor
[0m17:16:06.464103 [info ] [Thread-1 (]: 16 of 23 START sql table model dbt_dev_mart.most_frequent_actor ................ [RUN]
[0m17:16:06.464630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.most_frequent_actor)
[0m17:16:06.465161 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.most_frequent_actor
[0m17:16:06.471450 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.most_frequent_actor"
[0m17:16:06.474074 [debug] [Thread-1 (]: Began executing node model.data_warehouse.most_frequent_actor
[0m17:16:06.477594 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.most_frequent_actor"
[0m17:16:06.478595 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_frequent_actor"
[0m17:16:06.478595 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: BEGIN
[0m17:16:06.479595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.485594 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.485594 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_frequent_actor"
[0m17:16:06.486593 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_frequent_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."most_frequent_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT dim_fa.actor_id,
       CONCAT(dim_at.first_name,' ',dim_at.last_name) AS full_name, 
       COUNT(dim_fa.actor_id) AS total_film
FROM "data_warehouse"."dbt_dev_raw"."actor" AS dim_at
JOIN "data_warehouse"."dbt_dev_raw"."film_actor" AS dim_fa
ON dim_at.actor_id = dim_fa.actor_id 
JOIN "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
ON dim_fa.film_id = dim_fm.film_id
GROUP BY dim_fa.actor_id, full_name
ORDER BY total_film DESC
  );
  
[0m17:16:06.498238 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.011 seconds
[0m17:16:06.501237 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_frequent_actor"
[0m17:16:06.501237 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_frequent_actor"} */
alter table "data_warehouse"."dbt_dev_mart"."most_frequent_actor__dbt_tmp" rename to "most_frequent_actor"
[0m17:16:06.503240 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.505240 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: COMMIT
[0m17:16:06.505240 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_frequent_actor"
[0m17:16:06.506241 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: COMMIT
[0m17:16:06.508313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:16:06.511316 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."most_frequent_actor__dbt_backup"
[0m17:16:06.512313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_frequent_actor"
[0m17:16:06.512313 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_frequent_actor"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."most_frequent_actor__dbt_backup" cascade
[0m17:16:06.514314 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:16:06.515313 [debug] [Thread-1 (]: On model.data_warehouse.most_frequent_actor: Close
[0m17:16:06.516313 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F23D5580>]}
[0m17:16:06.517316 [info ] [Thread-1 (]: 16 of 23 OK created sql table model dbt_dev_mart.most_frequent_actor ........... [[32mSELECT 200[0m in 0.05s]
[0m17:16:06.518314 [debug] [Thread-1 (]: Finished running node model.data_warehouse.most_frequent_actor
[0m17:16:06.519265 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m17:16:06.519803 [info ] [Thread-1 (]: 17 of 23 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m17:16:06.520338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.most_frequent_actor, now model.data_warehouse.dim_inventory)
[0m17:16:06.520859 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m17:16:06.523984 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m17:16:06.524694 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m17:16:06.527837 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m17:16:06.529428 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.529959 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m17:16:06.530477 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.537474 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m17:16:06.538476 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.538476 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m17:16:06.542475 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.003 seconds
[0m17:16:06.545473 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.546475 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m17:16:06.548475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.550476 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.551476 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m17:16:06.552474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.554472 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m17:16:06.554472 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.555475 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m17:16:06.558519 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:06.560532 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m17:16:06.561533 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m17:16:06.562532 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m17:16:06.566529 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m17:16:06.568532 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m17:16:06.569529 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F1E2C740>]}
[0m17:16:06.570530 [info ] [Thread-1 (]: 17 of 23 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m17:16:06.571530 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m17:16:06.571530 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m17:16:06.572529 [info ] [Thread-1 (]: 18 of 23 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m17:16:06.573659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m17:16:06.574181 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m17:16:06.576828 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.577357 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m17:16:06.595142 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.597144 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.597144 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m17:16:06.598144 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.604141 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.605139 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.606139 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m17:16:06.608139 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m17:16:06.613140 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.614143 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:16:06.616141 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.617141 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m17:16:06.618140 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.619144 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m17:16:06.621791 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:06.623796 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m17:16:06.626796 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m17:16:06.627796 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m17:16:06.628795 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m17:16:06.630795 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m17:16:06.630795 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F1F6B860>]}
[0m17:16:06.631795 [info ] [Thread-1 (]: 18 of 23 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m17:16:06.632796 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m17:16:06.634000 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m17:16:06.635105 [info ] [Thread-1 (]: 19 of 23 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m17:16:06.636156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m17:16:06.636156 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m17:16:06.639293 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m17:16:06.640346 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m17:16:06.643490 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m17:16:06.644528 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.644536 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m17:16:06.645065 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.651577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.651577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.652581 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m17:16:06.660580 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m17:16:06.664581 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.664581 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m17:16:06.666581 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.669577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.669577 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m17:16:06.671581 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.672582 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m17:16:06.673581 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.673581 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m17:16:06.678579 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:06.680582 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m17:16:06.681582 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m17:16:06.682582 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m17:16:06.686578 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.687583 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m17:16:06.688581 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F23DCC80>]}
[0m17:16:06.689581 [info ] [Thread-1 (]: 19 of 23 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.05s]
[0m17:16:06.690579 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m17:16:06.690579 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m17:16:06.691863 [info ] [Thread-1 (]: 20 of 23 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m17:16:06.692928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m17:16:06.693461 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m17:16:06.697227 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m17:16:06.698290 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m17:16:06.701977 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m17:16:06.702497 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.703497 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m17:16:06.703497 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.709493 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.710497 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.710497 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m17:16:06.719495 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m17:16:06.723496 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.723496 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m17:16:06.725496 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.727497 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.728498 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m17:16:06.730496 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.732497 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m17:16:06.732497 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.733498 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m17:16:06.737495 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m17:16:06.740494 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m17:16:06.740494 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m17:16:06.741493 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m17:16:06.745498 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.747498 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m17:16:06.747498 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F234D2B0>]}
[0m17:16:06.748495 [info ] [Thread-1 (]: 20 of 23 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m17:16:06.750495 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m17:16:06.750723 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m17:16:06.751771 [info ] [Thread-1 (]: 21 of 23 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m17:16:06.752298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m17:16:06.752822 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m17:16:06.757513 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m17:16:06.758565 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m17:16:06.762257 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m17:16:06.763256 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.764256 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m17:16:06.764256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.771255 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.771255 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.772255 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m17:16:06.779258 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m17:16:06.783258 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.783258 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m17:16:06.785255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.788257 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.788257 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m17:16:06.789255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:06.791258 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m17:16:06.791258 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.792259 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m17:16:06.795257 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:16:06.797258 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m17:16:06.798256 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m17:16:06.799259 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m17:16:06.803256 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:06.804259 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m17:16:06.805258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27B3200>]}
[0m17:16:06.806259 [info ] [Thread-1 (]: 21 of 23 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m17:16:06.807256 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m17:16:06.807866 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m17:16:06.808397 [info ] [Thread-1 (]: 22 of 23 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m17:16:06.808925 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.best_selling_film)
[0m17:16:06.809463 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m17:16:06.814206 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m17:16:06.815280 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m17:16:06.818450 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling_film"
[0m17:16:06.818971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:06.819970 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: BEGIN
[0m17:16:06.819970 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:06.826611 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:06.827612 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:06.827612 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    dim_fm.film_id,
    dim_fm.title,
    COUNT(dim_fm.film_id) AS total_rent
FROM "data_warehouse"."dbt_dev_raw"."film" AS dim_fm
JOIN "data_warehouse"."dbt_dev_raw"."inventory" AS dim_invt
ON dim_fm.film_id = dim_invt.film_id
JOIN "data_warehouse"."dbt_dev_raw"."rental" AS dim_rnt
ON dim_invt.inventory_id = dim_rnt.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediete"."fact_payment" AS fct_pay
ON dim_rnt.rental_id = fct_pay.rental_id
GROUP BY dim_fm.film_id, dim_fm.title
ORDER BY total_rent DESC
  );
  
[0m17:16:07.079797 [debug] [Thread-1 (]: SQL status: SELECT 958 in 0.251 seconds
[0m17:16:07.082797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:07.083798 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film" rename to "best_selling_film__dbt_backup"
[0m17:16:07.084797 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:07.087796 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:07.087796 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m17:16:07.089798 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:07.090800 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m17:16:07.091799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:07.091799 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: COMMIT
[0m17:16:07.094796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:07.098796 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m17:16:07.099797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling_film"
[0m17:16:07.099797 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m17:16:07.102796 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:07.104800 [debug] [Thread-1 (]: On model.data_warehouse.best_selling_film: Close
[0m17:16:07.104800 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F27D0770>]}
[0m17:16:07.105797 [info ] [Thread-1 (]: 22 of 23 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 958[0m in 0.30s]
[0m17:16:07.106799 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m17:16:07.107797 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m17:16:07.107797 [info ] [Thread-1 (]: 23 of 23 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m17:16:07.108798 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m17:16:07.108798 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m17:16:07.112797 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m17:16:07.113800 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m17:16:07.117799 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m17:16:07.118799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.118799 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m17:16:07.119800 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:07.125796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m17:16:07.126797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.127796 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY payment_date
  );
  
[0m17:16:07.151309 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.023 seconds
[0m17:16:07.154313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.155314 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m17:16:07.156310 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:07.159313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.159313 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m17:16:07.161312 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:16:07.163313 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m17:16:07.163313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.164314 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m17:16:07.168144 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m17:16:07.170144 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m17:16:07.171143 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m17:16:07.171143 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m17:16:07.175147 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m17:16:07.177148 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m17:16:07.177148 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e9ff5dc-e30e-4496-8c81-a9aca3fcbf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F23298E0>]}
[0m17:16:08.649929 [info ] [Thread-1 (]: 23 of 23 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m17:16:08.650930 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m17:16:08.651930 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:08.652930 [debug] [MainThread]: On master: BEGIN
[0m17:16:08.652930 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:16:08.658929 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m17:16:08.659929 [debug] [MainThread]: On master: COMMIT
[0m17:16:08.659929 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:08.659929 [debug] [MainThread]: On master: COMMIT
[0m17:16:08.660930 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:16:08.661929 [debug] [MainThread]: On master: Close
[0m17:16:08.661929 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:16:08.662929 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m17:16:08.662929 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m17:16:08.663930 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m17:16:08.664291 [info ] [MainThread]: 
[0m17:16:08.665309 [info ] [MainThread]: Finished running 22 table models, 1 view model in 0 hours 0 minutes and 3.45 seconds (3.45s).
[0m17:16:08.669545 [debug] [MainThread]: Command end result
[0m17:16:08.702415 [info ] [MainThread]: 
[0m17:16:08.703414 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:16:08.703414 [info ] [MainThread]: 
[0m17:16:08.704415 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
[0m17:16:08.705415 [debug] [MainThread]: Command `dbt run` succeeded at 17:16:08.705415 after 4.36 seconds
[0m17:16:08.706414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208EFB39640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208EFB3B3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208F08CFE60>]}
[0m17:16:08.706414 [debug] [MainThread]: Flushing usage events
[0m17:16:17.485921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF3B1B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF5D05340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF58CF170>]}


============================== 17:16:17.490916 | a6226504-2c91-4fc0-b3cf-ac945a37f6f2 ==============================
[0m17:16:17.490916 [info ] [MainThread]: Running with dbt=1.8.5
[0m17:16:17.491917 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\RickyS-PC\\Desktop\\Training\\Tech-software\\Bootcamp\\Digital-Skola-FS-Data-Engineer\\Class\\mini-project2\\data_warehouse\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:16:17.690606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF676B380>]}
[0m17:16:17.742604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF621D820>]}
[0m17:16:17.743606 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:16:17.751605 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m17:16:17.915275 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:16:17.915275 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:16:17.955274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF68559D0>]}
[0m17:16:17.979275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF6953830>]}
[0m17:16:17.980275 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m17:16:17.981274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF68FA450>]}
[0m17:16:17.983272 [info ] [MainThread]: 
[0m17:16:17.984271 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:16:17.989273 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_intermediete'
[0m17:16:18.067409 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m17:16:18.068409 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: BEGIN
[0m17:16:18.068409 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:18.076409 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m17:16:18.077409 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediete"
[0m17:16:18.078407 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediete"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m17:16:18.081409 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m17:16:18.082412 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: ROLLBACK
[0m17:16:18.083412 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediete: Close
[0m17:16:18.084409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediete, now list_data_warehouse_dbt_dev)
[0m17:16:18.088458 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:16:18.088989 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m17:16:18.088989 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:18.095340 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:18.095867 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m17:16:18.096395 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m17:16:18.099972 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m17:16:18.100971 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m17:16:18.101970 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m17:16:18.102970 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m17:16:18.105469 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m17:16:18.106001 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m17:16:18.106528 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:18.112344 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:18.113398 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m17:16:18.113928 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m17:16:18.117544 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.003 seconds
[0m17:16:18.118544 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m17:16:18.119543 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m17:16:18.120545 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m17:16:18.122749 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:16:18.123281 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m17:16:18.123808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:18.129664 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m17:16:18.130722 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m17:16:18.131243 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m17:16:18.133870 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m17:16:18.135865 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m17:16:18.135865 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m17:16:18.143189 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:18.143723 [debug] [MainThread]: On master: BEGIN
[0m17:16:18.144256 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:16:18.150642 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m17:16:18.151642 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:18.151642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:16:18.159640 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m17:16:18.161642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6226504-2c91-4fc0-b3cf-ac945a37f6f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF6832C30>]}
[0m17:16:18.162642 [debug] [MainThread]: On master: ROLLBACK
[0m17:16:18.163639 [debug] [MainThread]: On master: Close
[0m17:16:18.163639 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:16:18.164641 [info ] [MainThread]: 
[0m17:16:18.168515 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m17:16:18.169041 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m17:16:18.169591 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m17:16:18.177003 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m17:16:18.178056 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m17:16:18.178056 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m17:16:18.179056 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m17:16:18.180053 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m17:16:18.181053 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m17:16:18.184055 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m17:16:18.185053 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m17:16:18.186055 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m17:16:18.186055 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m17:16:18.187054 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m17:16:18.188053 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m17:16:18.191053 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m17:16:18.192052 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m17:16:18.193052 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m17:16:18.193052 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m17:16:18.194052 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m17:16:18.194052 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m17:16:18.198054 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m17:16:18.199055 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m17:16:18.199866 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m17:16:18.200968 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m17:16:18.201500 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m17:16:18.202024 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m17:16:18.204673 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m17:16:18.205738 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m17:16:18.206807 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m17:16:18.207349 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m17:16:18.207867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m17:16:18.208403 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m17:16:18.211522 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m17:16:18.212561 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m17:16:18.213621 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m17:16:18.214665 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m17:16:18.215220 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m17:16:18.215792 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m17:16:18.218963 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m17:16:18.220005 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m17:16:18.220527 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m17:16:18.221560 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m17:16:18.221560 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m17:16:18.222558 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m17:16:18.226558 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m17:16:18.227559 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m17:16:18.228763 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m17:16:18.229295 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m17:16:18.230361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m17:16:18.231480 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m17:16:18.234640 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m17:16:18.235162 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m17:16:18.236223 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m17:16:18.236758 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m17:16:18.237288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m17:16:18.237816 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m17:16:18.240468 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m17:16:18.240998 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m17:16:18.242061 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m17:16:18.242597 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m17:16:18.243129 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m17:16:18.243659 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m17:16:18.246400 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m17:16:18.247027 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m17:16:18.248018 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m17:16:18.249018 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m17:16:18.250023 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m17:16:18.250023 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m17:16:18.253017 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m17:16:18.254019 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m17:16:18.255019 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m17:16:18.255019 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m17:16:18.256019 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m17:16:18.256019 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m17:16:18.259017 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m17:16:18.259017 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m17:16:18.260018 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m17:16:18.261018 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m17:16:18.261018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m17:16:18.262019 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m17:16:18.264546 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m17:16:18.265537 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m17:16:18.266538 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m17:16:18.267537 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m17:16:18.267537 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m17:16:18.268537 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m17:16:18.270537 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m17:16:18.271537 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m17:16:18.272539 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m17:16:18.272539 [debug] [Thread-1 (]: Began running node model.data_warehouse.most_frequent_actor
[0m17:16:18.273539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.most_frequent_actor)
[0m17:16:18.273539 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.most_frequent_actor
[0m17:16:18.276537 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.most_frequent_actor"
[0m17:16:18.277537 [debug] [Thread-1 (]: Began executing node model.data_warehouse.most_frequent_actor
[0m17:16:18.278540 [debug] [Thread-1 (]: Finished running node model.data_warehouse.most_frequent_actor
[0m17:16:18.278540 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m17:16:18.279541 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.most_frequent_actor, now model.data_warehouse.dim_inventory)
[0m17:16:18.280539 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m17:16:18.283538 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m17:16:18.284537 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m17:16:18.284537 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m17:16:18.285537 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m17:16:18.285537 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m17:16:18.286538 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m17:16:18.288537 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m17:16:18.289538 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m17:16:18.289538 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m17:16:18.290539 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:16:18.290539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m17:16:18.291539 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:16:18.303157 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:16:18.304157 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:16:18.305156 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:16:18.306157 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m17:16:18.306157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m17:16:18.307157 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m17:16:18.315156 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m17:16:18.316157 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m17:16:18.316157 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m17:16:18.317157 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m17:16:18.318158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m17:16:18.318158 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m17:16:18.320156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m17:16:18.321156 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m17:16:18.322157 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m17:16:18.322157 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m17:16:18.323157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m17:16:18.324157 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m17:16:18.326157 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m17:16:18.327157 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m17:16:18.328157 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m17:16:18.328157 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m17:16:18.329158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m17:16:18.329158 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m17:16:18.332156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m17:16:18.334159 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m17:16:18.335159 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m17:16:18.335159 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m17:16:18.336158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m17:16:18.336158 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m17:16:18.340156 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m17:16:18.341159 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m17:16:18.342157 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m17:16:18.342157 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m17:16:18.343157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m17:16:18.343157 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m17:16:18.347159 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:16:18.348156 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m17:16:18.349157 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m17:16:18.349157 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling_film
[0m17:16:18.350157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.best_selling_film)
[0m17:16:18.350157 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling_film
[0m17:16:18.353157 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling_film"
[0m17:16:18.354156 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling_film
[0m17:16:18.355157 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling_film
[0m17:16:18.355157 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m17:16:18.356157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_selling_film, now model.data_warehouse.total_revenue)
[0m17:16:18.356157 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m17:16:18.359156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m17:16:18.360156 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m17:16:18.360156 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m17:16:18.361158 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:16:18.362156 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m17:16:18.362156 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m17:16:18.367157 [debug] [MainThread]: Command end result
[0m17:16:18.457365 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m17:16:18.458365 [info ] [MainThread]: Building catalog
[0m17:16:18.469363 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m17:16:18.476362 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m17:16:18.477362 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m17:16:18.477362 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:18.484361 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m17:16:18.485362 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m17:16:18.485362 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('most_frequent_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_selling_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m17:16:18.490360 [debug] [ThreadPool]: SQL status: SELECT 208 in 0.004 seconds
[0m17:16:18.501361 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m17:16:18.503361 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m17:16:18.548748 [info ] [MainThread]: Catalog written to C:\Users\RickyS-PC\Desktop\Training\Tech-software\Bootcamp\Digital-Skola-FS-Data-Engineer\Class\mini-project2\data_warehouse\target\catalog.json
[0m17:16:18.550745 [debug] [MainThread]: Command `dbt docs generate` succeeded at 17:16:18.549746 after 1.16 seconds
[0m17:16:18.550745 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:16:18.550745 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m17:16:18.551745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF5CC8200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF63A3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BDF7AA7EF0>]}
[0m17:16:18.551745 [debug] [MainThread]: Flushing usage events
